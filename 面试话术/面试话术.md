# 0. 反问问题

实习时间、实习生培养机制、部门技术栈

# 1. 项目话术

1、编写时间工具类的时候，使用的是SimpleDateFormat，但是多线程下，该类会出现问题，这就牵扯到使用threadlocal来进行更改。**详情看笔记JUC进阶版第九章相关内容**

2、热点商品点赞计算器，点赞数加加统计，不要求实时精确。**详情看笔记JUC进阶版8.5LongAdder相关内容**

3、问到项目的时候，可以说那个乐享小程序，用到了ThreadLocal的知识来结合JWT令牌和Spring拦截器获取当前用户的ID

# 2. MySQL相关面试题

## 2.1 最左匹配原则

以最左边的为起点任何连续的索引都能匹配上，同时遇到范围查询（> < between lilke）就会停止匹配。

比如我们创建了一个联合索引，idx_abc(a, b, c)。在组合索引中，最底层的叶子节点先按照a列从左到右递增排序，但是b列和c列是无序的，而b列只有在a列值相等的情况下，才会小范围内有序，同理，c列只有在a和b都相等的情况下，才会小范围内有序。

B+树会先比较a列，才能确定下一步到底是往左还是往右，如果查询条件没有a列，B+树就不知道应该从哪个节点查起。

## ⭐2.2 什么是ACID，分别用什么来保证他们

[Innodb中的事务隔离级别和锁的关系 - 美团技术团队 (meituan.com)](https://tech.meituan.com/2014/08/20/innodb-lock.html)

- **原子性**：事务是最基本的一个单位，一个事务要么全部完成，要么全部不完成，**MySQL使用undo log来解决**
- **一致性**：有了原子性、隔离性、持久性的保证之后，事务的一致性才能得到保证（执行事务前后，数据保持一致，比如转账业务中，无论事务是否执行成功，转账人和收款人的总额应该是不变的）
- **隔离性**：并发访问数据库时，一个用户的事务不被其它事务所干扰，各并发事务之间数据库是独立的。**使用锁机制、MVCC来保障**
- **持久性**：一个事务被提交之后，它对数据库中数据的更改是持久的，即使数据库发生故障也不应该对其有任何影响。**使用redo log来保障**

## ⭐2.3 一条慢sql怎么去优化

如果是问：**怎么处理MySQL的慢查询**，就可以多一句：

**开启慢查询日志，准确定位到哪个sql语句出现了问题。**

1. 首先看这条sql有没有索引，如果有索引，就看该sql语句有没有索引失效
2. 看看是否是不恰当的sql语句，比如select *，或者在大数据表中使用< limit m，n>（比如找出10到20的记录，就可以写成`select xxx from t where id >= 10 limit 10`），以及对非索引字段进行排序。
3. 如果对语句的优化已经无法进行，可以考虑对表中的数据量是否过大，如果是的话就可以进行分库分表。

## ⭐2.4 MySQL如何避免死锁

MySQL中死锁产生的原因：MySQL默认是RR级别，且可以使用行锁。如果事务A给account表的id = 1这一行添加上了排它锁：`select * from account where id = 1 for update`，并且事务B给id = 2的行记录添加排它锁。再次之后，事务A想给id = 2的记录添加排它锁，事务B想给id = 1的记录添加排它锁，这就会造成mysql的死锁。

以上例子是为了理解，下面才是场景案例：

比如我们创建订单的时候需要做幂等性，就得先通过订单号查询该订单是否存在，如果不存在则新增订单记录。

![image-20220314103016841](IMG/面试话术.asserts/image-20220314103016841.png)

这是因为两个事务都加了排它锁，又因为order_no为非唯一索引，又是RR级别，所以select的加锁类型为gap lock，这里gap范围是4到正无穷。当我们想插入数据的时候，会在插入间隙上再次获取插入意向锁。它和gap lock是冲突的，需要等待其它事务释放gap lock之后，才能获取到插入意向锁。

解决办法：

1. **设置超时时间，当一个事务的等待时间超过设置的某个阈值，就对这个事务进行回滚**
2. 合理设计索引，尽量减少锁的范围
3. 尽量让数据表中的数据检索都通过索引来完成，避免无效索引导致行锁升级为表锁。
4. **将order_no设置为唯一索引，可以利用它的唯一性来保障订单记录不重复创建。**
5. **使用其它方式来代替数据库实现幂等性校验。**
6. 在允许幻读和不可重复读的情况下，尽量使用 RC 事务隔离级别，可以避免 gap lock 导 致的死锁问题；
7. 更新表时，尽量使用主键更新
8. 避免长事务，尽量将长事务拆解。

## ⭐2.4 说一下并发事务带来的问题：

- **脏读：**一个事务正在访问数据库并对数据进行了修改，而这个修改暂时没有提交到数据库中，此时另一个事务读取了这个数据，然后使用了这个数据。因为这个数据是未提交的数据，那么另一个事务读取到的就是脏数据。**简而言之，一个事务可以读取其它事务未提交的数据**
- **丢失修改：**一个事务读取一个数据，另一个事务也读取了该数据，那么在第一个事务修改了这个数据之后，第二个事务也修改了这个数据，那么第一个事务的修改就被丢失了。比如一个数据为20，第一个事务将其-1，第二个事务也是-1，最终该数据为19，丢失了一次修改。
- **不可重复读：**在一个事务中，第一次读取的数据和第二次读取的数据不一致。比如第一个事务读取了一个数据，此时第二个事务对这个数据进行了修改，并且提交。而此时第一个事务再次读取整个数据，就会发现两次读取的数据不一致。
- **幻读：**和不可重复读类似。第一个事务读取了数据之后，第二个事务进行了数据的insert，然后第一个事务再次读取，发现行数不一致，这就是幻读。

## ⭐2.5 说一下事务的隔离级别以及他们的原理

| 隔离级别 | 脏读 | 不可重复读 | 幻读 |
| -------- | ---- | ---------- | ---- |
| 读未提交 | √    | √          | √    |
| 读已提交 | ×    | √          | √    |
| 可重复读 | ×    | ×          | √    |
| 串行化   | ×    | ×          | ×    |

## 2.6 如何判断事务提交了？

InnoDB存储引擎对事务采用了WAL技术（write-ahead logging），这种技术的思想是先写日志，再写磁盘，只有日志写入成功，才算事务提交成功，这里的日志指的是redo日志

## 2.7 什么时候用表锁，什么时候用行锁

- 首先我们肯定绝大部分情况下都应该使用行锁，毕竟事务和行锁往往是我们之所以选择InnoDB存储引擎的原因。
- 事务需要更新大部分或者全部数据，表又比较大，如果使用默认的行锁，会导致该事务效率低，并且可能造成其它事务长时间等待和锁冲突，这时候可以使用表锁
- 事务涉及多个表，比较复杂，可能造成死锁导致大量事务回滚。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销。

## 2.8 count(*)、count(1)、count(列名)

**从执行结果来说**：

1. 前两者没有区别，他们都不会去过滤空值
2. count(列名)会过滤空值

**从执行效率来说**

1. 如果以列为主键，count（列名）优于count（1）
2. 如果表中存在主键，count（主键列名）效率最优
3. 如果表中只有一列，count（*）最优
4. 如果表有多列，且不存在主键，count（1）优于count（*）

所谓的count（1）其实就是计算一共有多少符合条件的行。1并不是表示第一个字段，而是表示一个固定值。

count（*）执行时会把星号翻译成字段的具体名字，效果也是一样，只不过多个一个翻译的动作，比固定值的方式效率稍微低一些。 

## 2.9 Memory存储引擎

Memory存储引擎将所有的数据都放在内存中，默认的索引结构是**哈希索引**，每个memory存储引擎的表实际上对应一个磁盘文件，**该文件只存储表的结构，而表的数据都存储在内存中。**

## ⭐2.10 redo log、bin log、undo log

### 1. redo log

首先我们知道，mysql中的数据是以页为单位，查询的时候会将该记录所在的整个页数据都加载到Buffer Pool中。然后会将”在某个数据页做了什么修改“记录到**重做日志缓存（redo log buffer）**中，接着会刷盘到redo log文件里。

我们必须知道的是，InnoDB存储引擎会有**一个后台线程，每隔1秒，就会将redo log buffer中的内容写进文件系统缓存（page cache），然后调用`fsync`刷盘**。也就是说，一个没有提交事务的redo log记录，也会刷盘。

**除此之外，当redo log buffer占用的空间即将达到`innodb_log_buffer_size`一半的时候，后台线程会主动刷盘。**

但是除此之外，还有三种刷盘策略：

1. **每次事务提交时不进行刷盘策略**：如果MySQL挂了或者宕机了可能会有1秒的数据丢失
2. **每次事务提交时都将进行刷盘策略（默认）：**只要事务提交，redo log记录就一定在磁盘里，不会有任何数据丢失。如果事务执行期间MySQL挂了或者宕机了，这部分日志丢了，但是事务还没有提交，所以日志丢了也不会有任何损失。
3. **每次事务提交时都只把redo log buffer中的内容写到page cache：**如果仅仅只是MySQL挂了将不会有任何损失，但是宕机可能会有一秒钟数据的丢失。

### 2. binlog

redolog是物理日志，记录内容是”某个数据页上做了什么修改“。而binlog是逻辑日志，记录的是语句的原始逻辑，属于MySQL Server层。不管什么引擎，只要发生了表数据更新，都会产生binlog日志

**binlog有两种格式：**

- **statement**：记录的内容是SQL语句原文，但是如果该SQL语句中包含了像`update_time=now()`之类的函数，就会导致与原库中的数据不一致。
- **row**：该格式记录的内容不再是简单的SQL语句了，还包含操作的具体数据，以该格式记录的内容看不到详细信息，需要通过`mysqlbinlog`工具解析出来。但是这种格式需要更大的容量来记录，比较占用空间，恢复与同步时会更加消耗IO资源，影响执行速度。
- **mixed**：前两者的混合，MySQL会判断这条SQL语句是否可能引起数据不一致，如果是就用row，否则使用statement。

**写入时机**

事务执行期间，会先把日志写进`binlog cache`中，事务提交的时候，再将binlog cache写到binlog文件中。

![img](IMG/面试话术.asserts/04-20220305234747840.png)

**write**只是将日志写入到文件系统的page cache，并没有持久化到磁盘上，所以速度比较快

**fsync**才是将数据持久化到磁盘的操作。

他们的时机可以通过参数**`sync_binlog`**来控制，默认是0；

- 为0表示每次提交事务只是执行write，由系统自行判断什么时候执行fsync
- 为1表示每次提交事务都会执行fsync，就如同redolog刷盘流程一样
- 为N（N>1），表示每次事务只执行write，但是积累N个事务之后再进行fsync

### 3. 两阶段提交

redolog让数据库拥有了崩溃恢复的能力，binlog让数据库保证了集群架构的数据一致性。他们的侧重点不同；

而且redolog是在事务过程中不断写入，binlog只有在事务提交的时候才会写入。写入的时机不一样。

但是如果这两部分日志逻辑不一致，会发生问题。比如在写完redolog之后，写入binlog的时候发生了异常，导致binlog没有写成功。当MySQL重启恢复数据的时候，就会发现数据不一致。

解决办法，**两阶段提交：将redolog的提交拆分成两个部分，prepare和commit**。

![IMG/面试话术.asserts/04-20220305234956774.png](IMG/面试话术.assets/04-20220305234956774.png)

如果binlog发生了异常导致没有写成功，MySQL根据redolog日志恢复数据的时候，发现redolog还处于prepare阶段，并且没有对应的binlog，就会回滚事务：

![img](IMG/面试话术.asserts/05-20220305234937243.png)

如果redolog设置commit阶段发生了异常呢？这就可以看下图的右边框框的流程图了，因为此时binlog肯定是写入成功了，能通过事务id找到binlog日志，所以MySQL认为是完成的，就会提交事务恢复数据。

![img](IMG/面试话术.asserts/06-20220305234907651.png)

### 4. undo log

如果想要保证事务的原子性，就需要在异常发生的时候，对已经执行的操作进行回滚，而回滚是通过undolog来实现的，**所有的事务进行的修改会先记录到这个回滚日志中，然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用回滚日志中的信息将数据回滚到修改之前的样子即可**。而且回滚日志先于数据持久化到磁盘中，这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库时，数据库还能通过查询回滚日志来回滚将之前未完成的事务。

## 2.10 唯一索引一定比普通索引快吗？

- 不一定
- 首先对于唯一索引的查询来说，因为知道是唯一了，在找到那条数据之后就会立即返回该数据，而普通索引还会继续匹配下一条数据，因此查询中唯一索引要比普通索引快，但是也是微乎其微的。
- 而对于更新来说，普通索引只需要将更新的数据放到changeBuffer就行了，而对于唯一索引来说，它必须去判断该数据的唯一性，还得将缓冲中的数据读入内存看有没有数据冲突。因此性能相对于普通索引来说比较慢。

## 2.11 索引下推？

[五分钟搞懂MySQL索引下推 - 掘金 (juejin.cn)](https://juejin.cn/post/7005794550862053412)

索引下推能够有效的利用联合索引减少回表的次数。

比如有一张user表，并且建了个联合索引（name、age）。执行下面的语句：

```mysql
select * from user where name = '张%' and age = 10;
# 如果查出来的记录如下：
id name age school
1	张三	10 长理
2	张四	11	长理
```

1、如果没有索引下推，那么存储引擎会先根据name索引找到id为1和2的记录，然后进行回表（两条记录两次回表），将id为1和2的完整的行记录查询出来交给server层，接着server层就会以age = 10进行筛选。

2、如果有索引下推，就会在查询到id为1的记录时判断它的age是否=10，符合条件；而查询id为2的时候，发现age不符合就直接给筛选掉了。这里就只需要回表id为1的行记录，只回表一次。

> 索引下推的目的是为了减少回表次数，也就是要减少IO操作。对于`InnoDB`的**聚簇索引**来说，数据和索引是在一起的，不存在回表这一说。

## 2.12 char和varchar的区别

1. char适用于对存取速度要求比较高或者占据空间一致的场景
2. **占据空间不同**：char的长度是不可变的（**固定为创建表时声明的长度，当char值被存储的时候，他们被空格填充到特定的长度，检索char值时也需要删除尾随空格。**），而varchar的长度是可变的
3. **存取速度不同**：char的存取速度比varchar要快，因为其长度固定，方便程序的存储和查找
4. **存储方式不同**：char是对英文字符占用1个字节，对汉字占用两个字节；而varchar的存储方式是对每个英文字符占用2个字符，汉字也是。

## 2.13 SQL注入原因？如何防止

- **原因：**开发过程中不注意规范书写sql语句对特殊字符进行过滤，导致客户端可以通过全局变量POST和GET提交一些sql语句正常执行。
- **防止措施：**
    1. 开启配置文件中的magic_quotes_gpc和magic_quotes_runtime设置
    2. 过滤掉关键词：select、update、insert
    3. 提高数据库和字段的命名技巧，对一些重要的字段根据程序的特点命名，不易被猜到。

## 2.14 MySQL一天五万条以上的数据增量，预计运维三年，怎么优化？

1. 设计良好的数据库结构，允许部分数据冗余，尽量避免join查询，提高效率
2. 选择合适的表字段数据类型和存储引擎，适当的添加索引
3. 主从读写分离
4. 进行分库分表，减少单表中的数据量
5. 添加缓存机制
6. 书写高效的SQL，比如只返回部分字段。

## 2.15 表a是主键、b是普通索引、c没有索引，select a,b,c from table where b =x 会用到索引吗？

正常情况下，mysql根据普通索引b来查询到对应的主键，然后会回表去找到该主键对应的记录。

但是当数据库b列相同的列到达一定的量之后，会发现mysql根本没有用到索引，而是会全表扫描。我估计是mysql的查询优化器会进行权衡判断这种情况要不要用索引。（可能是mysql觉得这个时候回表再查已经无意义，毕竟b的区分度已经不高了。

## 2.16 为什么不建议使用外键约束

使用外键约束可以保证数据的完整性和一致性；级联操作方便；将数据的完整性判断托付给了数据库完成，减少程序代码量。

1. **性能问题：**如果有一张表table里面有两个外键，每次向table插入数据的时候都得看那两个外键对应的表中有没有相应的数据，增加了查询过程。
2. **并发问题：**在每次修改数据都需要到另外一个表检查数据，需要获取额外的锁。更容易造成死锁。
3. **扩展性问题：**在水平拆分和分库的情况下，外键是无法生效的。

## 2.17 讲一下索引失效？

根本原因：

- 全局扫描的效率高于建立索引
- 索引涉及强制的类型转换
- 索引上做相关的运算操作

具体表现：

1. 组合索引未使用最左前缀
2. like未使用最左前缀，`where A like '%China'`
3. 搜索一个索引而在另一个索引上使用order by，`where A = a order by B`，只是用A上的索引，因为查询只使用一个索引。
4. or会使索引失效。`where A = a1 or A = a2（生效）、where A = a1 or B = b1（失效）`
5. 如果列类型是字符串，要使用引号。（否则会进行类型转换）
6. 在列上面的操作，函数（upper()等）、or、!= (<>) 、not in等

# 3. Redis相关面试题

## 3.1 布隆过滤器

是一种数据结构，用来告诉**某样东西一定不存在或可能存在**

通常判断某个元素是否存在可以使用hashMap，但是HashMap的存储容量比较高，而且如果数据集比较大，也不太可能能一次性全部加载到内存当中。

布隆过滤器是一个bit向量或者说bit数组。**如果我们要映射一个值到布隆过滤器中，需要使用多个不同的哈希函数生成多个哈希值，然后对每个哈希值指向的bit设置为1**

![image-20220310082010618](IMG/面试话术.asserts/image-20220310082010618.png)

**实战场景：**

某些存储系统的设计中，会存在空查询缺陷：当查询一个不存在的key时，需要访问慢设备，导致效率低下。比如一个前端页面的缓存系统，可能这样设计：先查询某个页面在本地是否存在，如果存在就直接返回，如果不存在，就从后端获取。但是当频繁从缓存系统查询一个页面时，缓存系统将会频繁请求后端，把压力导入后端。

这是只要增加一个bloom算法的服务，后端插入一个key时，在这个服务中设置一次。需要查询后端时，先判断key在后端是否存在，这样就能避免后端的压力。

## 3.2 Redis跳跃表

[Redis数据结构——跳跃表 - Mr于 - 博客园 (cnblogs.com)](https://www.cnblogs.com/hunternet/p/11248192.html)

如果一个有序集合（zset）包含的**元素数量比较多**或者**成员是比较长的字符串**时，redis就会使用跳跃表来作为有序集合键的底层实现。

为什么要元素数量比较多或者成员比较长的字符串呢？首先跳跃表这个结构是以空间换时间，来让链表快速的获取到指定的元素。当数量比较多时，或者成员变量是比较长的字符串时，跳表带来的空间消耗就相对而言非常少了，其优势必然会放大。

![Redis跳跃表](IMG/面试话术.asserts/Redis跳跃表.png)

Redis的跳跃表由zskiplistNode和skiplist两个结构定义，其中上图蓝色的部分就是skiplist，右边的四个部分就是zskiplistNode结构。

## 3.3 AOF文件过大怎么办

[(34条消息) 面试真题：AOF文件越来越大怎么办？_Z-AI-CSDN博客_aof文件过大怎么处理?](https://blog.csdn.net/qq_19595957/article/details/122122367)

1. AOF重写，Redis在AOF文件过大时会对命令进行合并重写。
2. redis考虑到像集合这种元素过多的时候不是一个命令能写完的，而是也会分多个命令写入。因为写入太多可能导致缓冲区溢出（先写缓冲区再写入AOF文件中）
3. 如果是大量写入的话，线程会被长时间阻塞，redis是单线程的，解决办法就是将重写放到子进程中，父进程可以继续处理命令请求，子进程带有父进程的数据副本，使用子进程而不是线程是因为可以避免使用锁，保证数据安全性
4. 但是可能会导致子进程和父进程数据不一致，比如在写入原来的数据时，父进程又处理了新的命令。解决办法是提供一个aof重写缓冲区，创建子进程开始，redis执行完写命令后会将命令发送到AOF缓冲区和AOF重写缓冲区，当子进程完成AOF重写工作后，子进程向父进程发送一个信号，父进程将AOF重写缓冲区的内容写入到新AOF文件中。

## 3.4 缓存一致性解决办法？



# 4. JVM相关面试题

## 4.1 说一下垃圾回收器的三色标记

[面试官:你说你熟悉jvm?那你讲一下并发的可达性分析 - 掘金 (juejin.cn)](https://juejin.cn/post/6844904070788939790)

所谓的三色标记其实就是白色、黑色、灰色

- 白色：表示对象尚未被垃圾回收器访问过
- 黑色：表示对象已经被垃圾回收器访问过，而且这个对象所有的直接引用都已经扫描过
- 灰色：表示对象已经被垃圾回收器访问过，但是这个对象至少有一个引用还没有被扫描过。

由于垃圾回收器和用户线程是并发工作的，再加上被标记为黑色的对象就一定不会再次被扫描。因此并发标记就会产生两个问题：对象消亡和浮动垃圾

**对象消亡：**把原本存活的对象错误的标记为已消亡

1. 存在对象关系，A指向B，B指向C，但是A不指向C。
2. 将A标记后，并开始标记B
3. 刚开始标记对象B，但是还没开始标记对象B的下一个对象C，此时A是黑色，B是灰色，C是白色。如果此时将引用关系改为A指向了C，并且断开了B和C的联系，根据三色标记原则，对象C是白色的，就会被错误的当成垃圾进行回收。

总的来说，**对象消亡需要两个条件**

1. 赋值器插入了一条或多条从黑色对象指向白色对象的新引用
2. 赋值器删除了全部从灰色对象到白色对象的直接或间接引用。

**有两种方式解决，增量更新和原始快照**

- 增量更新：用的是写后屏障，记录了所有新增的引用关系。当黑色对象插入新的指向白色对象的引用之后，就会将这个新插入的引用记录下来，等并发扫描结束之后，再将这些记录过的引用关系的黑色对象为根，再次扫描一遍。
- 原始快照：当灰色对象要删除指向白色对象的引用关系时，就会将这个要删除的引用记录下来，在并发扫描结束之后，再将这些记录过的引用关系中的灰色对象为根，重新扫描一次。也就是无论引用关系删除与否，都会按照刚刚开始扫描的那一刻的对象图快照进行搜索。

**CMS基于增量更新，G1基于原始快照**

## 4.2 说一下类卸载，或者说怎么判断无用类

- 该类的所有的实例都已经被回收，即堆空间中不存在任何该类以及它的派生子类的实例。
- 该类的类加载器已经被回收
- 该类所对应的Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类。

## 4.3 新生代中的survival满了怎么办？

首先得看是否发生了内存泄漏，可以使用JVisualVM来判断。

- 首先看服务器的内存是否足够，如果足够，建议直接增大新生代空间。
- 如果内存不够的话，就可以压缩Eden区，但是Eden区的减少会增加MinorGC的次数，可以根据系统对延迟和吞吐量的指标来看是否符合。
- 如果调整了之后内存还是不够用，可以试着去增加服务器的内存，或者把负担分担到多个JVM实例上。

## 4.4 tomcat如何打破双亲委派机制的？

**双亲委派机制的优点：**

1. 保证了Java程序的稳定运行
2. 可以避免类的重复加载
3. 保证了Java核心API不被篡改。

[1.5 tomcat是如何打破双亲委派机制的? - 盛开的太阳 - 博客园 (cnblogs.com)](https://www.cnblogs.com/ITPower/p/13217145.html)

我们都知道，一个tomcat可以加载多个不同的应用程序，比如可以同时加载spring5和spring4两种应用程序。而在spring4和spring5中，有很多类类名相同，但是他们的实现不一样。如果没有打破双亲委派机制，就只能加载一份，也就无法同时加载多个不同的应用程序了。

在tomcat中，每一个项目打包成war包的时候，tomcat都会自动生成一个类加载器，专门用来加载这个war包，而这个类加载器就打破了双亲委派机制。webapp类加载器就不需要再让上级去加载，它自己就可以加载对应war包里面的class文件了。

**双亲委派机制时ClassLoader类中的loadClass方法来实现的，重写该方法用来打破双亲委派机制**

## 4.5 FullGC效果不好，每次只能从90-85-90，该怎么办

（如果是一次fullgc后，剩余对象不多。那么说明你eden区设置太小，导致短生命周期的对象进入了old区。如果一次fullgc后，old区回收率不大，那么说明old区太小。）

## 4.6 内存分配策略

- 新对象优先在Eden中分配
- 大对象直接进入老年代
- 长期存活的对象进入老年代，默认是15
- 动态对象年龄判定：如果survivor中相同年龄所有对象大小的总和大于s空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到15岁
- 空间分配担保：在执行MinorGC之前，JVM会先检查老年代的最大可连续空间是否大于新生代所有对象的总空间，如果大于，则认为这次GC是安全的；如果不大于，就看HandlePromotionFailure的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于就尝试进行一次MinorGC；如果小于，或者不允许担保，就要进行FullGC

## 4.7 CPU占用过高的问题以及定位

[(34条消息) CPU占用过高的问题如何定位_weixin_32822759的博客-CSDN博客](https://blog.csdn.net/weixin_32822759/article/details/108170281)

1. 首先使用top命令查看正在执行进程的CPU使用率，内存使用率以及系统负载等信息。可以看到哪个进程id的进程cpu使用率最高，比如7139
2. 接下来就可以使用`top -p 7139 -H`，单独监视该进程下的所有线程信息，找到是哪个线程占用cpu最高。
3. 使用`jstack 指定线程id > xxx.txt`将线程的所有信息做dump记录。
4. 或者使用`jstat`相关命令
5. 或者使用`jmap`相关命令，或者使用`jvisualvm`可视化来看哪些对象用的最多，或者查看GC频率等

## 4.8 JVM如何对指令重排序，排序的依据?

[(34条消息) Java JVM（十二）：指令重排序_Sauron1的博客-CSDN博客_指令重排序](https://blog.csdn.net/pzxwhc/article/details/48984209)

**数据依赖性**：如果两个操作访问同一个变量，且这两个操作中有一个写操作，此时这两个操作之间就存在数据依赖性。

| 名称   | 示例代码      | 说明                         |
| ------ | ------------- | ---------------------------- |
| 写后读 | a = 1;  b = a | 写一个变量之后，再读这个变量 |
| 写后写 | a = 1;  a = 2 | 写一个变量之后，再写这个变量 |
| 读后写 | a = b; b = 1  | 读一个变量之后，再写这个变量 |

**在单线程环境中，JVM指令重排序会保证最终执行结果和代码顺序结果一致。并且处理器在执行重排序的过程中会考虑数据依赖性（如果不存在数据依赖性，编译器和处理器可能会对操作进行重排序）。但是多线程环境中，并不会保证。**

也就是说，as-if-serial语义：**不管怎么重排序，单线程下程序的执行结果不能被改变**

除了考虑数据依赖性以外，**还得考虑happens-before**

两个操作之间存在先行发生原则，并不意味着一定要按照该原则制定的顺序来执行。如果重排序之后的执行结果与按照先行发生原则来执行的结果一致，那么这种重排序并不非法。

## 4.9 了解堆内内存和堆外内存吗？

**堆内内存：**

1. 堆内内存 = 新生代 + 老年代 + 永久代

**堆外内存：**

1. 堆外内存就是把内存对象分配在Java虚拟机的堆以外的内存。
2. 使用`java.nio.DirectByteBuffer`对象进行堆外内存的管理和使用，该类会在创建对象时就分配堆外内存。
3. 元空间就是使用的堆外内存。
4. 对堆外内存的申请主要是通过成员变量`unsafe`来操作
5. **优点**：
   - 减少了垃圾回收机制
   - 加快了复制的速度：堆内在flush到远程时，会先复制到直接内存再发送，而堆外内存（本身就是物理机内存）几乎省略了该步骤
6. **缺点：**内存难以控制；使用堆外内存就间接失去了JVM管理内存的可能性，改由自己来管理，当发送内存溢出时排查起来十分困难。

# 5. Spring相关面试题

## ⭐5.1 Spring事务中的隔离级别？

Spring中的事务有五种，其实和MySQL的事务基本一致

|     隔离级别     | 脏读 | 不可重复读 | 幻读 |
| :--------------: | :--: | :--------: | :--: |
|     DEFAULT      |  -   |     -      |  -   |
| READ_UNCOMMITTED |  √   |     √      |  √   |
|  READ_COMMITTED  |  ×   |     √      |  √   |
| REPEATABLE_READ  |  ×   |     ×      |  √   |
|   SERIALIZABLE   |  ×   |     ×      |  ×   |

其中DEFAULT代表的含义就是**使用数据库默认的事务隔离级别**

如果Spring事务和MySQL的事务不一致的话，会默认使用Spring的事务，因为Spring的事务可以看作是MySQL的一种封装。

## 5.2 说一下Servlet或者Controller、Service是线程安全的吗

[Java面试题：Servlet是线程安全的吗？ - 陈树义 - 博客园 (cnblogs.com)](https://www.cnblogs.com/chanshuyi/p/5052426.html)

首先看Servlet，它是线程不安全的，当tomcat收到client的请求的时候，tomcat就会从线程池中取出一个线程，之后找到该请求对应的servlet对象并进行初始化，然后调用servlet中的service方法。注意的是每一个servlet对象在tomcat中只有一个实例，也就是单例模式。**如果servlet对象中有实例变量或者静态变量，并且service方法对其进行了操控，就会造成线程安全问题。**

同理，controller和service也是一样。但是对于大多数的bean来说，都是无状态的（不会保存数据），因此不用考虑线程安全问题。

## 5.3 Spring中的设计模式

- 工厂设计模式：Spring使用工厂模式通过BeanFactory、ApplicationContext创建bean对象
- 代理设计模式：AOP功能的实现。
- 单例设计模式：Bean默认都是单实例的
- 适配器模式：AOP的增强或通知（Advice）使用到了适配器模式、SpringMVC中也是用到了适配器模式适配Controller

## 5.4 springmvc中参数如何映射的

使用@RequestParam

## 5.5 说一下@Transactional失效的场景

1. 注解用在非public修饰的方法上，不支持回滚
   - 原因就是SpringAOP在动态代理的时候，TransactionInterceptor（事务拦截器）会在目标方法前后进行拦截。DynamicAdvisedInterceptor（CglibAopProxy 的内部类）的 intercept 方法或 JdkDynamicAopProxy 的 invoke 方法会间接调用 AbstractFallbackTransactionAttributeSource 的 computeTransactionAttribute 方法，获取Transactional 注解的事务配置信息，
   - ![img](IMG/面试话术.asserts/20201126161911807.jpeg)
2. 注解的rollbackFor设置错误：**Spring默认抛出了未检查（unchecked）异常（继承自 RuntimeException 的异常）或者 Error才回滚事务，其他异常不会触发回滚事务**
3. 普通方法A调用同类中的事务方法B，方法B的事务不会生效：**这还是由于使用Spring AOP代理造成的，因为只有当事务方法被当前类以外的代码直接调用时，才会由Spring生成的代理对象来管理，进而由 TransactionInterceptor （事务拦截器）生成事务对象。**
4. 数据库引擎不支持事务
5. 如果异常被try-catch处理了，也不会回滚。

## ⭐5.6 说一下Spring事务的传播行为

1. **REQUIRED**：默认的传播机制，如果当前没有事务，就新建一个事务，如果已经存在在一个事务中，就加入到这个事务。
2. **SUPPORTS**：持当前事务，如果当前有事务，就以事务方式执行；如果当前没有事务，就以非事务方式执行
3. **MANDATORY**：使用当前的事务，且必须在一个已经有的事务中执行，如果当前不存在事务，就会抛出异常。
4. **REQUIRES_NEW**：不管是否存在事务，都创建一个新的事务，原来的挂起，新的执行完毕，继续执行老的事务。
5. **NOT_SUPPORTED**：以非事务方式执行，如果当前存在事务，就把当前事务挂起
6. **NEVER**：以非事务方式执行，且必须在一个没有的事务中执行，如果当前存在事务，则抛出异常【和MANDATORY相反】
7. **NESTED**：如果当前存在事务，则在嵌套事务内执行，如果当前没有事务，则执行与REQUIRED类似的操作。

## 5.7 如何实现一个IOC容器？

IOC即控制反转，是一种思想，意味着将你设计好的对象交给容器来控制，而不是传统的在你的对象内部直接控制。将对象之间的相互依赖关系交给IOC容器进行管理，并由IOC容器完成对象的注入，简化应用开发，把应用从复杂的依赖关系中解放出来。

1. 先准备一个基本的容器对象，包含一些map结构的集合，用来方便后续过程中存储具体的对象。
2. 进行配置文件的读取工作或注解的解析工作，将需要创建的bean对象都封装成BeanDefinition对象存储再容器中。
3. 容器将封装好的BeanDefinition对象通过反射的方式进行实例化，完成对象的初始化工作。
4. 进行对象的初始化操作，也就是给类中对应属性值进行设置，也就是依赖注入，完成整个对象的创建，变成一个完整的bean对象，存储再容器的某个map结构中。
5. 通过容器对象来获取对象，进行对象的获取和逻辑处理工作
6. 提供销毁操作，当对象不用或者容器关闭的时候将无用的对象进行销毁。

## 5.8 Spring的优势

1. Spring拥有强大的生态圈，将Spring扩展到不同的领域
2. IOC容器降低了业务对象替换的复杂性，提高了组件之间的解耦
3. AOP支持允许将一些通用任务比如安全、事务、日志等进行集中处理，从而提供更好的复用
4. 高度开放性和可扩展性
5. 低侵入设计，代码的污染极低。

## 5.9 BeanFactory和ApplicationContext

**相同：**

1. 两者都是Spring提供的IOC容器，它们都可以用来配置XML属性，也支持属性的自动注入。
2. 都可以通过getBean("bean name")来获取bean。

**不同点：**

1. 对于BeanFactory来说，采用延迟加载形式注入bean，只有使用getbean时才会对该bean进行加载实例化；而后者在容器启动时一次性创建了所有的Bean。
2. 前者不支持国际化，即i18n，后者支持
3. 前者提供基本的IOC和DI功能，后者提供高级功能。
4. ApplicationContext是BeanFactory的子类。

## 5.10 bean的生命周期

![Spring Bean 生命周期](IMG/面试话术.asserts/b5d264565657a5395c2781081a7483e1.jpg)



# 6. SpringBoot相关面试题

## 6.1 说一下SpringBoot的加载过程



## 6.2 说一下拦截器的使用和底层原理

首先我们可以实现HandlerInterceptor接口，并在里面实现preHandler方法和afterComplete方法。接着去WebMvcConfigurer中配置好拦截器

拦截器的底层原理大概是，找出处理该请求的所有拦截器，并根据责任链模式一次执行拦截器，只有上一个拦截器返回了true才能执行下一个拦截器，否则不让被拦截的方法执行。 

## 6.3 说一下自动装配

SpringBoot通过@EnableAutoConfiguration注解开启自动装配功能，加载spring.factories中注册的各种AutoConfiguration类，当某个AutoConfiguration类满足其注解@Conditional指定的生效条件时，实例化该AutoConfiguration类中定义的Bean（组件等），并注入Spring容器中，就可以完成自动配置。

# 7. JUC相关面试题

## 7.1 JDK15为什么取消偏向锁

- 偏向锁导致synchronized子系统的代码复杂度过高，并影响其它的子系统，造成代码的维护和升级困难。
- 偏向锁带来的性能提升从整体来看并没有带来太多的收益，因为偏向锁的撤销成本过高，需要等待全局安全点，并且还需要暂停线程来做锁的撤销。

## 7.2 threadlocal在父子线程间是否可见，父子线程间如何通信

[(34条消息) 【并发编程】（十一）父子线程数据共享——InheritableThreadLocal原理_语言日记-CSDN博客_父子线程怎么共享数据](https://blog.csdn.net/qq_38249409/article/details/114300384?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-2-114300384.pc_agg_new_rank&utm_term=什么是父子线程&spm=1000.2123.3001.4430)

## ⭐7.3 线程池相关知识

### 0. 线程池优点

1. **线程复用**：降低资源消耗，通过重复利用自己创建的线程降低线程创建和销毁造成的损耗
2. **提高响应速度：**因为线程池中的线程数没有超过线程池的最大上限时，有的线程处于正在等待分配任务的状态，当任务到达时，任务可以不需要等到线程创建就能立即执行。
3. **管理线程：**提高线程的可管理性。使用线程池可以对线程进行统一分配、调优和监控。
4. **控制最大并发数**

### 1. 线程池种类

- **newCachedThreadPool**：线程池的大小不固定，可灵活回收空闲线程，若无可回收，则新建线程。****
- **newFixedThreadPool**：固定大小的线程池，当有新的任务提交，线程池中如果有空闲线程，则立即执行，否则新的任务会被缓存在一个任务队列中，等待线程池释放空闲线程。
- **newScheduledThreadPool**：定时线程池，支持定时及周期性任务执行。
- **newSingleThreadExecutor**：只创建一个线程，它只会用唯一的工作线程来执行任务，保证所有任务按顺序指定执行。

### 2. 线程池的拒绝策略

1. **ThreadPoolExecutor.AbortPolicy**：默认的策略。即丢弃并抛出RejectedExecutionException异常。
2. **ThreadPoolExecutor.DiscardPolicy**：丢弃任务，但是不抛出异常。
3. **DiscardOldestPolicy**：丢弃队列最前面的任务，然后重新提交被拒绝的任务，不抛出异常。
4. **CallerRunsPolicy**：由调用线程处理该任务，不会丢弃任务，也不抛出异常。

### 3. 线程池常见的阻塞队列

- **ArrayBlockingQueue**：是一个我们常用的典型的有界队列，其内部的实现是基于数组来实现的。
- **LinkedBlockingQueue**：由链表实现的队列，队列的长度是Integer.MAX_VALUE，基本上是可以任务是无界队列
- **SynchronousQueue**：是一个不存储任何元素的阻塞队列，每一个put操作都必须等待take操作，否则不能添加元素，同时它也支持公平锁和非公平锁。
- **PriorityBlockingQueue**：支持优先级排序的无界阻塞队列，插入的对象必须是可比较大小的，否则会报错
- **DelayQueue**：一个实现PriorityBlockingQueue的延迟获取的无界队列。具有延迟的功能。

### 4. 线程池的运行原理

1. 在创建了线程池后，等待提交过来的任务请求
2. 当调用execute方法添加一个请求任务时，线程池会做如下判断：
   1. 如果正在运行的线程数小于corePoolSize，那么马上创建线程运行这个任务
   2. 如果正在运行的线程数大于或等于corePoolSize，那么将这个任务放入队列
   3. 如果这时候队列满了且正在运行的线程数还小于maximumPoolSize，那么还是要创建非核心线程立即运行这个任务
   4. 如果队列满了且正在运行的线程数量大于或等于maximumPoolSize，那么线程池会启动饱和拒绝策略来执行
3. 当一个线程完成任务时，他会从队列中取下一个任务执行
4. 当一个线程无事可做超过一定的时间（keepAliveTime）时，线程池会判断：如果当前运行的线程数大于corePoolSize，那么这个线程就会被停掉

### 5. 如何合理设置线程池的核心参数

当线程池中核心线程数过大时，线程和线程之间会争夺CPU资源，会导致频繁上下文切换，过多的上下文切换会消耗CPU，增加线程的执行时间，影响了整体的执行效率。

当线程池中核心线程数过小时，如果同一时间有大量任务需要处理，可能会导致大量任务在任务队列中排队等待执行，甚至可能会执行拒绝策略，或者大量任务堆积在任务队列导致内存溢出OOM。

对于IO密集型（MySQL数据库、文件的读写、网络通信等任务）：**线程数 = CPU核数 * （1  + IO耗时 / CPU耗时）**或者**CPU核数 * 2**

对于CPU密集型（加解密、压缩、计算）：**CPU核数**，这样可以充分利用所有CPU的核心。如果线程数远远超出了CPU核心数量，反而会使任务效率下降，因为频繁的切换线程也是需要消耗时间的。

### 6. 为什么阿里不建议使用Executors创建线程池？

- 对于**newFixedThreadPool和newSingleThreadExector**来说，它们底层都是用的**LinkedBlockingQueue**，**当添加任务的速度大于线程池处理任务的速度，可能会在队列堆积大量的请求，消耗很大的内存，甚至导致OOM。**
- 对于**newCachedThreadPool和newScheduledThreadPool**来说，它们的**最大线程数都是Integer.MAX_VALUE**；当添加任务的速度大于线程池处理任务的速度，可能会创建大量的线程，消耗资源，甚至导致OOM。

## 7.4 什么是协程

[什么是协程？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/172471249)

## 7.5 run( )和start( )

**区别：**

1. run方法被称为线程体，每个线程执行的时候都是执行run方法里面的代码。而通过调用Thread中的start方法来启动一个线程。
2. start方法用于启动线程，而run方法用于执行线程的运行时代码。run可以重复调用，而start只能调用一次。
3. 调用start方法无需等待run方法执行完毕，可以直接继续执行其它的代码，此时线程是就绪态，并没有运行。然后通过此thread类调用run方法来完成其运行态，run方法运行结束，此线程终止，然后CPU调度其它的线程。

**为什么调用start方法的时候会执行run方法，为什么不能直接调用run方法？**

1. new一个Thread会让该线程进行新建态。调用start方法会启动一个线程并使线程进入了就绪态，当该线程分配到了CPU的时间片之后就可以开始运行。start会执行线程的相应准备工作，然后自动执行run方法里面的内容，这是真正的多线程运行。
2. 如果直接调用run方法，会把run方法当成一个main线程下的普通方法执行。

## 7.6 CAS为什么这么快？

1. CAS，比较并交换，如果内存中的值与预期原值相匹配，那么处理器就会自动将该位置的值更新为新的值。否则处理器不做任何操作。
2. 白话：我认为V的值一定等于A，如果是那就将V的值更新为B，否则不修改并告诉V的值实际是多少。
3. CAS的实现并不是简单的代码层面控制的，**而是需要硬件的支持**，因此在不同体系的架构中执行的性能差异很大。 **现代大多数处理器都是从硬件层面通过一些列指令实现CAS同步原语，进而操纵系统和JVM可以直接使用这些指令实现锁和并发的数据结构**
4. **JVM对CAS的支持**：由于Java程序运行在JVM上，所以应对不同的硬件体系架构的处理则需要JVM来实现。在不支持CAS操作的硬件上，JVM将使用自旋锁来实现。

## 7.7 为什么还要有非公平锁

1. 首先恢复挂起的线程到真正获取到锁还是有一定的时间差的。
2. 假设线程A持有一个锁，并且线程B请求这个锁。由于锁被A持有，因此B将被挂起。当A释放锁之后，B将被唤醒，然后B会再次尝试获取这个锁。与此同时，线程C也来请求这个锁，那么C很有可能在B被完全唤醒之前获得该锁，以及使用并释放该锁。因此非公平锁能更充分的利用CPU等待时间片，尽量减少CPU的空闲时间。
3. 举例：比如我在排队加油，我是第二个，但是我一直在玩手机，忘了到我了，然后后面的人就先行加油。

## 7.8 AQS原理

AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。  

**AQS 定义两种资源共享方式**  

- Exclusive（独占）：只有一个线程能执行，如 ReentrantLock。又可分为公平锁和非公平锁： 

- - 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 
  - 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 

- Share（共享）：多个线程可同时执行，如CountDownLatch、Semaphore、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。 

ReentrantReadWriteLock   可以看成是组合式，因为   ReentrantReadWriteLock   也就是读写锁允许多个线程同时对某一资源进行读。  

不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS 已经在顶层实现好了。  

1. 非公平锁在调用 lock 后，首先就会调用 CAS 进行一次抢锁，如果这个时候恰巧锁没有被占用，那么直接就获取到锁返回了。
2. 非公平锁在 CAS 失败后，和公平锁一样都会进入到 tryAcquire 方法，在 tryAcquire 方法中，如果发现锁这个时候被释放了（state == 0），非公平锁会直接 CAS 抢锁，但是公平锁会判断等待队列是否有线程处于等待状态，如果有则不去抢锁，乖乖排到后面。

## 7.9 synchronized和volatile的区别

1. sync表示只有一个线程可以获取作用对象的锁，执行代码，阻塞其余的线程；volatile表示变量在CPU寄存器中是不确定的，必须从主存中读取，保证多线程环境下变量的可见性，禁止指令重排。
2. volatile是变量修饰符，而sync可以作用与静态方法、方法和代码块。
3. volatile不会造成线程的阻塞
4. volatile标记的变量不会被编译器优化
5. volatile是线程同步的轻量级实现，性能比sync要高，但是volatile只能用于变量，而且volatile无法保证原子性。sync有了锁升级和各种优化，比如锁粗化和锁消除。

# 8. 不知道分类面试题

## 8.1 说一下一致性哈希

[白话解析：一致性哈希算法 consistent hashing-朱双印博客 (zsythink.net)](https://www.zsythink.net/archives/1182)

场景假设：如果我们有三台服务器用来缓存图片，那么就可以使用哈希算法以图片的名称计算hash，并且将其映射到这三台服务器上。这就可以让图片近乎均匀的缓存在这三台服务器上。

但是如果有一天，有一台服务器要下了，或者要增加一台新的服务器，这时所有的图片缓存都需要进行hash重算，就会导致所有的缓存都失效，也就是造成缓存雪崩问题，导致整个系统的压力过大而崩溃。而且就算不崩溃，几乎所有的缓存的位置都会发生变化，这也会对性能产生影响。

这时候一致性哈希算法就应运而生。

一致性哈希首先会假设有一个hash环。我们可以对服务器的IP地址进行取模运算，公式如下：

**hash（服务器A的IP地址）%2^32**

这样就会将这三台服务器放在hash环中的某个位置：（理想状况）


![image-20220309094122453](IMG/面试话术.asserts/image-20220309094122453.png)

同时，对于每一张图片，我们也同样计算它的位置：**hash（图片名称）%2^32**，

![IMG/面试话术.asserts/image-20220309094224633.png](IMG/面试话术.assets/image-20220309094224633.png)

我们以顺时针的方式来判断该图片应该属于哪一个服务器。上图的示例就是图片1和图片2缓存到服务器A，图片3缓存到服务器B，图片4缓存到服务器C上。

如果此时B给宕机了，那么只需要将图片3给缓存到服务器C就行了，其余的图片就不需要改变。这就只会影响一部分的缓存，从而减少系统的压力。

但是其实上面是理想的情况，我们还可能造成**hash环的倾斜**

实际计算hash的过程中，不会分布的那么均匀，就可能导致服务器之间在hash环上的位置非常的窄小，就会导致缓存的数据分布不均匀：

![IMG/面试话术.asserts/image-20220309094541586.png](IMG/面试话术.assets/image-20220309094541586.png)

**这就需要虚拟节点了**

我们凭空的让服务器节点多起来，既然没有多余的真正的物理服务器节点，我们就只能将现有的物理节点通过虚拟的方法复制出来，这些由实际节点虚拟复制而来的节点被称为”虚拟节点”。

![IMG/面试话术.asserts/image-20220309094606629.png](IMG/面试话术.assets/image-20220309094606629.png)

**“虚拟节点”是”实际节点”（实际的物理服务器）在hash环上的复制品,一个实际节点可以对应多个虚拟节点。**虚拟节点越多，hash环上的节点就越多，缓存被均匀分布的概率就越大。

## 8.2 什么是倒排索引

倒排索引源于实际应用中需要根据属性的值来查找记录。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index)。

## 8.3 负载均衡算法的实现

[几种简单的负载均衡算法及其Java代码实现 - 五月的仓颉 - 博客园 (cnblogs.com)](https://www.cnblogs.com/xrq730/p/5154340.html)

## 8.4 CPU的原子操作

[(34条消息) CPU实现原子操作的方法_盐焗咸鱼的博客-CSDN博客_cpu原子操作](https://blog.csdn.net/qq_33215865/article/details/88562456)

首先对于单核CPU来说，所有的时间都是串行，执行完第一个才会去执行第二个，每个指令都是原子的。

对于多核CPU来说：

1. CAS：它会检测现在内存中的值是不是符合预期值，如果符合就更新为新值，否则就丢弃新值
2. 使用总线锁：用来锁住某一个共享内存，当一个CPU要对内存进行操作的时候，会加上总线锁，限制其它cpu对共享内存操作。
3. 使用缓存锁：使用总线锁会锁定cpu与内存的通信，所以开销很大。而缓存锁在一个cpu进行回写时，会使用缓存一致性机制来保护内部内存，当其它处理器回写已被锁定的缓存行的数据时缓存行无效。

## 8.5 Hash冲突的解决办法

[解决哈希冲突的常用方法分析 - 简书 (jianshu.com)](https://www.jianshu.com/p/4d3cb99d7580)

1. **拉链法**
2. **开放地址法：**从发生冲突的单元起，按照一定的次序，从哈希表找到一个空闲的单元，然后将发生哈希冲突的元素存入到该单元。
3. **再哈希法：**同时构造多个不同的哈希函数。当H1=RH1（key）发生冲突时，再用H2 = RH2（key）进行计算，直到冲突不再发生，这种方法不易产生聚集，但是增加了计算的时间。
4. **建立公共溢出区：**将哈希表分为基本表和溢出表，凡是和基本表发生冲突的元素，一律填入溢出表。

# 9. Java基础

## 9.1 static可以修饰什么，可以修饰类吗？

static一般用来修饰成员变量和方法，也可以修饰类，但是普通类不允许声明为静态的，只有内部类可以。

**追问1：静态内部类的特点**

1. 静态内部类可以用静态成员变量和静态方法（普通内部类不能拥有）
2. 可以直接创建实例，不需要先创建外部类。`Test.StaticInner staticInner = new Test.StaticInner();`，而普通内部类需要先创建外部类：`Test.Inner inner1 = new Test().new Inner();`
3. 只可以直接访问外部类的静态成员，不可以直接访问外部类的非静态成员，需要传入外部类引用的方式才能使用。
4. 不持有外部类的引用（普通内部类持有）

**追问2：什么时候会用到静态内部类**

1. 内部类与所在的外部类有一定的关系，往往只有该外部内会调用此内部类，就无需专门用一个Java文件来存放这个类。


## 9.2 Java为什么不支持多继承

[(34条消息) Java不支持多继承的原因_u014133299的博客-CSDN博客_java为什么不支持多继承](https://blog.csdn.net/u014133299/article/details/77571912)

首先Java是一门面向对象的语言，从语义上来说，一个类继承了另一个类，那么这两个类就可以理解为父子关系，一个儿子只能有一个父亲。

再者多继承容易产生二义性：比如一个抽象类Animal，有一个抽象方法eat。此时有两个类分别继承了这个Animal类，Bird和Horse，但是同时又有一个类Pegasus继承了Horse和Bird类，当Pegasus执行eat方法时，到底是执行Bird的还是Horse的呢？这就产生了歧义。【致命方块】

为何接口不会产生致命方块问题，是以为接口所有的方法都是抽象的，实现的类必须得实现所有接口定义的接口，这不会存在歧义问题。

## 9.3 List一边遍历一边删除

如果是使用正序遍历：注意要修改i = i - 1

```java
public static void main(String[] args) {
    List<String> platformList = new ArrayList<>();
    platformList.add("博客园");
    platformList.add("CSDN");
    platformList.add("掘金");

    for (int i = 0; i < platformList.size(); i++) {
        String item = platformList.get(i);
        if (item.equals("博客园")) {
            platformList.remove(i);
            i = i - 1; 
        }
    }
    System.out.println(platformList);
}
```

如果是逆序遍历：不需要修改

```java
public static void main(String[] args) {
    List<String> platformList = new ArrayList<>();
    platformList.add("博客园");
    platformList.add("CSDN");
    platformList.add("掘金");

    for (int i = platformList.size() - 1; i >= 0; i--) {
        String item = platformList.get(i);
        if (item.equals("掘金")) {
            platformList.remove(i);
        }
    }
    System.out.println(platformList);
}
```

或者使用removeIf方法【推荐】

```java
public static void main(String[] args) {
    List<String> list = new ArrayList<>();
    list.add("aaa");
    list.add("bbb");
    list.add("ccc");

    list.removeIf(item -> "aaa".equals(item));
    // 也可以用下面的代替：
    list.removeIf("aaa"::equals);

}
```

## 9.4 自动装箱和拆箱

```java
public static void main(String[] args) {
    Integer a = new Integer(11);
    Integer b = 11;
    int c = 11;
    System.out.println(a == c); 
    System.out.println(a == b);
    System.out.println(b == c);
}
```

结果为true、false、true

如果a和c比较、b和c比较，因为c是基本数据类型，所以a和b都会进行拆箱，因此都转换为基本数据类型。

而a和b比较，b会进行装箱，取得是缓存池中的11的地址，所以为false

**为什么要有包装类型：**

1. Java本身就是一门OOP语言，对象是灵魂。
2. 基本数据类型有默认值，但是在业务中，可能我更加希望它的值是null，因为默认值也算是值。
3. 泛型参数不能是基本数据类型，必须是Object及其子类。

**自动拆箱带来的NPE问题**

1. 数据库的查询结果可能是null，如果使用基本数据类型进行接受，可能会导致NPE

   ```java
   public static void main(String[] args) throws InterruptedException {
       int a = new Test().getNum();
   }
   
   private Integer getNum() {
       return null;
   }
   ```

2. **三元运算符的不正确使用导致诡异的NPE**

   ```java
   boolean flag = false;
   Integer a = null;
   Integer n = flag ? 1 : a;
   ```

   原因在计算三元表达式结果时，a变量自动拆箱，调用了Integer.intValue()方法。

   **在三元表达式中，当第二、第三位操作数中有基本类型和对象时，对象就会拆箱为基本数据类型进行操作。**

## 9.5 序列化ID的作用

首先序列化就是将对象转换为字节流，而反序列化就是将字节流再转换成对象。

一般我们对可以进行序列化的对象进行序列化之前，该对象都得需要一个seriallVersionUID，原因就是Java的序列化机制是通过在运行时判断类的serialVersionUID来验证版本一致性的。在反序列化时，JVM会将传来的字节流中的serialVersionUID与本地实体类中的UID进行比较，如果相同则认为一致的，不相同就会报错。

如果我们没有显示指定UID，Java序列化机制就会根据编译时的class自动生成一个UID，只有同一次编译生成的class才会生成相同的UID。

## 9.6 泛型的缺点

Java中的泛型是伪泛型，这是因为在Java运行期间，所有的泛型信息都会被擦掉，也就是**类型擦除**

```java
public static void main(String[] args) throws NoSuchMethodException, InvocationTargetException, IllegalAccessException {
    List<Integer> list = new LinkedList<>();
    list.add(1);
    //        list.add('a');
    Class<? extends List> clazz = list.getClass();
    Method add = clazz.getDeclaredMethod("add", Object.class);
    add.invoke(list,"a");
    System.out.println(list);
}
```

最终输出的结果是：`[1, a]`

## 9.7 HashMap的hash扰动函数

- 使用扰动函数是为了防止一些比较差的hashCode函数，也就是为了减少哈希碰撞
- 底层1.7之前hash使用四次扰动，1.8之后只使用一次扰动，即hashcode右移16位，然后进行异或，目的是为了更全面的收集信息进一步减少冲突的可能，异或运算的结果更均匀
- 数组长度-1的作用相当于掩码，代替了取余的作用，效率更高

## 9.8 Comparator和Comparable

Comparable可作为一个类的内部排序实现，Java中一些普通类型如String、Integer等都实现了该接口，我们直接使用即可。

Comparator是外部排序接口，使用策略模式，一个类的排序规则在基于“开闭原则”时，可通过实现Compartor制定多个比较排序策略，供该类采用。可用于Collections.sort()、Arrays.sort()以及一些内部有序的类（SortedSet、SortedMap等）。

## 9.9 快速失败机制“fail-fast”

这个机制是Java集合的一种错误检测机制，当在迭代集合过程中进行结构上的改变的操作时，有可能会产生fail-fast机制。**单机和多线程时候都有可能会触发**

如果有两个线程，线程1通过iterator在遍历集合A中的元素，在某个时候线程2修改了集合A的结构（是结构的修改，不是简单的修改集合元素中的内容），那么就会报错：ConcurrentModificcationException异常。

```java
public static void main(String[] args) {
    List<String> list = new ArrayList<>();
    for (int i = 0; i < 10; i++) {
        list.add(i + "");
    }
    Iterator<String> iterator = list.iterator();
    int i = 0;
    while (iterator.hasNext()) {
        if (i == 3) {
            list.remove(3);
        }
        System.out.println(iterator.next());
        i++;
    }
}
```

**原因：**迭代器在遍历的时候直接访问集合中的内容， 并且在遍历过程中会使用到一个叫modCount的变量。集合在遍历过程中如果内容发生了变化，就会改变modCount的值。同时抛出异常的主要原因就是判断modCount是否等于expectedModCount，而一开始这两者是相等的。因此如果在遍历过程中，集合的内容发生了变化，就会导致异常的出现。

```java
// 每次调用next/hasNext方法的时候都会去调用该方法来判断集合中的内容是否发生变化
final void checkForComodification() {
    if (modCount != expectedModCount)
        throw new ConcurrentModificationException();
}
```

**解决办法：**使用CopyOnWriterArrayList来代替ArrayList；使用removeIf；使用迭代器中的remove方法而不是使用ArrayList中的remove方法，因为在迭代器中的remove方法里面，会让expectedModCount重新等于modCount

## 9.10 为什么 ArrayList 的 elementData 加上 transient 修饰？

首先被加上transient修饰的属性将不会被序列化。

对于ArrayList而言，由于扩容机制，就可能导致有一定的空间是没有被使用的，list重写了writeObject方法，它先将ArrayList中的非transient属性给序列化，然后会去遍历整个elementData，只序列化已存入的元素，这样即加快了序列化的速度，也减少了序列化之后的文件大小。

## 9.11 hashmap中的size究竟是什么

首先结论就是hashmap中的size其实就是map中所有的键值对数量。如果该数量大于负载因子*容量了，就会进行扩容。

而当hashmap中的链表长度大于8了，就会判断数组的长度是否超过64，如果超过了就会将链表转为红黑树。否则只会对数组扩容。

## 9.12 为什么hashmap中String、Integer这样的包装类适合作为key

String、Integer等包装类的特性能够保证Hash值的不可更改性和计算准确性，能够有效的减少Hash碰撞的几率

- 都是final类型，即不可变性，保证key的不可更改性，不会存在获取hash值不同的情况
- 内部已重写了equals()、hashCode()等方法，遵守了HashMap内部的规范，不容易出现Hash值计算错误的情况；

## 9.13 重写的规则？

1. 参数列表和返回类型必须完全与被重写的方法一致。
2. 构造方法不能被重写，声明为final的方法不能被重写
3. 声明为static的方法不能被重写，但是能够被再次声明
4. 访问权限不能比父类中被重写的方法低，即父类如果是public，子类就不能是protected
5. 重写的方法能够抛出任何非强制异常（uncheckedException，也叫非运行时异常），但是重写的方法不能抛出新的强制性异常，或者比被重写的方法声明的更广泛的强制性异常。

# 10. MyBatis相关面试题

## 10.1 MyBatis的一二级缓存

[MyBatis一级缓存详解 (qq.com)](https://mp.weixin.qq.com/s?__biz=MzkwMDE1MzkwNQ==&mid=2247496101&idx=1&sn=8d32c975eb41744903bb6331a500c28d&source=41#wechat_redirect)

对于MyBatis的一级缓存中，当MyBatis在执行一次SQL查询或者SQL更新之后，这条SQL语句并不会消失，而是会被MyBatis给缓存起来，再次执行相同SQL语句的时候，就会直接从缓存中进行提取。

**一级缓存又被称为SqlSession级别的缓存**

SqlSession是SqlSessionFactory会话工厂创建出来的一个会话的对象，这个SqlSession对象用于执行具体的SQL语句并返回给用户请求的结果。

![image-20220315170722539](IMG/面试话术.asserts/image-20220315170722539.png)

在每次更新操作的时候，MyBatis都会将此SqlSession中的一级缓存给清空掉。对于MyBatis来说，它每次访问数据库都会创建一个SqlSession，就算这两次访问都在同一个方法中。但是如果该方法是存在事务的，那么在同一个事务中，其实都是同一个SqlSession。

[(34条消息) 同一个方法中，Mybatis多次请求数据库，是否要创建多个SqlSession会话？_Abstracted的博客-CSDN博客](https://blog.csdn.net/qq_16159433/article/details/121128555?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-121128555.pc_agg_new_rank&utm_term=mybatisplus+每次请求+都需要创建SqlSession&spm=1000.2123.3001.4430)

**如果多个SqlSession需要共享缓存，则需要开启二级缓存**，开启之后，会使用CacheExecutor装饰Executor，进入一级缓存的查询流程前， 会先在CacheExecutor进行二级缓存的查询。

当二级缓存开启之后，同一个namespace的所有的操作语句，都影响着一个共同的cache。而且开启二级缓存的时候，**要求返回的POJO必须是可序列化的**

![img](IMG/面试话术.asserts/1515111-20190810211454258-1861395227.png)

# 11. 计算机网络

## 11.1 TCP的三次握手

### **1、建立连接可以两次握手吗？为什么？**

- 不可以
- 如果客户端发送的第一次请求由于网络的原因导致长时间滞留了，以至于误延到连接释放之后的某个时间才到达服务端。这次的请求是一个失效的请求，但是服务端收到这个失效的请求之后，会误以为这个是客户端再次发送的一个新的连接请求。于是服务端就向客户端发送确认，同意建立连接。假设不是三次握手，那么只要服务端发出确认，就认为新的连接已经建立了。由于客户端并没有发出建立连接的请求，因此不会理睬服务端的确认，也不会向服务端发送数据，但是此时服务端却认为新的连接已经建立了，就会一直等待客户端发送数据过来，这样就导致服务端很多资源白白浪费。而如果是三次握手，当服务端向客户端发送确认之后，客户端并不会向服务端发送确定，服务端由于收不到确认，就知道客户端并没有要求建立连接。
- 而且如果是两次握手，服务端也不知道客户端到底有没有收到它发送的确认请求。
- 虽然不可以采用两次握手，但是可以采用四次，不过会降低传输的效率。

### **2、如果已经建立了连接，但是客户端出现故障怎么办？**

服务端每收到一次客户端的请求之后都会重新复位一个计时器，通常是两个小时。如果两个小时之后还没有收到客户端的任何数据，server就会发送一个探测报文段，每隔75秒发送一次。如果发送了十次都没反应，就会认为客户端出现了故障， 然后就会关闭连接。

## 11.2 TCP四次挥手

### **1、四次回收的过程**

![IMG/面试话术.asserts/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA2MDg0ODUxMjcy](IMG/面试话术.assets/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA2MDg0ODUxMjcy)

1. 第一次挥手：客户端发送一个FIN，并发送一个序列号，用来关闭客户端到服务端的数据连接
2. 第二次挥手：服务端收到这个FIN，并且发回一个ACK，确认需要为收到的序列号加1，此时服务端进入CLOSE_WAIT状态。此时客户端已经没有要发送的数据了，但是仍然可以接受来此服务端的数据
3. 第三次挥手：服务端发送一个FIN，并且发送一个序列号给客户端，此时服务端进入LAST_ACK状态。第三次挥手的作用是服务端关闭与客户端的连接。
4. 第四次挥手：客户端收到服务端发送的FIN之后，进入TIME_WAIT状态，将ACK置为1，并且将确认序号设置为收到序号加1；服务端收到并确认序列号之后，变成CLOSE状态，不再向客户端发送数据。客户端等待2*MSL（报文段最长寿命）时间后，也进入CLOSE状态。完成四次挥手。

### **2、白话文理解四次挥手**

首先四次挥手是因为要确定数据全部传输完了。

1. 可以将四次挥手理解为A和B打电话。
2. A想要结束这次会话，就会告诉B，我要挂电话了。
3. B听到后，就说好的我知道了。但是此时B还有可能有话想和A说。
4. 当B话说完之后，就对A说：我说完了，我要挂电话了
5. A听到后，就说：好的，我知道你要挂电话了。
6. 四次挥手完毕

### **3、为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE_WAIT状态意义是什么）？**

服务端收到客户端断开连接的请求之后，可能会还有一部分数据没有发完，这时先回复ACK表示服务端接受到了客户端发来的断开连接请求。等待数据发送完之后再发送FIN，表示要断开服务端与客户端的数据传送。

### **4、客户端TIME_WAIT状态的意义？（为什么要等待2MSL）**

在第四次挥手的时候，客户端发给服务端的ACK可能丢失，TIME_WAIT就是用来重发可能丢失的ACK报文。如果server没有收到ACK，就会重发FIN，如果client在2MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL。防止server没有收到ACK而不断重发FIN。MSL是指一个片段在网络中的最大存活时间。2MSL就是一个发送和一个回复所需要的最大时间。如果直到2MSL，client都没有再次收到FIN，那么client推断ACK已经被成功接受，则结束TCP连接。

## 11.3 GET和POST的区别

1. GET重点在于从服务器上获得资源，POST重点在于向服务器发送数据。
2. GET传输的数据量小，因为受URL长度影响，但是效率较高；POST可以传送大量数据，所以上传文件只能POST
3. GET是不安全的，因为GET请求发送的数据是在URL上，是可见的。而POST是放在请求头部的，是安全的。

## 11.4 对称加密和非对称加密

- 对称加密指加密和解密使用的都是同一把钥匙，可能会造成不安全问题
- 非对称加密指使用两把钥匙，一把公钥一把私钥。公钥可以随便发布，私钥只能自己保存。发送密文的一方使用对方的公钥进行加密处理，对方接收到加密信息之后，使用自己的私钥进行解密。可以保障安全性，但是相比对称加密效率较慢。

## 11.5 Cookie和Session

HTTP是一种无状态协议，也就是说HTTP协议本身不对请求和响应之间的通信状态进行保存。因此就可以使用Cookie和Session来解决这个问题。

- Cookie一般用来保存用户信息。它是web服务器保存在用户浏览器上的文件（key-value），可以包含用户相关的信息。客户端向服务器发起请求的时候就会提取浏览器中的用户信息由HTTP发送给服务器。
- Session是浏览器向服务器会话过程中，服务器会分配的一块存储空间给SESSION。服务器默认为客户浏览器的cookie中设置sessionId，这个sessionId就和cookie对应，浏览器在向服务器请求过程中传输的cookie包含sessionId，服务器根据传输的cookie中的sessionId获取出会话中存储的信息，然后确认会话的身份信息。

**区别：**

1. cookie数据放在浏览器端，安全性较差；session放在服务器上，安全性相对较高
2. 单个cookie保存的数据不能超过4K，session无此限制

## 11.6 HTTP和HTTPS

### **1、什么是HTTP和HTTPS**

**HTTP：**

- HTTP全称超文本传输协议，用来规范超文本（网络上的包括文本在内的各种各样的消息）的传输的。具体来说，主要是用来规范浏览器和服务器端的行为的。 HTTP是一种无状态的协议，也就是说，服务器不维护任何有关客户端过去所发请求的消息。默认端口是80。
- HTTP优点：扩展性强、速度快、跨平台支持性好。
- HTTP通信过程：首先服务器再80端口等待客户的请求；浏览器发起到服务器的TCP连接；服务器接受来自浏览器的TCP连接；浏览器和服务器交换HTTP消息；关闭TCP连接。 

**HTTPS：**

- HTTPS是HTTP的加强安全版本，具有安全性的SSL加密传输协议。默认端口号是443.
- 保密性好、信任度高（可认证用户和服务器，确保数据发送到正确的客户机和服务器）。
- 建立一个信息安全通道来保证数据传输的安全；另一种就是确认网站的真实性。
- 相对于HTTP来说，HTTPS的技术门槛较高，并且CA证书的申请大部分都需要一定的资金。对接HTTPS也需要额外的技术支持；对于大部分网站来说，并不关系数据的安全性和保密性；HTTPS加重了服务端的负担，相比HTTP需要更多的资源来支撑，同时降低了用户的访问速度；对于用户来说，HTTP和HTTPS的差异感知不大。

### **2、HTTP和HTTPS的区别**

1. http是超文本传输协议，信息是明文传输；https是具有安全性的ssl加密传输协议。
2. https协议需要到CA申请证书
3. https和http是完全不同的连接方式，http默认80端口，https默认443端口
4. http的连接是无状态的，简单；https协议是由SSL + HTTP协议构建的可进行加密传输、身份认证的网络协议，比HTTP安全。

### **3、HTTPS工作原理**



### **4、一个完整的HTTP请求所经历的步骤**

### **5、HTTP版本对比**

**HTTP1.0**

**HTTP1.1**

**HTTP2相比HTTP1.1支持的特性：**

- **新的二进制格式**：HTTP1.1 基于文本格式传输数据；HTTP2.0采用二进制格式传输数据，解析更高效。 
- **多路复用**：在一个连接里，允许同时发送多个请求或响应，并且这些请求或响应能够并行的传输而不被阻塞，避免 HTTP1.1 出现的”队头堵塞”问题。 
- **头部压缩**，HTTP1.1的header带有大量信息，而且每次都要重复发送；HTTP2.0 把header从数据中分离，并封装成头帧和数据帧，使用特定算法压缩头帧，有效减少头信息大小。并且HTTP2.0在客户端和服务器端记录了之前发送的键值对，对于相同的数据，不会重复发送。比如请求a发送了所有的头信息字段，请求b则只需要发送差异数据，这样可以减少冗余数据，降低开销。 
- **服务端推送**：HTTP2.0允许服务器向客户端推送资源，无需客户端发送请求到服务器获取。

### 6. HTTPS如何实现可靠性

**对称加密 + 非对称加密 + 摘要算法 + 数字签名**

1. 

## 11.7 再看TCP和UDP

### **1. TCP和UDP的区别**

### **2. TCP协议如何保证可靠传输**

### **3. ARQ协议**

### **4. 滑动窗口和流量控制**

### **5. TCP头部的RST标志位**

RST表示复位，用来异常的关闭连接，在TCP的设计中它是不可或缺的。发送RST包关闭连接时，不必等缓冲区的包都发出去（不像FIN包），直接就丢弃缓冲区的包发送RST包。而接收端收到RST包之后，也不必发送个ACK包来确认。

TCP处理程序会在自己认为的异常时刻发送RST包。

1. A向B发起连接，但B之上并未监听相应的端口，这时B操作系统上的TCP处理程序会发RST包。
2. AB正常建立连接，正在通讯时，A向B发送了FIN包要求关闭连接，B发送ACK之后网断了，A通过若干原因放弃了这个连接（例如进程重启）。网通了之后，B又开始发送数据包，A收到之后表示压力很大，不知道这野连接哪来的，就发了个RST包强制把连接关了，B收到之后会出现connect reset by peer错误。

## 11.8 浏览器中输入url地址->>显示主页的过程

1. 浏览器通过DNS解析查找域名的IP地址（DNS查找过程：浏览器缓存、路由器缓存、DNS缓存）
2. 浏览器向服务器发送一个HTTP请求（cookies会随着请求发送给服务器）
3. 服务器处理请求（通过路径参数映射到对应的请求处理器进行请求）
4. 服务器发回一个HTML响应（将处理结果和视图返回给浏览器）
5. 浏览器开始显示HTML。

**这个过程中用到的协议？**

1. DNS：获取域名对应的IP
2. TCP：与服务器建立TCP连接
3. ARP：路由器在与服务器通信时，需要将IP地址转换为MAC地址，需要使用ARP协议。
4. HTTP：在TCP建立连接完成之后使用HTTP协议访问网页。
5. IP：建立TCP协议时，需要发送数据，发送数据在网络层使用IP协议。
6. OSPF：IP数据包在路由器之间，路由选择使用OSPF协议。

## 11.9 Keep-Alive

[(34条消息) http的keep-alive和tcp的keepalive区别_oceanperfect的博客-CSDN博客](https://blog.csdn.net/oceanperfect/article/details/51064574)

1. **HTTP中的KeepAlive**：在早期的HTTP，每一个HTTP请求都要求打开一个TCP SOCKET连接，并且在使用依次之后就会断开这个连接。这样的消耗无疑是非常大的。因此就可以使用KeepAlive来改善这种状态，**即在一次TCP连接种可以持续发送多份数据而不会断开连接**，通过该机制，可以减少TCP建立连接次数，提高性能和提高HTTP服务器的吞吐率。但是长时间的TCP连接容易导致系统资源无效占用，配置不当的KeepAlive带来的损失也是很大的。
2. **TCP种的KeepAlive**：TCP连接建立之后，如果应用程序或者上层协议一直不发送消息或者隔很久才发送一次数据，这是掉线了还是确实没有数据传输，连接还需不需要保持？当超过一段时间之后，TCP自动发送一个数据为空的报文给对方，如果对方回应了这个报文，说明连接还可以继续保持，如果没有报文返回，并且重复了多次之后还是没有，就会认为连接丢失，没有继续保持下去。

# 12. 操作系统

## 12.1 同步和异步？

1. 如果系统中存在临界资源（资源数量少于竞争资源的线程数量的资源），例如正在写的数据以后可能被另外一个线程读到，或者正在读的数据可能已经被另外一个线程写过了，那么这些数据就必须进行同步存取。
2. 当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用异步编程。
3. 事实上所谓的同步就是指阻塞式操作，而异步就是非阻塞式操作。

## 12.2 有了进程为什么还要有线程

**进程和线程：**

- 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，进程是系统进行资源分配和调度的一个独立单位。
- 线程是进程的一个实体，是CPU调度和分派的基本单位，他是比进程更小的能独立运行的基本单位，线程自己基本上不拥有系统资源，只拥有一点在运行过程中必不可少的资源（程序计数器、寄存器和栈），但是它可以与同属于一个进程的其他线程共享进程所拥有的全部资源。
- 一个进程崩溃之后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径，一个线程死掉就等于整个进程死掉。

**原因：**

- 进程只能在一个时间干一个事，如果想同时干两件事或多件事进程就无能为力了。
- 进程在执行过程中如果阻塞，例如等待输入，整个进程就会被挂起，即使进程中有些工作不依赖于输入的数据也将无法执行。

## 12.3 线程和进程的区别

进程是系统进行资源分配和调度的一个独立单位，是一个在内存中运行的应用程序；线程是进程划分的更小的运行单位，一个进程可以有多个线程。

**进程和线程的区别：**

1. **根本区别：**进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位。
2. **资源开销：**每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看作是轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和PC，线程之间切换的开销比较小。
3. **包含关系：**线程是进程的一部分，所以线程也被称为轻量级进程。
4. **内存分配：**同一个进程的线程共享本进程的地址空间和资源，而进程和进程之间的地址空间和资源是独立的。 
5. **影响关系：**一个进程崩溃之后，在保护模式下不会对其它进程产生影响，但是一个线程崩溃后有可能导致整个进程都死掉。进程比线程更有健壮性。
6. **执行过程：**每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行。

## 12.4 什么是上下文切换？

1. 在多线程编程中，线程的个数一般都大于CPU核心的个数，而一个CPU在任意时刻只能被一个线程使用，为了让这些线程都有效执行，**CPU采取的策略就是为每个线程分配时间片并轮转的形式。**当一个线程的时间片用完的时候就会重新处于就绪状态让给其它线程使用，这个过程就叫做上下文切换。
2. 概括来就是说，当前任务在执行完CPU的时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。**任务从保存到再加载的过程就是一次上下文切换。**
3. 频繁的上下文切换会消耗大量的CPU事件。

## 12.5 死锁

### 1. 死锁形成的条件

- **互斥条件：**资源只能有一个进程占用。如果此时还有其它的进程来请求该资源，就只能等待直到占有资源的进程用毕释放。
- **占有并等待**：一个进程至少应该占有一个资源，并等待另一个资源，而该资源被别的进程所占有。
- **非抢占：**资源不能被抢占，只能在持有资源的进程完成任务后，该资源才会被释放。 
- **循环等待：**若干进程之间形成一种头尾相接的循环等待关系。

### 2. 如何避免死锁

预防死锁，就要避免上述的四个死锁形成条件。

1. 避免一个线程同时获得多个锁
2. 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
3. 尝试使用定时锁，使用lock.tryLock(timeout)来替换使用内部锁机制。