# **0. 反问问题和自我介绍**

**反问问题：**

实习时间、实习生培养机制、部门技术栈

请问能不能谈谈你作为一个公司老员工对公司的感受？

我觉得我这次表现不是太好，你有什么建议或者评价给我吗？

接下来我会有一段时间的空档期，有什么值得注意的或者建议学习的吗？

未来如果我要加入这个团队，你对我的期望是什么？

# **1. 项目话术**

1、编写时间工具类的时候，使用的是SimpleDateFormat，但是多线程下，该类会出现问题，这就牵扯到使用threadlocal来进行更改。**详情看笔记JUC进阶版第九章相关内容**

2、热点商品点赞计算器，点赞数加加统计，不要求实时精确。**详情看笔记JUC进阶版8.5LongAdder相关内容**

3、问到项目的时候，可以说那个乐享小程序，用到了ThreadLocal的知识来结合JWT令牌和Spring拦截器获取当前用户的ID

4、字典树在项目中的应用：使用前缀树过滤黑白名单域名。

## 1.1 线程池的应用

技术参考：[Java线程池实现原理及其在美团业务中的实践 - 美团技术团队 (meituan.com)](https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html)

**场景1】快速响应用户请求**

就比如用户要查看一个商品的信息，就需要将商品维度的一系列信息比如：从库存服务里面查找商品价格、库存服务里面查找商品库存、优惠券服务里面查找该商品所拥有的优惠券、商品服务里面查找商品的详细信息、SKU、SPU等等给聚合起来展示给用户。

从用户的体验来说，这个结果的响应越快越好。可以将各种服务的调用封装成任务异步并行的执行，最后再总的封装起来，这里就可以去使用**CompletableFuture + 线程池**的技术进行实现。**这种场景最重要的就是获取最大的响应速度去满足用户，所以应该不设置队列去缓冲并发任务（采用同步队列SynchronousQueue），调高corePoolSize和maxPoolSize去尽可能创造更多的线程快速执行任务。**

**场景2】快速处理批量任务**

。。。。使用有界队列去缓冲大批量的任务，但是队列容量必须声明，防止任务无限制堆积。

**问题1】如何确定线程池的参数？**

我们应该怎么去确定线程池中的参数呢？最大线程数和核心线程数的值应该是多少呢？实际上在真正的业务中是很难合理预估的，

- 一方面线程池的运行机制并不是很好理解，配置合理需要强依赖于开发人员的个人经验和知识；
- 另一方面，线程池执行的情况和任务类型相关性较大，IO密集型和CPU密集型的任务运行起来的情况差异很大；
- 再者还可能受到硬件环境如CPU、内存、硬盘读写速度、网络状况等影响，

这导致很难有一个简单有效的通用公式帮我们直接计算出结果。

注：**可以说通用化公式以8核16线程cpu的服务器为例，核心线程设置为8，线程最大数量：可以调整为服务器线程x2**

但是为了更好的使用线程池，我们也可以去实现动态线程池（核心线程数、最大线程数、队列长度），将线程池的参数通过nacos等配置中心去进行配置。然后可以去设计一个系统去监控我们的项目中所有的线程池，在线程池中的线程数量即将达到阈值或者出现了RejectedException的时候，去触发警告，然后将警告信息推送到该服务相关负责人。负责人根据实际情况去通过nacos进行相关配置，降低故障发生的概率。

**不过还是存疑，具体仍然不知道实战中如何去使用它，以及到底是否真正的需要这种动态化线程池仍是一种未知。**

**【更多的核心线程数和最大线程数的配置见笔记7.3】**

面试时候可以将这些参数的选择理念说一说，然后如果说到具体的数据时，就说可以根据CPU核数*（1+IO耗时/CPU耗时）来计算，但是其实还得考虑到具体的业务，和访问情况，需要不停的调整参数，考虑到这种因素，当时只是做了理论的实现

## 1.2 Redis在项目中的应用

购物车、不常用数据缓存、实现销量排行功能的时候，在第一个版本中，使用到了MySQL进行实现，并对访问次数进行索引建立。这里可以提一下在后续优化中，使用Redis实现排行榜的功能。

## 1.3 项目中的关于MySQL的优化

对商品的价格进行排序的时候，对商品价格建立了索引。同时当时是一次性将所有的数据都查出来了，然后进行优化，限制查询数据量。

## 1.4 消息队列在项目中的应用

在订单服务的时候使用到了RabbitMQ，并且对MQ可靠性做了一定的保障。

## 1.5 幂等性

幂等性的特点就是多次相同的操作产生的影响均与一次执行的影响相同。

**场景1】唯一性索引**

一个电话号码只能注册一个用户，对于这种场景，就可以给用户表中的电话号码添加唯一性索引，就可以保证不会出现多个用户共用一个电话号码的情况。

比较适用于插入操作

**场景2】乐观锁**

1. 先查出当前要更新的数据的version
2. update table set name = #xxx, version = version + 1 where version = #version

**场景3】token令牌机制**

![image-20220427120006112](IMG/面试话术.assets/image-20220427120006112.png)

1. 如果redis在第一次请求的时候挂掉了，都没有redis了就不用考虑后续流程了。
2. 如果第一次请求删除缓存失败，就不会有操作数据库的行为
3. 如果第一次请求删除操作非常长，但是redis的这种操作是单线程的，完全不用考虑此时另外一个请求的查询。
4. 还有就是redis的确删除成功了，但是在返回的时候由于网络波动时间很长，然后在此期间另一个请求还是会发现redis中已经没有数据了，此次请求失败。

## 1.6 数据一致性

对于一致性要求高的业务，就可以采用**异步更新缓存**的方式去保证数据一致性：

- 写操作会先去删除缓存，然后去更新数据库，之后通过使用canal中间件订阅binlog来异步更新缓存。

- 读操作先判断缓存中有没有，如果没有就去查询数据库，但是不会去将数据添加进redis进行缓存。

- 比如此时线程A执行写操作，它先删除缓存，然后在更新数据库的时候由于网络波动等各种原因耗时较长；线程B执行读操作，它会发现缓存中没有数据了，就去数据库读，但是此时数据库还没有更新完成，就读取的是旧数据，然后将旧数据返回。此时数据库并没有更新成功，因此不算数据不一致，没有出现问题。
- 然后A执行更新数据库成功之后，此时缓存中的数据就是脏数据了，就得马上将其删除，就可以通过canal订阅binlog的方式，去异步的删除掉redis中的缓存。

也可以采用**延时双删**的方式，在更新完数据库之后，就可以sleep一段时间之后，再次去删除缓存，此时即使缓存中的数据是脏数据也会被删除。但是问题就是这个sleep的时间要根据具体的业务场景去设置，比较难以确定。而且要sleep一段时间，这会导致该更新方法的吞吐量下降。就可以采用**异步删除**的方式，将sleepM秒的操作和二次删除缓存的操作放到另一个线程里面，A线程在更新完数据库之后就直接结束。如果第二次删除缓存不成功，就可以采用重试的方式，直到删除成功。

而且对于StringRedisTemplate来说，使用delete操作会返回是否成功，如果失败了也可以选择抛出一个异常，然后对整个的更新方法进行一个事务回滚。更新操作都没了就不用谈数据不一致了。

对于我的商城项目来说，我缓存的是三级菜单，这种数据更新频率不高，而且对一致性要求并没有那么严格，因此出现短暂的数据不一致性是完全可以接受的。而且缓存并不是永久的，而是会有过期时间。

[缓存和数据库一致性问题，看这篇就够了 | Kaito's Blog (kaito-kidd.com)](http://kaito-kidd.com/2021/09/08/how-to-keep-cache-and-consistency-of-db/)

> **如何保证本地缓存和分布式缓存的一致性？**

比如Caffeine和Redis构成的二级缓存。

可以采用消息队列的方式：

1. 设置适当的过期时间，可以允许短暂的不一致，而达到最终一致性。
2. 引入消息队列，保证消息的可靠性，但是增加了系统的复杂度

# **2. MySQL相关面试题**

## 2.1 最左匹配原则

以最左边的为起点任何连续的索引都能匹配上，同时遇到范围查询（> < between lilke）就会停止匹配。

比如我们创建了一个联合索引，idx_abc(a, b, c)。在组合索引中，最底层的叶子节点先按照a列从左到右递增排序，但是b列和c列是无序的，而b列只有在a列值相等的情况下，才会小范围内有序，同理，c列只有在a和b都相等的情况下，才会小范围内有序。

B+树会先比较a列，才能确定下一步到底是往左还是往右，如果查询条件没有a列，B+树就不知道应该从哪个节点查起。

## ⭐2.2 什么是ACID，分别用什么来保证他们

[Innodb中的事务隔离级别和锁的关系 - 美团技术团队 (meituan.com)](https://tech.meituan.com/2014/08/20/innodb-lock.html)

- **原子性**：事务是最基本的一个单位，一个事务要么全部完成，要么全部不完成，**MySQL使用undo log来解决**
- **一致性**：有了原子性、隔离性、持久性的保证之后，事务的一致性才能得到保证（执行事务前后，数据保持一致，比如转账业务中，无论事务是否执行成功，转账人和收款人的总额应该是不变的）
- **隔离性**：并发访问数据库时，一个用户的事务不被其它事务所干扰，各并发事务之间数据库是独立的。**使用锁机制、MVCC来保障**
- **持久性**：一个事务被提交之后，它对数据库中数据的更改是持久的，即使数据库发生故障也不应该对其有任何影响。**使用redo log来保障**

## ⭐2.3 一条慢sql怎么去优化

如果是问：**怎么处理MySQL的慢查询**，就可以多一句：

**开启慢查询日志，准确定位到哪个sql语句出现了问题。**

1. 首先看这条sql有没有索引，如果有索引，就看该sql语句有没有索引失效
2. 看看是否是不恰当的sql语句，比如select *，或者在大数据表中使用< limit m，n>（比如找出10到20的记录，就可以写成`select xxx from t where id >= 10 limit 10`），以及对非索引字段进行排序。
3. 如果对语句的优化已经无法进行，可以考虑对表中的数据量是否过大，如果是的话就可以进行分库分表。

## ⭐2.4 MySQL如何避免死锁

MySQL中死锁产生的原因：MySQL默认是RR级别，且可以使用行锁。如果事务A给account表的id = 1这一行添加上了排它锁：`select * from account where id = 1 for update`，并且事务B给id = 2的行记录添加排它锁。再次之后，事务A想给id = 2的记录添加排它锁，事务B想给id = 1的记录添加排它锁，这就会造成mysql的死锁。

以上例子是为了理解，下面才是场景案例：

比如我们创建订单的时候需要做幂等性，就得先通过订单号查询该订单是否存在，如果不存在则新增订单记录。

![image-20220314103016841](IMG/面试话术.asserts/image-20220314103016841.png)

这是因为两个事务都加了排它锁，又因为order_no为非唯一索引，又是RR级别，所以select的加锁类型为gap lock，这里gap范围是4到正无穷。当我们想插入数据的时候，会在插入间隙上再次获取插入意向锁。它和gap lock是冲突的，需要等待其它事务释放gap lock之后，才能获取到插入意向锁。

解决办法：

1. **设置超时时间，当一个事务的等待时间超过设置的某个阈值，就对这个事务进行回滚**
2. 合理设计索引，尽量减少锁的范围
3. 尽量让数据表中的数据检索都通过索引来完成，避免无效索引导致行锁升级为表锁。
4. **将order_no设置为唯一索引，可以利用它的唯一性来保障订单记录不重复创建。**
5. **使用其它方式来代替数据库实现幂等性校验。**
6. 在允许幻读和不可重复读的情况下，尽量使用 RC 事务隔离级别，可以避免 gap lock 导 致的死锁问题；
7. 更新表时，尽量使用主键更新
8. 避免长事务，尽量将长事务拆解。

## ⭐2.4 说一下并发事务带来的问题：

- **脏读：**一个事务正在访问数据库并对数据进行了修改，而这个修改暂时没有提交到数据库中，此时另一个事务读取了这个数据，然后使用了这个数据。因为这个数据是未提交的数据，那么另一个事务读取到的就是脏数据。**简而言之，一个事务可以读取其它事务未提交的数据**
- **丢失修改：**一个事务读取一个数据，另一个事务也读取了该数据，那么在第一个事务修改了这个数据之后，第二个事务也修改了这个数据，那么第一个事务的修改就被丢失了。比如一个数据为20，第一个事务将其-1，第二个事务也是-1，最终该数据为19，丢失了一次修改。
- **不可重复读：**在一个事务中，第一次读取的数据和第二次读取的数据不一致。比如第一个事务读取了一个数据，此时第二个事务对这个数据进行了修改，并且提交。而此时第一个事务再次读取整个数据，就会发现两次读取的数据不一致。
- **幻读：**和不可重复读类似。第一个事务读取了数据之后，第二个事务进行了数据的insert，然后第一个事务再次读取，发现行数不一致，这就是幻读。

## ⭐2.5 说一下事务的隔离级别以及他们的原理

| 隔离级别 | 脏读 | 不可重复读 | 幻读 |
| -------- | ---- | ---------- | ---- |
| 读未提交 | √    | √          | √    |
| 读已提交 | ×    | √          | √    |
| 可重复读 | ×    | ×          | √    |
| 串行化   | ×    | ×          | ×    |

## 2.6 如何判断事务提交了？

InnoDB存储引擎对事务采用了WAL技术（write-ahead logging），这种技术的思想是先写日志，再写磁盘，只有日志写入成功，才算事务提交成功，这里的日志指的是redo日志

## 2.7 什么时候用表锁，什么时候用行锁

- 首先我们肯定绝大部分情况下都应该使用行锁，毕竟事务和行锁往往是我们之所以选择InnoDB存储引擎的原因。
- 事务需要更新大部分或者全部数据，表又比较大，如果使用默认的行锁，会导致该事务效率低，并且可能造成其它事务长时间等待和锁冲突，这时候可以使用表锁
- 事务涉及多个表，比较复杂，可能造成死锁导致大量事务回滚。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销。

## 2.8 count(*)、count(1)、count(列名)

**从执行结果来说**：

1. 前两者没有区别，他们都不会去过滤空值
2. count(列名)会过滤空值

**从执行效率来说**

1. 如果以列为主键，count（列名）优于count（1）
2. 如果表中存在主键，count（主键列名）效率最优
3. 如果表中只有一列，count（*）最优
4. 如果表有多列，且不存在主键，count（1）优于count（*）

所谓的count（1）其实就是计算一共有多少符合条件的行。1并不是表示第一个字段，而是表示一个固定值。

count（*）执行时会把星号翻译成字段的具体名字，效果也是一样，只不过多个一个翻译的动作，比固定值的方式效率稍微低一些。 

## 2.9 Memory存储引擎

Memory存储引擎将所有的数据都放在内存中，默认的索引结构是**哈希索引**，每个memory存储引擎的表实际上对应一个磁盘文件，**该文件只存储表的结构，而表的数据都存储在内存中。**

## ⭐2.10 redo log、bin log、undo log

### 1. redo log

首先我们知道，mysql中的数据是以页为单位，查询的时候会将该记录所在的整个页数据都加载到Buffer Pool中。然后会将”在某个数据页做了什么修改“记录到**重做日志缓存（redo log buffer）**中，接着会刷盘到redo log文件里。

我们必须知道的是，InnoDB存储引擎会有**一个后台线程，每隔1秒，就会将redo log buffer中的内容写进文件系统缓存（page cache），然后调用`fsync`刷盘**。也就是说，一个没有提交事务的redo log记录，也会刷盘。

**除此之外，当redo log buffer占用的空间即将达到`innodb_log_buffer_size`一半的时候，后台线程会主动刷盘。**

但是除此之外，还有三种刷盘策略：

1. **每次事务提交时不进行刷盘策略**：如果MySQL挂了或者宕机了可能会有1秒的数据丢失
2. **每次事务提交时都将进行刷盘策略（默认）：**只要事务提交，redo log记录就一定在磁盘里，不会有任何数据丢失。如果事务执行期间MySQL挂了或者宕机了，这部分日志丢了，但是事务还没有提交，所以日志丢了也不会有任何损失。
3. **每次事务提交时都只把redo log buffer中的内容写到page cache：**如果仅仅只是MySQL挂了将不会有任何损失，但是宕机可能会有一秒钟数据的丢失。

### 2. binlog

redolog是物理日志，记录内容是”某个数据页上做了什么修改“。而binlog是逻辑日志，记录的是语句的原始逻辑，属于MySQL Server层。不管什么引擎，只要发生了表数据更新，都会产生binlog日志

**binlog有两种格式：**

- **statement**：记录的内容是SQL语句原文，但是如果该SQL语句中包含了像`update_time=now()`之类的函数，就会导致与原库中的数据不一致。
- **row**：该格式记录的内容不再是简单的SQL语句了，还包含操作的具体数据，以该格式记录的内容看不到详细信息，需要通过`mysqlbinlog`工具解析出来。但是这种格式需要更大的容量来记录，比较占用空间，恢复与同步时会更加消耗IO资源，影响执行速度。
- **mixed**：前两者的混合，MySQL会判断这条SQL语句是否可能引起数据不一致，如果是就用row，否则使用statement。

**写入时机**

事务执行期间，会先把日志写进`binlog cache`中，事务提交的时候，再将binlog cache写到binlog文件中。

![img](IMG/面试话术.asserts/04-20220305234747840.png)

**write**只是将日志写入到文件系统的page cache，并没有持久化到磁盘上，所以速度比较快

**fsync**才是将数据持久化到磁盘的操作。

他们的时机可以通过参数**`sync_binlog`**来控制，默认是0；

- 为0表示每次提交事务只是执行write，由系统自行判断什么时候执行fsync
- 为1表示每次提交事务都会执行fsync，就如同redolog刷盘流程一样
- 为N（N>1），表示每次事务只执行write，但是积累N个事务之后再进行fsync

### 3. 两阶段提交

redolog让数据库拥有了崩溃恢复的能力，binlog让数据库保证了集群架构的数据一致性。他们的侧重点不同；

而且redolog是在事务过程中不断写入，binlog只有在事务提交的时候才会写入。写入的时机不一样。

但是如果这两部分日志逻辑不一致，会发生问题。比如在写完redolog之后，写入binlog的时候发生了异常，导致binlog没有写成功。当MySQL重启恢复数据的时候，就会发现数据不一致。

解决办法，**两阶段提交：将redolog的提交拆分成两个部分，prepare和commit**。

![IMG/面试话术.asserts/04-20220305234956774.png](IMG/面试话术.assets/04-20220305234956774.png)

如果binlog发生了异常导致没有写成功，MySQL根据redolog日志恢复数据的时候，发现redolog还处于prepare阶段，并且没有对应的binlog，就会回滚事务：

![img](IMG/面试话术.asserts/05-20220305234937243.png)

如果redolog设置commit阶段发生了异常呢？这就可以看下图的右边框框的流程图了，因为此时binlog肯定是写入成功了，能通过事务id找到binlog日志，所以MySQL认为是完成的，就会提交事务恢复数据。

![img](IMG/面试话术.asserts/06-20220305234907651.png)

### 4. undo log

如果想要保证事务的原子性，就需要在异常发生的时候，对已经执行的操作进行回滚，而回滚是通过undolog来实现的，**所有的事务进行的修改会先记录到这个回滚日志中，然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用回滚日志中的信息将数据回滚到修改之前的样子即可**。而且回滚日志先于数据持久化到磁盘中，这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库时，数据库还能通过查询回滚日志来回滚将之前未完成的事务。

## 2.10 唯一索引一定比普通索引快吗？

- 不一定
- 首先对于唯一索引的查询来说，因为知道是唯一了，在找到那条数据之后就会立即返回该数据，而普通索引还会继续匹配下一条数据，因此查询中唯一索引要比普通索引快，但是也是微乎其微的。
- 而对于更新来说，普通索引只需要将更新的数据放到changeBuffer就行了，而对于唯一索引来说，它必须去判断该数据的唯一性，还得将缓冲中的数据读入内存看有没有数据冲突。因此性能相对于普通索引来说比较慢。

## 2.11 索引下推？

[五分钟搞懂MySQL索引下推 - 掘金 (juejin.cn)](https://juejin.cn/post/7005794550862053412)

索引下推能够有效的利用联合索引减少回表的次数。

比如有一张user表，并且建了个联合索引（name、age）。执行下面的语句：

```mysql
select * from user where name = '张%' and age = 10;
# 如果查出来的记录如下：
id name age school
1	张三	10 长理
2	张四	11	长理
```

1、如果没有索引下推，那么存储引擎会先根据name索引找到id为1和2的记录，然后进行回表（两条记录两次回表），将id为1和2的完整的行记录查询出来交给server层，接着server层就会以age = 10进行筛选。

2、如果有索引下推，就会在查询到id为1的记录时判断它的age是否=10，符合条件；而查询id为2的时候，发现age不符合就直接给筛选掉了。这里就只需要回表id为1的行记录，只回表一次。

> 索引下推的目的是为了减少回表次数，也就是要减少IO操作。对于`InnoDB`的**聚簇索引**来说，数据和索引是在一起的，不存在回表这一说。

## 2.12 char和varchar的区别

1. char适用于对存取速度要求比较高或者占据空间一致的场景
2. **占据空间不同**：char的长度是不可变的（**固定为创建表时声明的长度，当char值被存储的时候，他们被空格填充到特定的长度，检索char值时也需要删除尾随空格。**），而varchar的长度是可变的
3. **存取速度不同**：char的存取速度比varchar要快，因为其长度固定，方便程序的存储和查找
4. **存储方式不同**：char是对英文字符占用1个字节，对汉字占用两个字节；而varchar的存储方式是对每个英文字符占用2个字符，汉字也是。

## 2.13 SQL注入原因？如何防止

- **原因：**开发过程中不注意规范书写sql语句对特殊字符进行过滤，导致客户端可以通过全局变量POST和GET提交一些sql语句正常执行。
- **防止措施：**
    1. 开启配置文件中的magic_quotes_gpc和magic_quotes_runtime设置
    2. 过滤掉关键词：select、update、insert
    3. 提高数据库和字段的命名技巧，对一些重要的字段根据程序的特点命名，不易被猜到。

## 2.14 MySQL一天五万条以上的数据增量，预计运维三年，怎么优化？

1. 设计良好的数据库结构，允许部分数据冗余，尽量避免join查询，提高效率
2. 选择合适的表字段数据类型和存储引擎，适当的添加索引
3. 主从读写分离
4. 进行分库分表，减少单表中的数据量
5. 添加缓存机制
6. 书写高效的SQL，比如只返回部分字段。

## 2.15 表a是主键、b是普通索引、c没有索引，select a,b,c from table where b =x 会用到索引吗？

正常情况下，mysql根据普通索引b来查询到对应的主键，然后会回表去找到该主键对应的记录。

但是当数据库b列相同的列到达一定的量之后，会发现mysql根本没有用到索引，而是会全表扫描。我估计是mysql的查询优化器会进行权衡判断这种情况要不要用索引。（可能是mysql觉得这个时候回表再查已经无意义，毕竟b的区分度已经不高了。

## 2.16 为什么不建议使用外键约束

使用外键约束可以保证数据的完整性和一致性；级联操作方便；将数据的完整性判断托付给了数据库完成，减少程序代码量。

1. **性能问题：**如果有一张表table里面有两个外键，每次向table插入数据的时候都得看那两个外键对应的表中有没有相应的数据，增加了查询过程。
2. **并发问题：**在每次修改数据都需要到另外一个表检查数据，需要获取额外的锁。更容易造成死锁。
3. **扩展性问题：**在水平拆分和分库的情况下，外键是无法生效的。

## 2.17 讲一下索引失效？

**根本原因：**

- 全局扫描的效率高于建立索引
- 索引涉及强制的类型转换
- 索引上做相关的运算操作

**具体表现：**

1. 组合索引未使用最左前缀
2. like未使用最左前缀，`where A like '%China'`
3. 搜索一个索引而在另一个索引上使用order by，`where A = a order by B`，只是用A上的索引，因为查询只使用一个索引。
4. or语句前后没有同时使用索引会使索引失效。`where A = a1 or A = a2（生效）、where A = a1 or B = b1（失效）`
5. 如果列类型是字符串，要使用引号。（否则会进行类型转换）
6. where中索引列有运算，或者索引列使用了函数
6. where中在索引字段上使用not、<>、!=（不等于操作符是永远不会用到索引的，因为对它的处理只会产生全表扫描，优化方法：key<>0改为key>0 or key < 0）
6. 在索引列上使用IS NULL 或 IS NOT NULL：索引是不索引空值的，所有这样的操作不能使用索引，可以将NULL值变成数字类型，或给字符串类型设置一个默认值，判断是否等于默认值即可。

**没必要使用到索引的场景**

1. 唯一性差
2. 频繁更新的字段不用
3. where中不用的索引
4. 索引使用<>时，效果一般

## 2.18 分库分表

1、**RANGE（水平分表）**

可以指定一个数据范围来表示分表，比如每百万条数据放到一个表中，但是这个得用redis或者其余的工具来维护表的ID。

2、**HASH取模**

根据用户的ID进行hash取模的方式，将数据放到不同的表中，但是如果要对MySQL服务器进行扩容，在数据迁移的时候就很麻烦，还得重新去计算hash值。**这时候就可以使用一致性哈希**

3、**垂直分表**

将经常用的数据独立出来成为一张新的表。

## 2.19 MySQL脏页刷盘

首先对于MySQL来说，如果想要更新数据，都是会查询到指定的记录所在的数据页，然后将整个数据页都加载出来到BufferPool中。然后它在BufferPool中进行更新。这时候就会导致内存数据页和磁盘数据页的不一致，这种不一致的内存数据页就被称为脏页。等到该脏页写入到磁盘之后，数据一致性就得到了解决。

但是试想一下， 如果每更新一条记录就对该页进行一次刷盘，无疑是非常消耗性能的；如果到达一个阈值之后才进行一次刷盘，数据库突然宕机之后，这些数据都会被丢失。**因此就可以引入redolog进行记录**，将每个记录在哪个页做了什么修改进行记录。

虽然redolog的内存缓冲区中的日志写入日志文件中也需要进行磁盘IO，但是这个过程是顺序IO的，在磁盘文件的尾部追加即可。而IO刷盘是随机存储的（需要寻找刷新的磁盘位置）。所以redolog写入磁盘的速度远远快于数据的刷盘。

## 2.20 RR下MVCC不能完全解决幻读

对于快照读来说，在InnoDB的RR模式下，依靠与MVCC的确可以解决幻读。但是它**并没有解决更新操作后的幻读**。

比如一开始t表中只有一条记录A，事务2在第一次读取的时候发现表中只有记录A，然后会生成一个ReadView，接着事务1向其添加了记录B，事务2在第二次查看的时候，发现表中仍然只有记录A，这就解决了快照读下的幻读问题。可是如果此时事务2对记录B进行update操作，然后第三次查询，发现表中多了条记录B，这就没有解决幻读问题。

## 2.21 讲一讲索引设计原则

**适合创建索引的情况：**

1. 字段的数值拥有唯一性的限制，比如学号、身份证号码
2. 频繁作为where查询条件的字段
3. 频繁作为group by和order by的列。
4. update、delete的where列。
5. distinct字段需要创建索引
6. 多表连接的连接条件
7. 使用字符串前缀创建索引。
8. 尽量创建联合索引

**不适合创建索引的情况**

1. where中使用不到的字段。
2. 数据量小的情况
3. 大量重复数据的字段
4. 经常更新的字段
5. 不建议使用无序的值作为索引
6. 删除不再使用或者很少使用的索引
7. 不要定义冗余或重复的索引。

## 2.22 什么是页分裂

按照正常的流程来说，我们一般都会使用默认的自增主键，但是如果使用UUID作为主键就可能会造成页分裂。因为在InnoDB索引的设定中，要求主键索引是递增的，这样构建索引树的时候才方便，因为得保证下一个数据页中的所有行一定要比前一个数据页中的行的主键id要大。而UUID则是无序的，就可能导致页分裂，从而调整成为有序的。

**页分裂的目的就是保证：后一个数据页中的所有行主键值比前一个数据页中主键值大。**

## 2.23 MySQL常见异常

- Access denied for user 'root'@'localhost' (using password: YES)。

无权限，密码错误

- MySQL5.7 group by 新特性报错

ONLY_FULL_GROUP_BY规定SELECT中的列必须在GROUP BY中。

- 高版本的驱动类包出错。

MySQL8.0使用的是com.mysql.cj.jdbc.Driver，而之前的是com.mysql.jdbc.Driver

# **3. Redis相关面试题**

## 3.1 布隆过滤器

是一种数据结构，用来告诉**某样东西一定不存在或可能存在**

通常判断某个元素是否存在可以使用hashMap，但是HashMap的存储容量比较高，而且如果数据集比较大，也不太可能能一次性全部加载到内存当中。

布隆过滤器是一个bit向量或者说bit数组。**如果我们要映射一个值到布隆过滤器中，需要使用多个不同的哈希函数生成多个哈希值，然后对每个哈希值指向的bit设置为1**

![image-20220310082010618](IMG/面试话术.asserts/image-20220310082010618.png)

**实战场景：**

某些存储系统的设计中，会存在空查询缺陷：当查询一个不存在的key时，需要访问慢设备，导致效率低下。比如一个前端页面的缓存系统，可能这样设计：先查询某个页面在本地是否存在，如果存在就直接返回，如果不存在，就从后端获取。但是当频繁从缓存系统查询一个页面时，缓存系统将会频繁请求后端，把压力导入后端。

这是只要增加一个bloom算法的服务，后端插入一个key时，在这个服务中设置一次。需要查询后端时，先判断key在后端是否存在，这样就能避免后端的压力。

## 3.2 Redis跳跃表

[Redis数据结构——跳跃表 - Mr于 - 博客园 (cnblogs.com)](https://www.cnblogs.com/hunternet/p/11248192.html)

如果一个有序集合（zset）包含的**元素数量比较多**或者**成员是比较长的字符串**时，redis就会使用跳跃表来作为有序集合键的底层实现。

为什么要元素数量比较多或者成员比较长的字符串呢？首先跳跃表这个结构是以空间换时间，来让链表快速的获取到指定的元素。当数量比较多时，或者成员变量是比较长的字符串时，跳表带来的空间消耗就相对而言非常少了，其优势必然会放大。

![Redis跳跃表](IMG/面试话术.asserts/Redis跳跃表.png)

Redis的跳跃表由zskiplistNode和skiplist两个结构定义，其中上图蓝色的部分就是skiplist，右边的四个部分就是zskiplistNode结构。

## 3.3 AOF文件过大怎么办

[(34条消息) 面试真题：AOF文件越来越大怎么办？_Z-AI-CSDN博客_aof文件过大怎么处理?](https://blog.csdn.net/qq_19595957/article/details/122122367)

1. AOF重写，Redis在AOF文件过大时会对命令进行合并重写。
2. redis考虑到像集合这种元素过多的时候不是一个命令能写完的，而是也会分多个命令写入。因为写入太多可能导致缓冲区溢出（先写缓冲区再写入AOF文件中）
3. 如果是大量写入的话，线程会被长时间阻塞，redis是单线程的，解决办法就是将重写放到**子进程**中，父进程可以继续处理命令请求，子进程带有父进程的数据副本，使用子进程而不是线程是因为可以避免使用锁，保证数据安全性
4. 但是可能会导致子进程和父进程数据不一致，比如在写入原来的数据时，父进程又处理了新的命令。解决办法是提供一个aof重写缓冲区，创建子进程开始，redis执行完写命令后会将命令发送到AOF缓冲区和AOF重写缓冲区，当子进程完成AOF重写工作后，子进程向父进程发送一个信号，父进程将AOF重写缓冲区的内容写入到新AOF文件中。

## ⭐3.4 缓存一致性解决办法？

https://blog.csdn.net/qq_42253147/article/details/94447103

要是问到为什么简历上写的是双写一致性，我就说当时做项目的时候是这么考虑的，然后随着后续的学习，发现这样子对性能有影响，就对项目进行了改造，采用延时双删。

如果是**先写数据库再更新缓存**，首先会有数据不一致问题，比如A线程写了数据库，然后由于网络等原因，没来得及更新缓存。此时B线程进行更新了数据库，然后将缓存写到了redis，这时候线程A又开始写缓存了，就会导致线程B的缓存更新无效。同时如果数据库一小时更新了很多次，就会导致缓存也更新很多次。然后这个缓存可能一个小时内只会被读取一次，那么额外更新的缓存数就完全没有必要。**因此缓存应该是被删除而不是被更新**

因此采用的策略是**先删除缓存，再更新数据库**，解决方案是**延迟双删**

问题产生：先删除缓存，此时数据库还没有更新成功，如果另一个线程来读取缓存，发现缓存为空，就会去数据库读取新的值，但是此时数据库还未更新成功，因此读到的就是旧值，缓存不一致发生。

解决办法：为了避免在更新数据库的时候，其它线程从缓存中读取不到数据，就在更新完成之后sleep一段时间，然后再次删除缓存。同时sleep的时间要对业务读写缓存的时间做出评估，sleep时间大于读写缓存的时间即可。

1. 线程1删除缓存，然后去更新数据库
2. 线程2来读缓存，发现缓存已经被删除，所以直接从数据库中读取，这时候由于线程1还没有更新完成，所以读到的是旧值，然后把旧值写入缓存
3. 线程1，根据估算的时间，sleep，由于sleep的时间大于线程2读数据+写缓存的时间，所以缓存被再次删除
4. 如果还有其他线程来读取缓存的话，就会再次从数据库中读取到最新值

![image-20220330164742346](IMG/面试话术.asserts/image-20220330164742346.png)

## 3.5 说一下redis中的事务

首先在redis中，每一条命令都是原子性的。而对于redis的事务而言，它其实并不能保证原子性，你可以将它看成是一个打包的批量执行脚本，如果中间某条指令执行失败了，并不会导致前面已经执行完了的指令回滚，也不会导致后续未执行的指令不执行。

redis的事务提供了一种将多个命令打包，然后一次性、有序地执行的机制。多个命令会被人入队到事务队列中，然后按照FIFO的顺序执行。

## 3.6 数据倾斜？

[Redis如何避免数据倾斜问题？-云社区-华为云 (huaweicloud.com)](https://bbs.huaweicloud.com/blogs/194535)

简单的来说，数据倾斜就是我们在计算数据的时候，数据不够分散，大量的数据集中到了一台或几台机器节点上，就导致这些节点负载过大，而其余的节点确是空闲等待中的，最终导致整体效率低下。

比如一些big key的存在，数据量比较大，在业务上举例：论坛中的大型持久盖楼活动；聊天室系统中的热门聊天室的消息列表。

big key解决办法：如果big key是个大JSON，通过mset，将该key的存储内容分散到各个实例中。如果是个大list，就将list进行拆分。

## 3.7 Redis的持久化

redis有两种持久化机制：RDB和AOF

**RDB持久化方式**：快照式持久化，通过创建快照的方式来获得存储在内存里面的数据在某个时间点上的副本。

在RDB持久化的时候，一般使用子进程进行持久化。**为什么使用子进程而不用子线程呢？**如果使用子线程去做备份的话，**没法保证数据的一致性**，因为子线程会共享内存，如果需要单独的内存则需要重新copy一份内存，这样对性能而言是非常不合适的。而使用fork的话，子进程虽然会和父进程共享内存空间的页帧，但是fork的时候会把共享的页帧设置为只可读状态，当任意一方尝试去写这个内存的时候，就产生一个异常，这时内核就把这个页复制到一个新的页帧中并标记为可写。这就是我们说的**copy on write**。另外子进程退出的时候也会释放掉只属于子进程的内存空间，这样就创建了一个完美的快照。

**AOF持久化方式：**默认没有开启该持久化方式，开启之后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入到内存缓存中，然后再刷盘到AOF文件里面。一般的话，可以选择每隔一秒钟同步一次AOF文件。

**拓展：Redis4.0的时候对于持久化机制进行了优化**，开始支持RDB和AOF的混合持久化（默认关闭），如果开启了持久化，AOF重写的时候就直接把RDB的内容写到AOF文件开头。这样做的好处就是可以结合RDB和AOF的优点，快速加载的同时避免丢失过多的数据。当然AOF里面的RDB部分是压缩格式，，可读性较差。

## 3.8 Redis的过期策略

**1、惰性删除：**只会在取出key的时候才进行过期检查，对CPU较为友好，但是如果该key一直不被访问，该key就会一直堆积在内存空间中。

**2、定期删除：**每隔一段时间抽取一批key执行删除过期key操作。

**3、定时删除：**在设置key的过期时间的同时，创建一个定时器，让定时器在key的过期时间来临时，立即执行key的删除操作。对CPU不友好。

## 3.9 内存淘汰机制

**1、volatile-lru**：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰。

**2、volatile-ttl：**从已设置过期时间的数据集中挑选即将要过期的数据淘汰。

**3、volatile-random**：从已设置过期时间的数据集中任意选择数据

**4、allkeys-lru**：从数据集中挑选最近最少使用的数据淘汰

**5、allkeys-random**：从数据集中任意选择数据淘汰

**6、no-eviction**：禁止驱逐数据，也就是当内存不足的时候，新写入会报错。

4.0版本之后新增如下两个内存淘汰机制

**7、volatile-lfu**：从已设置过期时间的数据集中挑选最不经常使用的数据淘汰

**8、allkeys-lfu**：从数据集中挑选最不经常使用的数据淘汰。

## 3.10 redis中有一亿条数据，其中10w个以某个固定的已知前缀开头，找到这些数据？

可以使用keys命令配合通配符找到这些keys，但是使用keys的话会导致redis阻塞一段时间，直到指令执行完毕。这个时候可以使用scan指令，它可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端去一次重就好了，但是整体所花费的时间会比keys指令长。

# **4. JVM相关面试题**

## 4.1 说一下垃圾回收器的三色标记

[面试官:你说你熟悉jvm?那你讲一下并发的可达性分析 - 掘金 (juejin.cn)](https://juejin.cn/post/6844904070788939790)

所谓的三色标记其实就是白色、黑色、灰色

- 白色：表示对象尚未被垃圾回收器访问过
- 黑色：表示对象已经被垃圾回收器访问过，而且这个对象所有的直接引用都已经扫描过
- 灰色：表示对象已经被垃圾回收器访问过，但是这个对象至少有一个引用还没有被扫描过。

由于垃圾回收器和用户线程是并发工作的，再加上被标记为黑色的对象就一定不会再次被扫描。因此并发标记就会产生两个问题：对象消亡和浮动垃圾

**对象消亡：**把原本存活的对象错误的标记为已消亡

1. 存在对象关系，A指向B，B指向C，但是A不指向C。
2. 将A标记后，并开始标记B
3. 刚开始标记对象B，但是还没开始标记对象B的下一个对象C，此时A是黑色，B是灰色，C是白色。如果此时将引用关系改为A指向了C，并且断开了B和C的联系，根据三色标记原则，对象C是白色的，就会被错误的当成垃圾进行回收。

总的来说，**对象消亡需要两个条件**

1. 赋值器插入了一条或多条从黑色对象指向白色对象的新引用
2. 赋值器删除了全部从灰色对象到白色对象的直接或间接引用。

**有两种方式解决，增量更新和原始快照**

- 增量更新：用的是写后屏障，记录了所有新增的引用关系。当黑色对象插入新的指向白色对象的引用之后，就会将这个新插入的引用记录下来，等并发扫描结束之后，再将这些记录过的引用关系的黑色对象为根，再次扫描一遍。
- 原始快照：当灰色对象要删除指向白色对象的引用关系时，就会将这个要删除的引用记录下来，在并发扫描结束之后，再将这些记录过的引用关系中的灰色对象为根，重新扫描一次。也就是无论引用关系删除与否，都会按照刚刚开始扫描的那一刻的对象图快照进行搜索。

**CMS基于增量更新，G1基于原始快照**

## 4.2 说一下类卸载，或者说怎么判断无用类

- 该类的所有的实例都已经被回收，即堆空间中不存在任何该类以及它的派生子类的实例。
- 该类的类加载器已经被回收
- 该类所对应的Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类。

## 4.3 新生代中的survival满了怎么办？

首先得看是否发生了内存泄漏，可以使用JVisualVM来判断。

- 首先看服务器的内存是否足够，如果足够，建议直接增大新生代空间。
- 如果内存不够的话，就可以压缩Eden区，但是Eden区的减少会增加MinorGC的次数，可以根据系统对延迟和吞吐量的指标来看是否符合。
- 如果调整了之后内存还是不够用，可以试着去增加服务器的内存，或者把负担分担到多个JVM实例上。

## 4.4 tomcat如何打破双亲委派机制的？

**双亲委派机制的优点：**

1. 保证了Java程序的稳定运行
2. 可以避免类的重复加载
3. 保证了Java核心API不被篡改。

[1.5 tomcat是如何打破双亲委派机制的? - 盛开的太阳 - 博客园 (cnblogs.com)](https://www.cnblogs.com/ITPower/p/13217145.html)

我们都知道，一个tomcat可以加载多个不同的应用程序，比如可以同时加载spring5和spring4两种应用程序。而在spring4和spring5中，有很多类类名相同，但是他们的实现不一样。如果没有打破双亲委派机制，就只能加载一份，也就无法同时加载多个不同的应用程序了。

在tomcat中，每一个项目打包成war包的时候，tomcat都会自动生成一个类加载器，专门用来加载这个war包，而这个类加载器就打破了双亲委派机制。webapp类加载器就不需要再让上级去加载，它自己就可以加载对应war包里面的class文件了。

**双亲委派机制时ClassLoader类中的loadClass方法来实现的，重写该方法用来打破双亲委派机制**

## 4.5 FullGC效果不好，每次只能从90-85-90，该怎么办

（如果是一次fullgc后，剩余对象不多。那么说明你eden区设置太小，导致短生命周期的对象进入了old区。如果一次fullgc后，old区回收率不大，那么说明old区太小。）

## 4.6 内存分配策略

- 新对象优先在Eden中分配

- 大对象直接进入老年代

- 长期存活的对象进入老年代，默认是15

- 动态对象年龄判定：如果survivor中相同年龄所有对象大小的总和大于s空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到15岁（HotSpot虚拟机遍历所有对象时，按照年龄从小到大对其所占有的空间进行累积，当累积的某个年龄大小超过了s区中的一半时，取出这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值）

  ```c
  uint ageTable::compute_tenuring_threshold(size_t survivor_capacity) {
      //survivor_capacity是survivor空间的大小
      size_t desired_survivor_size = (size_t)((((double)survivor_capacity)*TargetSurvivorRatio)/100);
      size_t total = 0;
      uint age = 1;
      while (age < table_size) {
          //sizes数组是每个年龄段对象大小
          total += sizes[age];
          if (total > desired_survivor_size) {
              break;
          }
          age++;
      }
      uint result = age < MaxTenuringThreshold ? age : MaxTenuringThreshold;
      ...
  }
  ```

- 空间分配担保：在执行MinorGC之前，JVM会先检查老年代的最大可连续空间是否大于新生代所有对象的总空间，如果大于，则认为这次GC是安全的；如果不大于，就看HandlePromotionFailure的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于就尝试进行一次MinorGC；如果小于，或者不允许担保，就要进行FullGC；**在JDK6 Update24之后，规则变为只要老年代的最大连续可用空间大于新生代对象总大小或者历次晋升的平均大小就会进行MinorGC，否则将进行FullGC。**

## 4.7 CPU占用过高的问题以及定位

[(34条消息) CPU占用过高的问题如何定位_weixin_32822759的博客-CSDN博客](https://blog.csdn.net/weixin_32822759/article/details/108170281)

1. 首先使用top命令查看正在执行进程的CPU使用率，内存使用率以及系统负载等信息。可以看到哪个进程id的进程cpu使用率最高，比如7139
2. 接下来就可以使用`top -p 7139 -H`，单独监视该进程下的所有线程信息，找到是哪个线程占用cpu最高。
3. 使用`jstack 指定线程id > xxx.txt`将线程的所有信息做dump记录。
4. 或者使用`jstat`相关命令
5. 或者使用`jmap`相关命令，或者使用`jvisualvm`可视化来看哪些对象用的最多，或者查看GC频率等

或者如果是业务线程CPU占用高，就检查代码，CPU狂算或者死循环；如果是GC线程，频繁FGC，读日志。如果每次回收不掉，内存泄漏

## 4.8 JVM如何对指令重排序，排序的依据?

[(34条消息) Java JVM（十二）：指令重排序_Sauron1的博客-CSDN博客_指令重排序](https://blog.csdn.net/pzxwhc/article/details/48984209)

**数据依赖性**：如果两个操作访问同一个变量，且这两个操作中有一个写操作，此时这两个操作之间就存在数据依赖性。

| 名称   | 示例代码      | 说明                         |
| ------ | ------------- | ---------------------------- |
| 写后读 | a = 1;  b = a | 写一个变量之后，再读这个变量 |
| 写后写 | a = 1;  a = 2 | 写一个变量之后，再写这个变量 |
| 读后写 | a = b; b = 1  | 读一个变量之后，再写这个变量 |

**在单线程环境中，JVM指令重排序会保证最终执行结果和代码顺序结果一致。并且处理器在执行重排序的过程中会考虑数据依赖性（如果不存在数据依赖性，编译器和处理器可能会对操作进行重排序）。但是多线程环境中，并不会保证。**

也就是说，as-if-serial语义：**不管怎么重排序，单线程下程序的执行结果不能被改变**

除了考虑数据依赖性以外，**还得考虑happens-before**

两个操作之间存在先行发生原则，并不意味着一定要按照该原则制定的顺序来执行。如果重排序之后的执行结果与按照先行发生原则来执行的结果一致，那么这种重排序并不非法。

## 4.9 了解堆内内存和堆外内存吗？

**堆内内存：**

1. 堆内内存 = 新生代 + 老年代 + 永久代

**堆外内存：**

1. 堆外内存就是把内存对象分配在Java虚拟机的堆以外的内存。
2. 使用`java.nio.DirectByteBuffer`对象进行堆外内存的管理和使用，该类会在创建对象时就分配堆外内存。
3. 元空间就是使用的堆外内存。
4. 对堆外内存的申请主要是通过成员变量`unsafe`来操作
5. **优点**：
   - 减少了垃圾回收机制
   - 加快了复制的速度：堆内在flush到远程时，会先复制到直接内存再发送，而堆外内存（本身就是物理机内存）几乎省略了该步骤
6. **缺点：**内存难以控制；使用堆外内存就间接失去了JVM管理内存的可能性，改由自己来管理，当发送内存溢出时排查起来十分困难。

## 4.10 Java8为什么用元空间代替永久代

- HotSpot JVM和JRockit VM进行了融合，而JRockit中没有永久代。
- 永久代内存经常不够用或发生内存溢出，这是因为在1.7的时候永久代的内存受JVM的内存限制，并且回收率较低，导致更容易溢出。而且PermGen分配多大的空间很难确定，它的大小依赖于很多因素，比如JVM加载的class总数、常量池的大小和方法的大小。

## 4.11 常见的性能调优

**1、降低MinorGC频率**

如果频繁发生MinorGC，可能是新生代的空间太小所导致的，因此就可以适当的增大新生代的空间。但是有人可能会说，增大了空间，难道不会导致单次MinorGC时间变长吗？值得注意的是，MinorGC分为扫描和复制。如果在堆内存中存在较多的长期存活的对象，此时增大年轻代空间，反而会增加MinorGC的时间；但是如果堆中的短期对象很多，那么扩容新生代，单次MinorGC反而不会显著增加，因为GC频率变低，就可能导致大量的对象已经过期了，存活的对象少了，在复制阶段的损耗也会大大减少。

**2、降低FullGC频率**

可以**减少创建大对象**，因为大对象会直接创建在老年代；即使被创建在了年轻代，由于年轻代内存空间有限，通过MinorGC之后也会进入到老年代。这种大对象过多很容易导致FullGC。因此可以将大对象拆解出来，只查询一些重要的字段，如果还需要其它字段辅助查看，再通过第二次查询显示剩余的字段。

**增大堆内存空间**

**3、选择合适的GC回收器**

如果对低延时有要求，就可以选择CMS；如果对吞吐量有要求，就选择Parallel Scavenge；如果内存较大，可以选用G1。

## 4.12 FullGC的触发条件

1. **调用System.gc()**，只是建议JVM执行，但是它不一定真正去执行，不建议使用这种方式。
2. **老年代空间不足**：大对象直接进入老年代，长期存活的对象进入老年代。尽量不要创建大对象以及数组。
3. **空间分配担保失败**：使用复制算法的MinorGC需要老年代的内存空间作为担保，如果担保失败会执行一次FullGC
4. **JDK1.7以及之前的永久代空间不足：**当系统要加载的类、反射的类和调用的方法较多时，可能会被占满。
5. **Concurrent Mode Failure**：使用CMS垃圾回收器的时候，用户线程并没有被中断，如果在回收过程中，老年代空间不足了（也有可能是浮动垃圾过多，或者碎片过多），便会报错，并且触发一次FullGC，临时采用serial old收集器来重新进行老年代的垃圾收集，这时也会整理碎片。

# **5. Spring相关面试题**

## ⭐5.1 Spring事务中的隔离级别？

Spring中的事务有五种，其实和MySQL的事务基本一致

|     隔离级别     | 脏读 | 不可重复读 | 幻读 |
| :--------------: | :--: | :--------: | :--: |
|     DEFAULT      |  -   |     -      |  -   |
| READ_UNCOMMITTED |  √   |     √      |  √   |
|  READ_COMMITTED  |  ×   |     √      |  √   |
| REPEATABLE_READ  |  ×   |     ×      |  √   |
|   SERIALIZABLE   |  ×   |     ×      |  ×   |

其中DEFAULT代表的含义就是**使用数据库默认的事务隔离级别**

如果Spring事务和MySQL的事务不一致的话，会默认使用Spring的事务，因为Spring的事务可以看作是MySQL的一种封装。

## 5.2 说一下Servlet或者Controller、Service是线程安全的吗

[Java面试题：Servlet是线程安全的吗？ - 陈树义 - 博客园 (cnblogs.com)](https://www.cnblogs.com/chanshuyi/p/5052426.html)

首先看Servlet，它是线程不安全的，当tomcat收到client的请求的时候，tomcat就会从线程池中取出一个线程，之后找到该请求对应的servlet对象并进行初始化，然后调用servlet中的service方法。注意的是每一个servlet对象在tomcat中只有一个实例，也就是单例模式。**如果servlet对象中有实例变量或者静态变量，并且service方法对其进行了操控，就会造成线程安全问题。**

同理，controller和service也是一样。但是对于大多数的bean来说，都是无状态的（不会保存数据），因此不用考虑线程安全问题。

## 5.3 Spring中的设计模式

- 工厂设计模式：Spring使用工厂模式通过BeanFactory、ApplicationContext创建bean对象，IOC的实现中其实也是用到了工厂 + 反射。
- 代理设计模式：AOP功能的实现。
- 单例设计模式：Bean默认都是单实例的
- 原型模式：Bean的prototype作用域
- 策略模式：Resource的实现类，针对不同的资源文件，实现了不同方式的资源获取策略。还有逆向生成就用了策略。
- 模板方法：将相同部分的代码放在父类中，而将不同的代码放入不同的子类中，用来解决代码重复的问题，比如RestTemplate、RedisTemplate
- 适配器模式：AOP的增强或通知（Advice）使用到了适配器模式、SpringMVC中也是用到了适配器模式适配Controller
- 桥接模式：根据客户的需求能够动态切换不同的数据源，比如我们项目需要连接多个数据库，客户在每次访问中根据需要会访问不同的数据库。
- 享元模式：数据库连接池

## 5.4 springmvc中参数如何映射的

使用@RequestParam

## 5.5 说一下@Transactional失效的场景

1. 注解用在非public修饰的方法上，不支持回滚
   - 原因就是SpringAOP在动态代理的时候，TransactionInterceptor（事务拦截器）会在目标方法前后进行拦截。DynamicAdvisedInterceptor（CglibAopProxy 的内部类）的 intercept 方法或 JdkDynamicAopProxy 的 invoke 方法会间接调用 AbstractFallbackTransactionAttributeSource 的 computeTransactionAttribute 方法，获取Transactional 注解的事务配置信息，
   - ![img](IMG/面试话术.asserts/20201126161911807.jpeg)
2. 注解的rollbackFor设置错误：**Spring默认抛出了未检查（unchecked）异常（继承自 RuntimeException 的异常）或者 Error才回滚事务，其他异常不会触发回滚事务**
3. 普通方法A调用同类中的事务方法B，方法B的事务不会生效：**这还是由于使用Spring AOP代理造成的，因为只有当事务方法被当前类以外的代码直接调用时，才会由Spring生成的代理对象来管理，进而由 TransactionInterceptor （事务拦截器）生成事务对象。**
4. 数据库引擎不支持事务
5. 如果异常被try-catch处理了，也不会回滚。

## ⭐5.6 说一下Spring事务的传播行为

1. **REQUIRED**：默认的传播机制，如果当前没有事务，就新建一个事务，如果已经存在在一个事务中，就加入到这个事务。
2. **SUPPORTS**：持当前事务，如果当前有事务，就以事务方式执行；如果当前没有事务，就以非事务方式执行
3. **MANDATORY**：使用当前的事务，且必须在一个已经有的事务中执行，如果当前不存在事务，就会抛出异常。
4. **REQUIRES_NEW**：不管是否存在事务，都创建一个新的事务，原来的挂起，新的执行完毕，继续执行老的事务。
5. **NOT_SUPPORTED**：以非事务方式执行，如果当前存在事务，就把当前事务挂起
6. **NEVER**：以非事务方式执行，且必须在一个没有的事务中执行，如果当前存在事务，则抛出异常【和MANDATORY相反】
7. **NESTED**：如果当前存在事务，则在嵌套事务内执行，如果当前没有事务，则执行与REQUIRED类似的操作。

## 5.7 如何实现一个IOC容器？

IOC即控制反转，是一种思想，意味着将你设计好的对象交给容器来控制，而不是传统的在你的对象内部直接控制。将对象之间的相互依赖关系交给IOC容器进行管理，并由IOC容器完成对象的注入，简化应用开发，把应用从复杂的依赖关系中解放出来。

1. 先准备一个基本的容器对象，包含一些map结构的集合，用来方便后续过程中存储具体的对象。
2. 进行配置文件的读取工作或注解的解析工作，将需要创建的bean对象都封装成BeanDefinition对象存储再容器中。
3. 容器将封装好的BeanDefinition对象通过反射的方式进行实例化，完成对象的初始化工作。
4. 进行对象的初始化操作，也就是给类中对应属性值进行设置，也就是依赖注入，完成整个对象的创建，变成一个完整的bean对象，存储再容器的某个map结构中。
5. 通过容器对象来获取对象，进行对象的获取和逻辑处理工作
6. 提供销毁操作，当对象不用或者容器关闭的时候将无用的对象进行销毁。

## 5.8 Spring的优势

1. Spring拥有强大的生态圈，将Spring扩展到不同的领域
2. IOC容器降低了业务对象替换的复杂性，提高了组件之间的解耦
3. AOP支持允许将一些通用任务比如安全、事务、日志等进行集中处理，从而提供更好的复用
4. 高度开放性和可扩展性
5. 低侵入设计，代码的污染极低。
6. 拥有一个庞大而且活跃的社区，提供不同范围的，真实用户的持续反馈。这也帮助Spring不断改进、不断发展

## 5.9 BeanFactory和ApplicationContext

**相同：**

1. 两者都是Spring提供的IOC容器，它们都可以用来配置XML属性，也支持属性的自动注入。
2. 都可以通过getBean("bean name")来获取bean。

**不同点：**

1. 对于BeanFactory来说，采用延迟加载形式注入bean，只有使用getbean时才会对该bean进行加载实例化，如果某个Bean的某一个属性没有注入，只有等到第一次调用getBean获取该Bean的时候才会抛出异常；而后者在容器启动时一次性创建了所有的Bean。
2. 前者不支持国际化，即i18n，后者支持
3. 前者提供基本的IOC和DI功能，后者提供高级功能，比如AOP。
4. ApplicationContext是BeanFactory的子接口。

**什么时候用哪个？**

**延迟实例化优点：**应用启动的时候占用资源很少，对于资源要求较高的应用，比较有优势。

**不延迟实例化优点：**所有的Bean在启动的时候就已经加载了，系统运行速度较快。又因为如此，我们能在系统启动的时候发现系统中的配置问题。建立Web应用。

## 5.10 bean的生命周期

![Spring Bean 生命周期](IMG/面试话术.asserts/b5d264565657a5395c2781081a7483e1.jpg)

初始化->设置属性->setBeanName（如何实现了BeanNameAware接口）->setBeanFactory (如果实现了BeanFactoryAware接口)->setApplicationContext(如果实现了ApplicationContextAware接口)->预初始化方法postProcessorBeforeInitialization(如果实现了BeanPostProcessor接口)->afterPropertiesSet方法（如果实现了InitializingBean接口）-> 调用自定义的方法init-method（如果指定了） -> 初始化之后的方法postProcessorAfterInitialization(如果实现了BeanPostProcessor接口)->最后是destroy（如果实现了DisposableBean） 和destroy-method方法。

1. 解析类得到BeanDefinition
2. 如果有多个构造方法，则要推断构造方法
3. 确定好构造方法之后，进行实例化得到一个对象
4. 进行属性填充，设置对象属性。
5. 回调Aware方法，比如BeanNameAware、BeanFactoryAware
6. 调用BeanPostProcessor的初始化前的方法，然后调用初始化方法，接着调用初始化后的方法（这里会AOP）
7. 如果当前创建的bean是单例的，就会将bean放到单例池
8. 此时Bean就可以被使用了
9. 在销毁的时候看看Bean有没有实现DisposableBean接口或者使用destory-method声明了销毁方法。

## 5.11 IOC

**IOC即控制反转**，它将在程序中手动创建对象的控制权交给了Spring框架来管理。Spring IOC负责创建对象，管理对象（通过DI），装配对象，配置对象，并且管理这些对象的整个生命周期。

**DI即依赖注入**，就是IOC容器在运行期间，动态地将某种依赖关系注入到对象中。

通过引入IOC容器，利用依赖注入的方式，来实现对象之间的解耦。

**作用：**

- 对象之间的耦合度或者说依赖程度降低。比如我们如果针对于UserDao接口开发了它的实现类UserDaoImpl，然后传统方式在用到该实现类的地方都去new UserDaoImpl，但是如果我们想去使用新的实现类NewUserDaoImpl，就得在每个使用到UserDaoImpl的地方去修改代码，这就非常的麻烦。
- 资源变得容易管理，它支持单例和原型。
- 简化开发，让程序员更加的专注于业务的实现。

**实现原理：工厂模式 + 反射机制**

```java
interface Fruit {
    void eat();
}

class Apple implements Fruit {
    @Override
    public void eat() {
        System.out.println("我吃苹果！");
    }
}

class FruitFactory {
    public static Fruit getInstance(String className) {
        Fruit fruit = null;
        try {
            fruit = (Fruit)Class.forName(className).newInstance();
        } catch (Exception e) {
            e.printStackTrace();
        }
        return fruit;
    }
}

public class Test{
    public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException {
        Fruit apple = FruitFactory.getInstance("Apple");
        if (apple != null) {
            apple.eat();
        }
    }
}
```

## 5.12 AOP

### 1. 概念

AOP一般被称为面向切面编程，它能够将那些与业务无关，却是业务所共同调用的逻辑或责任，比如事务处理、日志管理、权限控制等。AOP能够减少系统的重复代码，降低模块之间的耦合度，并有利于未来的扩展性和维护性。

### 2. 原理

Spring AOP底层是使用动态代理的，又可以分为JDK动态代理和Cglib动态代理。

### 3. Spring AOP和AspectJ AOP

AOP的实现是基于代理的，而代理又分为动态代理和静态代理。其中Spring AOP是动态代理，AspectJ AOP是静态代理。

**SpringAOP属于运行时增强，AspectJAOP属于编译时增强**

- 前者不会去修改字节码，而是每次运行时在内存中临时为方法生成一个AOP对象，这个对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。
- 后者是基于字节码操作的，它会在编译阶段生成AOP代理类，因此也称为编译时增强，他会在编译阶段将AspectJ（切面）织入到Java字节码中，运行的时候就是增强之后的AOP对象。

### 4. JDK动态代理和Cglib

JDK动态代理只能代理实现了某个接口的类或者直接代理该接口，而CGLIB可以代理未实现任何接口的类。同时CGLIB是通过生成一个被代理类的子类来拦截被代理类的方法调用，因此不能代理声明为final类型的类和方法，private修饰的方法也不行。

## 5.13 @Autowired和@Resource

这两个注解都是用于依赖注入。

其中@Autowired默认是按照类型装配注入的，如果想要按名称注入，就得配合@Qualifier

而Resource是java中的注解，默认按照名称来装配注入，只有当找不到与名称匹配的bean才会按照类型来装配注入。

## 5.14 Spring中Bean的自动装配

bean的自动装配指的是bean的属性值在进行注入的时候通过某种特定的规则和方式去容器中查找，并设置到具体的对象属性中，它有五种方式：

1. no：缺省情况下，自动配置是通过ref属性手动设定，在项目中最常用
2. byName：根据属性名称自动装配。如果一个bean的名称和其它bean属性的名称是一样的，将会自动装配它。
3. byType：根据类型自动装配
4. constructor：在构造函数参数的byType方式
5. autodetect：如果找到默认的构造函数，使用构造函数，否者按类型自动装配。

## 5.15 SpringMVC的工作流程

![image-20220409191239028](IMG/面试话术.asserts/image-20220409191239028.png)

1、用户向服务器发送请求，这个请求会先到中央控制器DispatcherServlet

2、中央控制器接收到请求后会调用HandlerMapper处理器映射器。由此得知该请求该由哪个Controller来处理

3、中央控制器调用HandlerAdapter处理器适配器，告诉处理器适配器应该要去执行哪个Controller

4、处理器适配器HandlerAdapter去执行Controller并得到ModelAndView，然后层层返回给DispatcherServlet

5、中央控制器将ModelAndView交给ViewResolver视图解析器解析视图，然后返回真正的视图。

6、中央控制器将模型数据填充到视图中，然后将结果响应给用户。

## 5.16 spring怎么根据不同的环境条件注入不同的对象（比如win和linux）

[(34条消息) Spring之条件注解@Conditional，条件（系统）不同注入的对象也不同。_Small-Young的博客-CSDN博客_条件注入](https://blog.csdn.net/yjc_1111/article/details/78807129)

我们可以使用注解**@Conditional**，大致就是我们先定义一个接口TomcatService，里面包含两个方法：getTomcatStartupPath、getTomcatShutdownPath。然后可以搞两个不同的实现类去实现这个接口，比如WindowsTomcatService、LinuxTomcatService。下一步就实现两个不同的Condition的子类，然后就可以在注册TomcatService的时候，根据不同的Conditional去注册不同的TomcatService。

```java
public class WindowsCondition implements Condition {
    public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) {
        return context.getEnvironment().getProperty("os.name").contains("Windows");
    }
}

public class LinuxCondition implements Condition {
    public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) {
        return context.getEnvironment().getProperty("os.name").contains("Linux");
    }
}

@Configuration
public class ConditionConfig {
    @Bean
    @Conditional(WindowsCondition.class)
    public TomcatService wndowsListService() {
        return new WindowsTomcatServiceImpl();
    }
    
    @Bean
    @Conditional(LinuxCondition.class)
    public TomcatService wndowsListService() {
        return new LinuxTomcatServiceImpl();
    }
}
```

# **6. SpringBoot相关面试题**

## 6.1 说一下SpringBoot的加载过程

![img](IMG/面试话术.asserts/20200806150352650.png)

大体启动流程分为三个部分：

1. 进行SpringApplication的初始化模块，配置一些基本的环境变量、资源、构造器、监听器
2. 实现了应用具体的启动方案，包括启动流程的监听模块、加载配置环境模块、及核心的创建上下文环境模块
3. 自动化配置模块，该模块作为springboot自动配置的核心。

一开始会调用SpringApplication.run方法，它首先会初始化SpringApplication对象，初始化的时候会设置ApplicationContextInitializer和ApplicationListener对象，之后会调用内部的run方法，发布SpringApplicationRunListeners starting事件，准备相关配置环境，初始化ApplicationContext，然后调用prepareContext设置环境加载一部分bean如mainApplication等，最后会调用refreshContext创建BeanFactory容器，加载并初始化bean，执行Bean的后置处理等。

## 6.2 说一下拦截器的使用和底层原理

首先我们可以实现HandlerInterceptor接口，并在里面实现preHandler方法和afterComplete方法。接着去WebMvcConfigurer中配置好拦截器

拦截器的底层原理大概是，找出处理该请求的所有拦截器，并根据责任链模式一次执行拦截器，只有上一个拦截器返回了true才能执行下一个拦截器，否则不让被拦截的方法执行。 

## 6.3 说一下自动装配

SpringBoot通过@EnableAutoConfiguration注解开启自动装配功能，加载spring.factories中注册的各种AutoConfiguration类，当某个AutoConfiguration类满足其注解@Conditional指定的生效条件时，实例化该AutoConfiguration类中定义的Bean（组件等），并注入Spring容器中，就可以完成自动配置。

# **7. JUC相关面试题**

## 7.1 JDK15为什么取消偏向锁

- 偏向锁导致synchronized子系统的代码复杂度过高，并影响其它的子系统，造成代码的维护和升级困难。
- 偏向锁带来的性能提升从整体来看并没有带来太多的收益，因为偏向锁的撤销成本过高，需要等待全局安全点，并且还需要暂停线程来做锁的撤销。

## 7.2 threadlocal在父子线程间是否可见，父子线程间如何通信

[(34条消息) 【并发编程】（十一）父子线程数据共享——InheritableThreadLocal原理_语言日记-CSDN博客_父子线程怎么共享数据](https://blog.csdn.net/qq_38249409/article/details/114300384?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-2-114300384.pc_agg_new_rank&utm_term=什么是父子线程&spm=1000.2123.3001.4430)

## ⭐7.3 线程池相关知识

### 0. 线程池优点

1. **线程复用**：降低资源消耗，通过重复利用自己创建的线程降低线程创建和销毁造成的损耗
2. **提高响应速度：**因为线程池中的线程数没有超过线程池的最大上限时，有的线程处于正在等待分配任务的状态，当任务到达时，任务可以不需要等到线程创建就能立即执行。
3. **管理线程：**提高线程的可管理性。使用线程池可以对线程进行统一分配、调优和监控。
4. **控制最大并发数**

### 1. 线程池种类

- **newCachedThreadPool**：线程池的大小不固定，可灵活回收空闲线程，若无可回收，则新建线程。****
- **newFixedThreadPool**：固定大小的线程池，当有新的任务提交，线程池中如果有空闲线程，则立即执行，否则新的任务会被缓存在一个任务队列中，等待线程池释放空闲线程。
- **newScheduledThreadPool**：定时线程池，支持定时及周期性任务执行。
- **newSingleThreadExecutor**：只创建一个线程，它只会用唯一的工作线程来执行任务，保证所有任务按顺序指定执行。

### 2. 线程池的拒绝策略

1. **ThreadPoolExecutor.AbortPolicy**：默认的策略。即丢弃并抛出RejectedExecutionException异常。
2. **ThreadPoolExecutor.DiscardPolicy**：丢弃任务，但是不抛出异常。
3. **DiscardOldestPolicy**：丢弃队列最前面的任务，然后重新提交被拒绝的任务，不抛出异常。
4. **CallerRunsPolicy**：由调用线程处理该任务，不会丢弃任务，也不抛出异常。

### 3. 线程池常见的阻塞队列

- **ArrayBlockingQueue**：是一个我们常用的典型的有界队列，其内部的实现是基于数组来实现的。
- **LinkedBlockingQueue**：由链表实现的队列，队列的长度是Integer.MAX_VALUE，基本上是可以任务是无界队列
- **SynchronousQueue**：是一个不存储任何元素的阻塞队列，每一个put操作都必须等待take操作，否则不能添加元素，同时它也支持公平锁和非公平锁。
- **PriorityBlockingQueue**：支持优先级排序的无界阻塞队列，插入的对象必须是可比较大小的，否则会报错
- **DelayQueue**：一个实现PriorityBlockingQueue的延迟获取的无界队列。具有延迟的功能。

### 4. 线程池的运行原理

1. 在创建了线程池后，等待提交过来的任务请求
2. 当调用execute方法添加一个请求任务时，线程池会做如下判断：
   1. 如果正在运行的线程数小于corePoolSize，那么马上创建线程运行这个任务
   2. 如果正在运行的线程数大于或等于corePoolSize，那么将这个任务放入队列
   3. 如果这时候队列满了且正在运行的线程数还小于maximumPoolSize，那么还是要创建非核心线程立即运行这个任务
   4. 如果队列满了且正在运行的线程数量大于或等于maximumPoolSize，那么线程池会启动饱和拒绝策略来执行
3. 当一个线程完成任务时，他会从队列中取下一个任务执行
4. 当一个线程无事可做超过一定的时间（keepAliveTime）时，线程池会判断：如果当前运行的线程数大于corePoolSize，那么这个线程就会被停掉

### 5. 如何合理设置线程池的核心参数

当线程池中核心线程数过大时，线程和线程之间会争夺CPU资源，会导致频繁上下文切换，过多的上下文切换会消耗CPU，增加线程的执行时间，影响了整体的执行效率。

当线程池中核心线程数过小时，如果同一时间有大量任务需要处理，可能会导致大量任务在任务队列中排队等待执行，甚至可能会执行拒绝策略，或者大量任务堆积在任务队列导致内存溢出OOM。

对于IO密集型（MySQL数据库、文件的读写、网络通信等任务）：**线程数 = CPU核数 * （1  + IO耗时 / CPU耗时）**或者**CPU核数 * 2**。可以理解为当线程A正在执行IO操作的时候，另外的IO/CPU的线程数就可以执行完自己的CPU计算。因为这种情况任务最大线程数一般都会大于CPU核心数很多倍，因为IO读写速度相比于CPU的读写速度而言是比较慢的，如果我们设置过少的线程数就可能导致CPU资源的浪费，而如果我们设置更多的线程数，那么当一部分线程正在等待IO的时候，他们此时并不需要CPU来计算，那么另外的线程便可以利用CPU去执行其他的任务，互不影响，这样的话在任务队列中等待的任务就会减少，可以更好的利用资源。

对于CPU密集型（加解密、压缩、计算）：**CPU核数**，这样可以充分利用所有CPU的核心。如果线程数远远超出了CPU核心数量，反而会使任务效率下降，因为频繁的切换线程也是需要消耗时间的（因为此时CPU每个核心几乎都是满负荷运行）。不过在工程上，**线程数的数量一般会设置为CPU核数 + 1**，这样的化，当线程因为偶尔的内存页失效或其它原因导致阻塞时，这个额外的线程可以顶上，从而保证CPU利用率。

**当然过少的线程会使整体性能降低，过多的线程也会消耗内存等其他资源，所以想要准确的话，可以进行压测，监控JVM的线程情况以及CPU的负载情况，根据实际情况衡量应该创建的线程数，合理并充分利用资源。**

**极端情况下当任务队列满了之后，继续增加非核心线程，直到达到最大线程数，那么效率其实会逐渐降低**

把握住一条原则：**将硬件的性能发挥到极致**，在实际场景中，IO耗时和CPU耗时的比值是一个关键参数，但这个参数其实是动态的，如果要估算这个参数，需要在各种不同的场景下压测来验证我们的估计。需要重点关注CPU、IO设备的利用率和性能指标（响应时间、吞吐量）之间的关系。

### 6. 为什么阿里不建议使用Executors创建线程池？

- 对于**newFixedThreadPool和newSingleThreadExector**来说，它们底层都是用的**LinkedBlockingQueue**，**当添加任务的速度大于线程池处理任务的速度，可能会在队列堆积大量的请求，消耗很大的内存，甚至导致OOM。**
- 对于**newCachedThreadPool和newScheduledThreadPool**来说，它们的**最大线程数都是Integer.MAX_VALUE**；当添加任务的速度大于线程池处理任务的速度，可能会创建大量的线程，消耗资源，甚至导致OOM。

## 7.4 什么是协程

[什么是协程？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/172471249)

协程是一种协作式的用户态线程

1. 线程和进程是抢占式执行的，意思是系统帮我们自动快速切换线程和进程来让我们感觉同步运行的感觉，这种切换动作由系统自动完成。
2. 协作式执行说的就是，**想要切换线程，必须用户手动来切换**

协程为什么那么快原因就是因为，无需系统自动切换（系统自动切换会浪费很多的资源），而协程是我们用户手动切换，而且是在同一个栈上执行，速度就会非常快而且省资源。  

   但是，协程有他自己的问题：  **协程只能有一个进程，一个线程在跑，一旦发生IO阻塞，这个程序就会卡住。**所以我们要使用协程之前，必须要保证我们所有的**IO都必须是非阻塞的**  

**协程调用阻塞IO操作的时候，操作系统会让线程进入阻塞状态，当前的协程和其它绑定在该线程之上的协程都会陷入阻塞而得不到调度，这往往是不能接受的。**

   协程的真正目的其实并不是为了解决高并发而存在的，而是为了解决无限回调而存在的；  

   协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。

## 7.5 run( )和start( )

**区别：**

1. run方法被称为线程体，每个线程执行的时候都是执行run方法里面的代码。而通过调用Thread中的start方法来启动一个线程。
2. start方法用于启动线程，而run方法用于执行线程的运行时代码。run可以重复调用，而start只能调用一次。
3. 调用start方法无需等待run方法执行完毕，可以直接继续执行其它的代码，此时线程是就绪态，并没有运行。然后通过此thread类调用run方法来完成其运行态，run方法运行结束，此线程终止，然后CPU调度其它的线程。

**为什么调用start方法的时候会执行run方法，为什么不能直接调用run方法？**

1. new一个Thread会让该线程进行新建态。调用start方法会启动一个线程并使线程进入了就绪态，当该线程分配到了CPU的时间片之后就可以开始运行。start会执行线程的相应准备工作，然后自动执行run方法里面的内容，这是真正的多线程运行。
2. 如果直接调用run方法，会把run方法当成一个main线程下的普通方法执行。

## 7.6 CAS为什么这么快？

1. CAS，比较并交换，如果内存中的值与预期原值相匹配，那么处理器就会自动将该位置的值更新为新的值。否则处理器不做任何操作。
2. 白话：我认为V的值一定等于A，如果是那就将V的值更新为B，否则不修改并告诉V的值实际是多少。
3. CAS的实现并不是简单的代码层面控制的，**而是需要硬件的支持**，因此在不同体系的架构中执行的性能差异很大。 **现代大多数处理器都是从硬件层面通过一些列指令实现CAS同步原语，进而操纵系统和JVM可以直接使用这些指令实现锁和并发的数据结构**
4. **JVM对CAS的支持**：由于Java程序运行在JVM上，所以应对不同的硬件体系架构的处理则需要JVM来实现。在不支持CAS操作的硬件上，JVM将使用自旋锁来实现。

## 7.7 为什么还要有非公平锁

1. 首先恢复挂起的线程到真正获取到锁还是有一定的时间差的。
2. 假设线程A持有一个锁，并且线程B请求这个锁。由于锁被A持有，因此B将被挂起。当A释放锁之后，B将被唤醒，然后B会再次尝试获取这个锁。与此同时，线程C也来请求这个锁，那么C很有可能在B被完全唤醒之前获得该锁，以及使用并释放该锁。因此非公平锁能更充分的利用CPU等待时间片，尽量减少CPU的空闲时间。
3. 举例：比如我在排队加油，我是第二个，但是我一直在玩手机，忘了到我了，然后后面的人就先行加油。

## 7.8 AQS原理

AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。  

**AQS 定义两种资源共享方式**  

- Exclusive（独占）：只有一个线程能执行，如 ReentrantLock。又可分为公平锁和非公平锁： 

- - 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 
  - 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 

- Share（共享）：多个线程可同时执行，如CountDownLatch、Semaphore、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。 

ReentrantReadWriteLock   可以看成是组合式，因为   ReentrantReadWriteLock   也就是读写锁允许多个线程同时对某一资源进行读。  

不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS 已经在顶层实现好了。  

1. 非公平锁在调用 lock 后，首先就会调用 CAS 进行一次抢锁，如果这个时候恰巧锁没有被占用，那么直接就获取到锁返回了。
2. 非公平锁在 CAS 失败后，和公平锁一样都会进入到 tryAcquire 方法，在 tryAcquire 方法中，如果发现锁这个时候被释放了（state == 0），非公平锁会直接 CAS 抢锁，但是公平锁会判断等待队列是否有线程处于等待状态，如果有则不去抢锁，乖乖排到后面。

## 7.9 synchronized和volatile的区别

1. sync表示只有一个线程可以获取作用对象的锁，执行代码，阻塞其余的线程；volatile表示变量在CPU寄存器中是不确定的，必须从主存中读取，保证多线程环境下变量的可见性，禁止指令重排。
2. volatile是变量修饰符，而sync可以作用与静态方法、方法和代码块。
3. volatile不会造成线程的阻塞
4. volatile标记的变量不会被编译器优化
5. volatile是线程同步的轻量级实现，性能比sync要高，但是volatile只能用于变量，而且volatile无法保证原子性。sync有了锁升级和各种优化，比如锁粗化和锁消除。

## 7.10 举一举线程不安全的例子

比如多个线程同时操作i++，或者多个线程共享一个HashMap，导致在1.7的时候会产生环形链或者数据覆盖，而1.8的时候利用尾插法解决了环形链，但是还是会有数据覆盖。

**并发三要素：**

1. 原子性：指的是一个或多个操作要么全部执行成功，要么全部执行失败。
2. 可见性：一个线程对共享变量的修改，另一个线程能够马上看得到。
3. 有序性：程序执行的顺序按照代码的先后顺序执行。（处理器可能会对执行进行重排序）

**出现线程安全问题的原因：**

1. 多线程的切换带来的原子性问题
2. JMM内存模型，即缓存带来的可见性问题
3. 编译优化带来的有序性问题（执行重排）

**解决办法：**

1. JDK Atomic开头的原子类、synchronized、Lock、CAS自选，解决原子性问题
2. volatile、sync、lock解决可见性问题
3. happens-before解决有序性问题。

## 7.11 synchronized底层实现原理

可以从两方面来回答：

**1、JVM层面**

如果使用同步代码块，底层是通过monitorenter来获取锁，使用monitorexit来释放锁。但是注意的是**同步代码块方式的sync会有两个monitorexit**，这是问题：

防止在同步代码块中线程因异常退出，而锁没有得到释放，这必然会导致死锁。因此最后一个monitorexit是保证在异常情况下，锁也可以得到释放，避免死锁。

而如果sync修饰方法，则字节码文件中没有monitorenter和monitorexit，而是会有个标识，`ACC_SYNCHRONIZED`；如果sync修饰静态方法，则还会多一个`ACC_STATIC`。

**2、底层层面**

每个锁其实都对应着一个monitor对象，多个线程想要访问共享资源的时候，就必须获取该锁的monitor，而这个monitor在c++层面是由ObjectMonitor实现的，每个对象都会有一个monitor与之关联。在ObjectMonitor中就维护了计数器和指向持有该monitor的线程的指针。

**synchronized可重入锁原理：**

每个锁底层都维护着一个计数器和一个指向只有该锁的线程的指针，当线程获取该锁的时候，计数器加一，当释放锁的时候，计数器减一。当计数器为零，标识该锁没有被任何线程占有。

## 7.12 synchronized和Lock

1. sync是Java中的关键字，在JVM层面；而Lock是Java中的一个类。
2. sync可以给方法、静态方法、代码块加锁，而Lock只能给代码块加锁。
3. sync不需要手动的释放锁，使用简单，而Lock需要手动释放锁。
4. Lock支持精准唤醒，而sync只能随机唤醒或者全部唤醒。

## 7.13 为什么wait、notify等方法需要在sync内部使用

当一个线程正在某个对象的同步方法中运行时调用了这个对象的wait方法，那么这个线程将释放对象的独占锁并放入这个对象的等待队列中。注意的是wait方法会强制当前线程释放对象锁，这就意味着**在调用某对象的wait方法之前，当前线程必须已经获得该对象的锁。**因此wait方法必须在sync中使用。

当线程调用某对象的notify或notifyall方法时，任意一个或者所有的在该对象的waitSet中的线程，将会被转移到该对象的EntryList中，接着这些队列将会竞争该对象的锁，最终获得锁的线程继续执行。如果没有线程在该对象的等待队列中等待获得锁，那么notify或notifyAll将不起任何作用。在调用对象的notify或notifyAll方法之前，调用线程必须已经得到该对象的锁，因此必须在sync内部使用。

拿生产者消费者的例子进一步说明：生产者向缓冲区中写入数据，消费者从缓冲区中读取数据。消费者线程需要等待直到生产者完成一次写入操作，生产者需要等待消费者完成一次读取操作。假如wait、notify、notifyAll不需要加锁就能够被调用，那么此时消费者线程调用wait，然后正在进入等待队列（可能还未进入，只是正在进入），在同一时刻，生产者调用notify打算向消费者线程通知状态改变，那么此时消费者线程将错过这个通知并一直阻塞。而生产者认为自己已经发出了通知，一直在等待消费者将自己唤醒，这就出现问题了。

# **8. 不知道分类面试题**

## 8.1 说一下一致性哈希

[白话解析：一致性哈希算法 consistent hashing-朱双印博客 (zsythink.net)](https://www.zsythink.net/archives/1182)

场景假设：如果我们有三台服务器用来缓存图片，那么就可以使用哈希算法以图片的名称计算hash，并且将其映射到这三台服务器上。这就可以让图片近乎均匀的缓存在这三台服务器上。

但是如果有一天，有一台服务器要下了，或者要增加一台新的服务器，这时所有的图片缓存都需要进行hash重算，就会导致所有的缓存都失效，也就是造成缓存雪崩问题，导致整个系统的压力过大而崩溃。而且就算不崩溃，几乎所有的缓存的位置都会发生变化，这也会对性能产生影响。

这时候一致性哈希算法就应运而生。

一致性哈希首先会假设有一个hash环。我们可以对服务器的IP地址进行取模运算，公式如下：

**hash（服务器A的IP地址）%2^32**

这样就会将这三台服务器放在hash环中的某个位置：（理想状况）


![image-20220309094122453](IMG/面试话术.asserts/image-20220309094122453.png)

同时，对于每一张图片，我们也同样计算它的位置：**hash（图片名称）%2^32**，

![IMG/面试话术.asserts/image-20220309094224633.png](IMG/面试话术.assets/image-20220309094224633.png)

我们以顺时针的方式来判断该图片应该属于哪一个服务器。上图的示例就是图片1和图片2缓存到服务器A，图片3缓存到服务器B，图片4缓存到服务器C上。

如果此时B给宕机了，那么只需要将图片3给缓存到服务器C就行了，其余的图片就不需要改变。这就只会影响一部分的缓存，从而减少系统的压力。

但是其实上面是理想的情况，我们还可能造成**hash环的倾斜**

实际计算hash的过程中，不会分布的那么均匀，就可能导致服务器之间在hash环上的位置非常的窄小，就会导致缓存的数据分布不均匀：

![IMG/面试话术.asserts/image-20220309094541586.png](IMG/面试话术.assets/image-20220309094541586.png)

**这就需要虚拟节点了**

我们凭空的让服务器节点多起来，既然没有多余的真正的物理服务器节点，我们就只能将现有的物理节点通过虚拟的方法复制出来，这些由实际节点虚拟复制而来的节点被称为”虚拟节点”。

![IMG/面试话术.asserts/image-20220309094606629.png](IMG/面试话术.assets/image-20220309094606629.png)

**“虚拟节点”是”实际节点”（实际的物理服务器）在hash环上的复制品,一个实际节点可以对应多个虚拟节点。**虚拟节点越多，hash环上的节点就越多，缓存被均匀分布的概率就越大。

## 8.2 什么是倒排索引

倒排索引源于实际应用中需要根据属性的值来查找记录。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index)。

## 8.3 负载均衡算法的实现

[几种简单的负载均衡算法及其Java代码实现 - 五月的仓颉 - 博客园 (cnblogs.com)](https://www.cnblogs.com/xrq730/p/5154340.html)

1. **轮询法：**它试图做到请求转移的绝对均衡。但是同时也需要付出一定代价，因为为了保证并发下的均衡，可能得引入悲观锁或者CAS。
2. **随机法：**基于概率统计的理论，吞吐量越大，随机算法的效果越接近于轮询算法的效果。
3. **源地址哈希法**：获取客户端访问的IP地址值，通过哈希函数计算得到一个哈希值，用该值对服务器列表的大小进行取模运算。
4. **加权轮询**：不同的服务器可能配置不同，因此可以给配置高、负载低的机器赋予更大的权重。
5. **最小连接数**：以后端服务器的视角来观察系统的负载，而不是请求发起方来观察。该算法比较灵活，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，因此该算法就会动态的选取其中当前积压连接数最少的一台服务器来处理当前请求，尽可能提高后端服务器的利用效率，将负载合理地分流到每一台机器。

## 8.4 CPU的原子操作

[(34条消息) CPU实现原子操作的方法_盐焗咸鱼的博客-CSDN博客_cpu原子操作](https://blog.csdn.net/qq_33215865/article/details/88562456)

首先对于单核CPU来说，所有的时间都是串行，执行完第一个才会去执行第二个，每个指令都是原子的。

对于多核CPU来说：

1. CAS：它会检测现在内存中的值是不是符合预期值，如果符合就更新为新值，否则就丢弃新值
2. 使用总线锁：用来锁住某一个共享内存，当一个CPU要对内存进行操作的时候，会加上总线锁，限制其它cpu对共享内存操作。
3. 使用缓存锁：使用总线锁会锁定cpu与内存的通信，所以开销很大。而缓存锁在一个cpu进行回写时，会使用缓存一致性机制来保护内部内存，当其它处理器回写已被锁定的缓存行的数据时缓存行无效。

## 8.5 Hash冲突的解决办法

[解决哈希冲突的常用方法分析 - 简书 (jianshu.com)](https://www.jianshu.com/p/4d3cb99d7580)

1. **拉链法**
2. **开放地址法：**从发生冲突的单元起，按照一定的次序，从哈希表找到一个空闲的单元，然后将发生哈希冲突的元素存入到该单元。
3. **再哈希法：**同时构造多个不同的哈希函数。当H1=RH1（key）发生冲突时，再用H2 = RH2（key）进行计算，直到冲突不再发生，这种方法不易产生聚集，但是增加了计算的时间。
4. **建立公共溢出区：**将哈希表分为基本表和溢出表，凡是和基本表发生冲突的元素，一律填入溢出表。

## 8.6 git常用命令

![img](IMG/面试话术.asserts/011500266295799.jpg)

## 8.7 典型的对称加密和非对称加密算法

> 对称加密算法 AES、DES、3DES

DES是一种分组数据加密技术（先将数据分成固定长度的小数据块，之后进行加密），速度较快，适合于大量数据加密。3DES是一种基于DES的加密算法，使用3个不同密钥对同一个分组数据块进行3次加密，使密文强度更高。

相对于DES和3DES来说，AES算法有着更高的速度和资源使用效率，安全级别更高，被称为下一代加密算法

> 非对称加密算法：RSA、DSA、ECC

RSA和DSA的安全性及其各方面性能都差不多，而ECC较之则有着很多的性能优越，包括处理速度，带宽要求，存储空间等

# **9. Java基础**

## 9.1 static可以修饰什么，可以修饰类吗？

static一般用来修饰成员变量和方法，也可以修饰类，但是普通类不允许声明为静态的，只有内部类可以。

**追问1：静态内部类的特点**

1. 静态内部类可以用静态成员变量和静态方法（普通内部类不能拥有）
2. 可以直接创建实例，不需要先创建外部类。`Test.StaticInner staticInner = new Test.StaticInner();`，而普通内部类需要先创建外部类：`Test.Inner inner1 = new Test().new Inner();`
3. 只可以直接访问外部类的静态成员，不可以直接访问外部类的非静态成员，需要传入外部类引用的方式才能使用。
4. 不持有外部类的引用（普通内部类持有）

**追问2：什么时候会用到静态内部类**

1. 内部类与所在的外部类有一定的关系，往往只有该外部内会调用此内部类，就无需专门用一个Java文件来存放这个类。


## 9.2 Java为什么不支持多继承

[(34条消息) Java不支持多继承的原因_u014133299的博客-CSDN博客_java为什么不支持多继承](https://blog.csdn.net/u014133299/article/details/77571912)

首先Java是一门面向对象的语言，从语义上来说，一个类继承了另一个类，那么这两个类就可以理解为父子关系，一个儿子只能有一个父亲。

再者多继承容易产生二义性：比如一个抽象类Animal，有一个抽象方法eat。此时有两个类分别继承了这个Animal类，Bird和Horse，但是同时又有一个类Pegasus继承了Horse和Bird类，当Pegasus执行eat方法时，到底是执行Bird的还是Horse的呢？这就产生了歧义。【致命方块】

为何接口不会产生致命方块问题，是以为接口所有的方法都是抽象的，实现的类必须得实现所有接口定义的接口，这不会存在歧义问题。

那么注意的是在1.8的时候，接口可以拥有默认实现，如果我们有两个接口，都同时默认实现了方法a，那么类Test去同时实现T1和T2接口的时候，又该去选择哪个接口呢？

**如果一个类同时实现的多个接口拥有相同的默认实现方法，如果不去在该类中实现该默认方法，就会产生编译时错误！**

![image-20220402180133872](IMG/面试话术.asserts/image-20220402180133872.png)

同时在Class文件结构中，只用了一个u2表示它的父类，而用了一个u2数组来表示该类对应的接口

```java
u2             this_class;//当前类
u2             super_class;//父类
u2             interfaces_count;//接口
u2             interfaces[interfaces_count];//一个类可以实现多个接口
```

## 9.3 List一边遍历一边删除

如果是使用正序遍历：注意要修改i = i - 1

```java
public static void main(String[] args) {
    List<String> platformList = new ArrayList<>();
    platformList.add("博客园");
    platformList.add("CSDN");
    platformList.add("掘金");

    for (int i = 0; i < platformList.size(); i++) {
        String item = platformList.get(i);
        if (item.equals("博客园")) {
            platformList.remove(i);
            i = i - 1; 
        }
    }
    System.out.println(platformList);
}
```

如果是逆序遍历：不需要修改

```java
public static void main(String[] args) {
    List<String> platformList = new ArrayList<>();
    platformList.add("博客园");
    platformList.add("CSDN");
    platformList.add("掘金");

    for (int i = platformList.size() - 1; i >= 0; i--) {
        String item = platformList.get(i);
        if (item.equals("掘金")) {
            platformList.remove(i);
        }
    }
    System.out.println(platformList);
}
```

或者使用removeIf方法【推荐】

```java
public static void main(String[] args) {
    List<String> list = new ArrayList<>();
    list.add("aaa");
    list.add("bbb");
    list.add("ccc");

    list.removeIf(item -> "aaa".equals(item));
    // 也可以用下面的代替：
    list.removeIf("aaa"::equals);

}
```

## 9.4 自动装箱和拆箱

```java
public static void main(String[] args) {
    Integer a = new Integer(11);
    Integer b = 11;
    int c = 11;
    System.out.println(a == c); 
    System.out.println(a == b);
    System.out.println(b == c);
}
```

结果为true、false、true

如果a和c比较、b和c比较，因为c是基本数据类型，所以a和b都会进行拆箱，因此都转换为基本数据类型。

而a和b比较，b会进行装箱，取得是缓存池中的11的地址，所以为false

**为什么要有包装类型：**

1. Java本身就是一门OOP语言，对象是灵魂。
2. 基本数据类型有默认值，但是在业务中，可能我更加希望它的值是null，因为默认值也算是值。
3. 泛型参数不能是基本数据类型，必须是Object及其子类。

**自动拆箱带来的NPE问题**

1. 数据库的查询结果可能是null，如果使用基本数据类型进行接受，可能会导致NPE

   ```java
   public static void main(String[] args) throws InterruptedException {
       int a = new Test().getNum();
   }
   
   private Integer getNum() {
       return null;
   }
   ```

2. **三元运算符的不正确使用导致诡异的NPE**

   ```java
   boolean flag = false;
   Integer a = null;
   Integer n = flag ? 1 : a;
   ```

   原因在计算三元表达式结果时，a变量自动拆箱，调用了Integer.intValue()方法。

   **在三元表达式中，当第二、第三位操作数中有基本类型和对象时，对象就会拆箱为基本数据类型进行操作。**

## 9.5 序列化ID的作用

首先序列化就是将对象转换为字节流，而反序列化就是将字节流再转换成对象。

一般我们对可以进行序列化的对象进行序列化之前，该对象都得需要一个seriallVersionUID，原因就是Java的序列化机制是通过在运行时判断类的serialVersionUID来验证版本一致性的。在反序列化时，JVM会将传来的字节流中的serialVersionUID与本地实体类中的UID进行比较，如果相同则认为一致的，不相同就会报错。

如果我们没有显示指定UID，Java序列化机制就会根据编译时的class自动生成一个UID，只有同一次编译生成的class才会生成相同的UID。

## 9.6 泛型的缺点

Java中的泛型是伪泛型，这是因为在Java运行期间，所有的泛型信息都会被擦掉，也就是**类型擦除**

```java
public static void main(String[] args) throws NoSuchMethodException, InvocationTargetException, IllegalAccessException {
    List<Integer> list = new LinkedList<>();
    list.add(1);
    //        list.add('a');
    Class<? extends List> clazz = list.getClass();
    Method add = clazz.getDeclaredMethod("add", Object.class);
    add.invoke(list,"a");
    System.out.println(list);
}
```

最终输出的结果是：`[1, a]`

## 9.7 HashMap详解

### 1. HashMap的hash扰动函数

- 使用扰动函数是为了防止一些比较差的hashCode函数，也就是为了减少哈希碰撞
- 底层1.7之前hash使用四次扰动，1.8之后只使用一次扰动，即hashcode右移16位，然后进行异或，目的是为了更全面的收集信息进一步减少冲突的可能，异或运算的结果更均匀
- 数组长度-1的作用相当于掩码，代替了取余的作用，效率更高

### 2. 为什么hashmap中String、Integer这样的包装类适合作为key

String、Integer等包装类的特性能够保证Hash值的不可更改性和计算准确性，能够有效的减少Hash碰撞的几率

- 都是final类型，即不可变性，保证key的不可更改性，不会存在获取hash值不同的情况
- 内部已重写了equals()、hashCode()等方法，遵守了HashMap内部的规范，不容易出现Hash值计算错误的情况；

### 3. hashmap中的size究竟是什么

首先结论就是hashmap中的size其实就是map中所有的键值对数量。如果该数量大于负载因子*容量了，就会进行扩容。

而当hashmap中的链表长度大于8了，就会判断数组的长度是否超过64，如果超过了就会将链表转为红黑树。否则只会对数组扩容。

### 4. HashMap扩容优化

在1.7的时候，hashMap会对每个元素都进行rehash算法， 计算原来每个元素在扩容之后的哈希表中的位置，但是这样效率过低。

在1.8的时候，HashMap借助两倍扩容机制，使元素不需要进行重新计算位置，而是通过高位运算`e.hash & oldCap`的方式来确定元素是否需要移动，如果高位为0，就表示不需要移动；如果为1，就表示元素在扩容的时候发生了变化，新的下标位置等于原下标位置+原数组长度。

### 5. 为什么扩容是两倍

一般在计算完hash之后就得进行取余操作来决定该元素放在数组的哪个位置。但是**取余操作中如果除数是2的幂次方则等价于该hash值与其除数减一的与操作，也就是说 hash%length = hash & (length - 1)**，采用二进制与操作，相对于%来说能够提升运算效率。

而且在2的幂次方的前提下采用了这种位运算方式，**hash值始终在和一个大部分数字都为1的值做与运算，那么就有更大的可能性不会发生冲突（这可以提一下1.8时候的扰动函数）**。因为在与运算中，如果一个数全为1，那么结果就完全取决于另外一个数，而这里的另外一个数就是指hash算法求出来的hash值，这样就大大减少了冲突的可能性。因为一个良好的hash函数会导致不同对象的hash值几乎不相等。

## 9.8 Comparator和Comparable

Comparable可作为一个类的内部排序实现，Java中一些普通类型如String、Integer等都实现了该接口，我们直接使用即可。

Comparator是外部排序接口，使用策略模式，一个类的排序规则在基于“开闭原则”时，可通过实现Compartor制定多个比较排序策略，供该类采用。可用于Collections.sort()、Arrays.sort()以及一些内部有序的类（SortedSet、SortedMap等）。

## 9.9 快速失败机制“fail-fast”

这个机制是Java集合的一种错误检测机制，当在迭代集合过程中进行结构上的改变的操作时，有可能会产生fail-fast机制。**单机和多线程时候都有可能会触发**

如果有两个线程，线程1通过iterator在遍历集合A中的元素，在某个时候线程2修改了集合A的结构（是结构的修改，不是简单的修改集合元素中的内容），那么就会报错：ConcurrentModificcationException异常。

```java
public static void main(String[] args) {
    List<String> list = new ArrayList<>();
    for (int i = 0; i < 10; i++) {
        list.add(i + "");
    }
    Iterator<String> iterator = list.iterator();
    int i = 0;
    while (iterator.hasNext()) {
        if (i == 3) {
            list.remove(3);
        }
        System.out.println(iterator.next());
        i++;
    }
}
```

**原因：**迭代器在遍历的时候直接访问集合中的内容， 并且在遍历过程中会使用到一个叫modCount的变量。集合在遍历过程中如果内容发生了变化，就会改变modCount的值。同时抛出异常的主要原因就是每次迭代器hasNext()/next()遍历下一个元素之前，都会判断modCount是否等于expectedModCount，而一开始这两者是相等的。因此如果在遍历过程中，集合的内容发生了变化，就会导致异常的出现。

```java
// 每次调用next/hasNext方法的时候都会去调用该方法来判断集合中的内容是否发生变化
final void checkForComodification() {
    if (modCount != expectedModCount)
        throw new ConcurrentModificationException();
}
```

**解决办法：**使用CopyOnWriterArrayList来代替ArrayList；使用removeIf；使用迭代器中的remove方法而不是使用ArrayList中的remove方法，因为在迭代器中的remove方法里面，会让expectedModCount重新等于modCount

## 9.10 为什么 ArrayList 的 elementData 加上 transient 修饰？

首先被加上transient修饰的属性将不会被序列化。

对于ArrayList而言，由于扩容机制，就可能导致有一定的空间是没有被使用的，list重写了writeObject方法，它先将ArrayList中的非transient属性给序列化，然后会去遍历整个elementData，只序列化已存入的元素，这样即加快了序列化的速度，也减少了序列化之后的文件大小。

## 9.13 重写的规则？

1. 参数列表和返回类型必须完全与被重写的方法一致。
2. 构造方法不能被重写，声明为final的方法不能被重写
3. 声明为static的方法不能被重写，但是能够被再次声明
4. 访问权限不能比父类中被重写的方法低，即父类如果是public，子类就不能是protected
5. 重写的方法能够抛出任何非强制异常（uncheckedException，也叫非运行时异常），但是重写的方法不能抛出新的强制性异常，或者比被重写的方法声明的更广泛的强制性异常。

## 9.14 红黑树和AVL树

链接：https://www.nowcoder.com/discuss/817925?channel=-1&source_id=profile_follow_post_nctrack

普通的二叉查找树在极端情况下可退化成链表，此时的增删查效率都会比较低下。为了避免这种情况，就出现了一些自平衡的查找树，比如 AVL，红黑树等。这些自平衡的查找树通过定义一些性质，将任意节点的左右子树高度差控制在规定范围内，以达到平衡状态。以红黑树为例，红黑树通过如下的性质定义实现自平衡：  

1.  **节点是红色或黑色。** 
2.  **根是黑色。** 
3.  **所有叶子都是黑色（叶子是NIL节点）。** 
4.  **每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。）** 
5.  **从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点（简称黑高）。** 

​    有了上面的几个性质作为限制，即可避免二叉查找树退化成单链表的情况。但是，仅仅避免这种情况还不够，这里还要考虑某个节点到其每个叶子节点路径长度的问题。如果某些路径长度过长，那么，在对这些路径上的节点进行增删查操作时，效率也会大大降低。这个时候性质4和性质5用途就凸显了，有了这两个性质作为约束，即可保证**任意节点到其每个叶子节点路径最长不会超过最短路径的2倍**。原因如下：  

​    当某条路径最短时，这条路径必然都是由黑色节点构成。当某条路径长度最长时，这条路径必然是由红色和黑色节点相间构成（性质4限定了不能出现两个连续的红色节点）。而性质5又限定了从任一节点到其每个叶子节点的所有路径必须包含相同数量的黑色节点。此时，在路径最长的情况下，路径上红色节点数量 = 黑色节点数量。该路径长度为两倍黑色节点数量，也就是最短路径长度的2倍。

**AVL和红黑树**

AVL就是平衡二叉树，它的所有子树的高度之差小于等于1。如果插入或删除后破坏了平衡性，就得将其进行旋转处理，但是频繁的旋转会造成性能损失。

1. AVL的时间复杂度虽然优于红黑树，但是性能差异不是太大。
2. 红黑树的插入删除比AVL树更便于控制操作。
3. 红黑树整体的性能略优于AVL树（红黑树旋转情况少于AVL树）

## 9.15 为什么ConcurrentHashMap读操作不需要加锁

[Java 经典面试题：为什么 ConcurrentHashMap 的读操作不需要加锁？ - 云+社区 - 腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1461980)

1. 在1.8中ConcurrentHashMap的get操作全程不需要加锁。
2. 是因为Node的成员val是用volatile修饰的，和数组用volatile修饰没有关系。
3. 数组用volatile修饰主要是保证数组在扩容时的可见性

```java
transient volatile Node<K,V>[] table;

static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    //可以看到这些都用了volatile修饰
    volatile V val;
    volatile Node<K,V> next;
}
```

## 9.16 接口和抽象类

| 接口                                          | 抽象类                                               |
| --------------------------------------------- | ---------------------------------------------------- |
| 不可以定义构造器                              | 可以定义构造器                                       |
| 只能有抽象方法，1.8的时候有默认实现           | 可以有抽象方法和具体方法，不能有默认方法             |
| 不能有静态方法                                | 可以有静态方法                                       |
| 一个类可以实现多个接口                        | 一个类只能继承一个抽象类                             |
| 成员全都是public的                            | 成员可以是public、protected、private、默认           |
| 成员变量实际上全都是常量，public static final | 有抽象方法的类一定是抽象类，而抽象类未必要有抽象方法 |

相同点：

1. 都不能实例化
2. 可以将抽象类和接口作为引用类型。
3. 如果一个类继承了某个抽象类或者实现了某个接口，都需要对其中的抽象方法全部进行实现，否则该类仍然需要被声明为抽象类。

## 9.17 反射导致的异常

```java
public static void main(String[] args) throws Exception {
    String origin = "String  of test";

    Field value2 = origin.getClass().getDeclaredField("value");
    value2.setAccessible(true);
    char[] o2 = (char[]) value2.get(origin);
    o2[0] = 'R';
    o2[1] = 'e';
    o2[2] = 'f';
    o2[3] = 'l';
    o2[4] = 'e';
    o2[5] = 'c';
    o2[6] = 't';

    //此时S3"Reflect of test"
    //origin为"Reflect of test"
    //        String ss="Reflect of test";

    String sss="String  of test";
    System.out.println(sss);
}
```

## 9.18 HashMap和HashTable的区别

1. HashMap是线程不安全的，HashTable是线程安全的，适合在多线程使用，但是它对数据的操作都会使用上synchronized锁，效率低下。
2. HashTable不允许键或值为null的；HashMap的键值都可以为null
3. 初始化容量不同：HashMap的初始容量是16，每次扩容2倍。HashTable初始容量是11，每次扩容2倍 + 1，而且如果指定了HashTable的容量初始值，它会直接使用你给定的大小。
4. 底层数据结构：1.8的时候HashMap有了大改变

> 关于HashTable不允许键或值为null的解释

HashTable的作者认为要从HashTable成功存储和检索对象，用作键的对象必须实现hashCode和equals，但是null不是对象，因此无法调用equals或hashCode，因此HashTable无法将其计算哈希值用以键。

```
* This class implements a hash table, which maps keys to values. Any
* non-<code>null</code> object can be used as a key or as a value. <p>
*
* To successfully store and retrieve objects from a hashtable, the
* objects used as keys must implement the <code>hashCode</code>
* method and the <code>equals</code> method. <p>
```

## 9.19 安全失败机制（fail-safe）

采用安全失败机制的集合容器，在遍历的时候不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。

**原理**：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所做的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。

**缺点**：基于拷贝的遍历是为了避免CME，但是迭代器不能访问到修改后的内容，即迭代器遍历的是一开始那一时刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。

# **10. MyBatis相关面试题**

## 10.1 MyBatis的一二级缓存

[MyBatis一级缓存详解 (qq.com)](https://mp.weixin.qq.com/s?__biz=MzkwMDE1MzkwNQ==&mid=2247496101&idx=1&sn=8d32c975eb41744903bb6331a500c28d&source=41#wechat_redirect)

对于MyBatis的一级缓存中，当MyBatis在执行一次SQL查询或者SQL更新之后，这条SQL语句并不会消失，而是会被MyBatis给缓存起来，再次执行相同SQL语句的时候，就会直接从缓存中进行提取。

**一级缓存又被称为SqlSession级别的缓存**

SqlSession是SqlSessionFactory会话工厂创建出来的一个会话的对象，这个SqlSession对象用于执行具体的SQL语句并返回给用户请求的结果。

![image-20220315170722539](IMG/面试话术.asserts/image-20220315170722539.png)

在每次更新操作的时候，MyBatis都会将此SqlSession中的一级缓存给清空掉。对于MyBatis来说，它每次访问数据库都会创建一个SqlSession，就算这两次访问都在同一个方法中。但是如果该方法是存在事务的，那么在同一个事务中，其实都是同一个SqlSession。

[(34条消息) 同一个方法中，Mybatis多次请求数据库，是否要创建多个SqlSession会话？_Abstracted的博客-CSDN博客](https://blog.csdn.net/qq_16159433/article/details/121128555?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-121128555.pc_agg_new_rank&utm_term=mybatisplus+每次请求+都需要创建SqlSession&spm=1000.2123.3001.4430)

**如果多个SqlSession需要共享缓存，则需要开启二级缓存**，开启之后，会使用CacheExecutor装饰Executor，进入一级缓存的查询流程前， 会先在CacheExecutor进行二级缓存的查询。

当二级缓存开启之后，同一个namespace的所有的操作语句，都影响着一个共同的cache。而且开启二级缓存的时候，**要求返回的POJO必须是可序列化的**

![img](IMG/面试话术.asserts/1515111-20190810211454258-1861395227.png)

## 10.2 #{}和${}

前者是预编译处理，在处理的时候，会将sql中的#{}替换为？，然后调用PreparedStatement的set方法来赋值。

后者是字符串替换，在处理的时候，把括号里面的值替换成变量的值。

使用前者可以有效的防止SQL注入，提高系统安全性。

# **11. 计算机网络**

## 11.1 TCP和UDP

### TCP的三次握手

> 建立连接可以两次握手吗？为什么？

- 不可以
- 如果客户端发送的第一次请求由于网络的原因导致长时间滞留了，以至于误延到连接释放之后的某个时间才到达服务端。这次的请求是一个失效的请求，但是服务端收到这个失效的请求之后，会误以为这个是客户端再次发送的一个新的连接请求。于是服务端就向客户端发送确认，同意建立连接。假设不是三次握手，那么只要服务端发出确认，就认为新的连接已经建立了。由于客户端并没有发出建立连接的请求，因此不会理睬服务端的确认，也不会向服务端发送数据，但是此时服务端却认为新的连接已经建立了，就会一直等待客户端发送数据过来，这样就导致服务端很多资源白白浪费。而如果是三次握手，当服务端向客户端发送确认之后，客户端并不会向服务端发送确定，服务端由于收不到确认，就知道客户端并没有要求建立连接。
- 而且如果是两次握手，服务端也不知道客户端到底有没有收到它发送的确认请求。
- 虽然不可以采用两次握手，但是可以采用四次，不过会降低传输的效率。

> 如果已经建立了连接，但是客户端出现故障怎么办？

服务端每收到一次客户端的请求之后都会重新复位一个计时器，通常是两个小时。如果两个小时之后还没有收到客户端的任何数据，server就会发送一个探测报文段，每隔75秒发送一次。如果发送了十次都没反应，就会认为客户端出现了故障， 然后就会关闭连接。

> 第三次ACK丢失怎么办？

对于服务端来说，它会根据TCP的超时重传机制，等待3秒、6秒、12秒后重新发送SYN+ACK包，以便客户端重新发送ACK包。

### TCP四次挥手

> 四次回收的过程

![IMG/面试话术.asserts/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA2MDg0ODUxMjcy](IMG/面试话术.assets/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA2MDg0ODUxMjcy)

1. 第一次挥手：客户端发送一个FIN，并发送一个序列号，用来关闭客户端到服务端的数据连接
2. 第二次挥手：服务端收到这个FIN，并且发回一个ACK，确认需要为收到的序列号加1，此时服务端进入CLOSE_WAIT状态。此时客户端已经没有要发送的数据了，但是仍然可以接受来此服务端的数据
3. 第三次挥手：服务端发送一个FIN，并且发送一个序列号给客户端，此时服务端进入LAST_ACK状态。第三次挥手的作用是服务端关闭与客户端的连接。
4. 第四次挥手：客户端收到服务端发送的FIN之后，进入TIME_WAIT状态，将ACK置为1，并且将确认序号设置为收到序号加1；服务端收到并确认序列号之后，变成CLOSE状态，不再向客户端发送数据。客户端等待2*MSL（报文段最长寿命）时间后，也进入CLOSE状态。完成四次挥手。

> 白话文理解四次挥手

首先四次挥手是因为要确定数据全部传输完了。

1. 可以将四次挥手理解为A和B打电话。
2. A想要结束这次会话，就会告诉B，我要挂电话了。
3. B听到后，就说好的我知道了。但是此时B还有可能有话想和A说。
4. 当B话说完之后，就对A说：我说完了，我要挂电话了
5. A听到后，就说：好的，我知道你要挂电话了。
6. 四次挥手完毕

> 为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE_WAIT状态意义是什么）？

**产生原因：**

服务端收到客户端断开连接的请求之后，可能会还有一部分数据没有发完，这时先回复ACK表示服务端接受到了客户端发来的断开连接请求。等待数据发送完之后再发送FIN，表示要断开服务端与客户端的数据传送。

**CLOSE_WAIT产生太多的原因：**

CLOSE_WAIT按照正常的操作应该是很短的时间，接收到客户端传来的FIN包并且回复客户端ACK之后，会继续发送FIN包告知客户端关闭连接，之后就会迁移到LAST_ACK状态。

但是close_wait过多只能说明没有迁移到last_ack状态，也就是服务端是否发送FIN包，只有发送了FIN之后才会迁移到last_ack状态，所以**问题定位在是否发送FIN包**。

FIN包的底层的实现其实就是调用socket中的close方法，这里的问题出在没有执行close方法，说明服务端socket忙于读写。 

**CLOSE_WAIT太多解决办法：**

1. 使用完socket就调用close方法。
2. socket读控制，当读取的长度为0时（读到结尾），立即close；
3. 如果read返回-1，出现错误，检查error返回码，有三种情况：INTR（被中断，可以继续读取），WOULDBLOCK（表示当前socket_fd文件描述符是非阻塞的，但是现在被阻塞了），AGAIN（表示现在没有数据稍后重新读取）。如果不是AGAIN，立即close
4. 可以设置TCP的连接时长keep_alive_time还有tcp监控连接的频率以及连接没有活动多长时间被迫断开连接

> 客户端TIME_WAIT状态的意义？（为什么要等待2MSL）

[(34条消息) TCP通信过程中time_wait和close_wait产生过多的原因和解决方法_赵雨诺的博客-CSDN博客_tcp time wait 过多](https://blog.csdn.net/weixin_43851782/article/details/116925584)

- **保证TCP协议的全双工连接能够可靠关闭**

在第四次挥手的时候，客户端发给服务端的ACK可能丢失，TIME_WAIT就是用来重发可能丢失的ACK报文。如果server没有收到ACK，就会重发FIN，如果client在2MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL。防止server没有收到ACK而不断重发FIN。MSL是指一个片段在网络中的最大存活时间。2MSL就是一个发送和一个回复所需要的最大时间。如果直到2MSL，client都没有再次收到FIN，那么client推断ACK已经被成功接受，则结束TCP连接。

- **保证这次连接的重复数据段从网络中消失**

客户端在发送完最后一个ACK报文段之后，再经过2MSL，就可以使本次连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。

**拓展：TIME_WAIT过多产生原因：**

如果短时间内进行大量的短连接，就可能会导致客户端所在的操作系统的socket端口和我呢见描述符被用尽，系统无法再发起新的连接。

**扩展；TIME_WAIT过多解决办法：**

1. 修改为长连接，但是长连接太多也会导致服务器性能问题，并且安全性较差。
2. 增大可用端口范围，但是只能缓解问题
3. 客户端打开tcp_tw_recycle和tcp_timestamps选项：也就是销毁TIME_WAIT，当开启这个配置之后，内核会快速的回收处于TIME_WAIT状态的socket连接。多快？不再是2MSL，而是一个RTO（retransmission timeout，数据包重传的timeout时间）的时间，这个时间根据RTT动态计算出来，但是远小于2MSL。

### TCP和UDP的区别

UDP主要用于那些对高速传输和实时性有较高要求的通信或广播通信。如果我们使用通过IP电话进行通信：如果使用TCP协议，数据在传输过程中如果丢失会被重发，但是这样无法流畅地传输通话人的声音，会导致无法进行正常交流。而采用UDP，它不会进行重发处理，从而也就不会有声音大幅度延迟到达的问题，即使有数据丢失也只会影响某一小部分的通话。

即使是出现网络拥堵，UDP也无法进行流量控制等避免网络拥塞的行为。而且传输途中即使出现了丢包，UDP也不会负责重发。甚至当出现包的到达顺序乱掉的时候也没有纠正功能。

> UDP的用途：

- 包总量较少的通信（DNS、SNMP等）
- 视频、音频等多媒体通信（即时通信）
- 限定于LAN等特定网络中的应用通信
- 广播通信（广播、多播）

![img](IMG/面试话术.assets/B67D1C5538D193ED0D71FE132439138E.png)

> 为什么说TCP是面向字节流的，而UDP是面向报文的？

**UDP是面向报文的**：发送方的UDP对应用层交下来的报文，不合并不拆分，只是在其上面加上首部之后就交给了下面的网络层，也就是说无论应用层交给UDP多长的报文，它统统发送，一次发送一个。而对于接收方，接收到之后直接去除首部，交给上面的应用层就完成任务了。因此，它需要应用层控制报文的大小，如果报文太长就会导致IP层需要分片，降低效率。

**TCP是面向字节流的**：TCP将上面交下来的数据看成是无结构的字节流来发送，发送方TCP会将数据放入缓存区，等到可以发送的时候才发送，不能发送就等着。如果应用层传送的数据块太长，TCP就可以将它划分短一些再传送。如果应用程序一次只发送一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去。

### TCP协议如何保证可靠传输

1. 应用数据被分割成 TCP 认为最适合发送的数据块。 
2. TCP给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 
3. **校验和**： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 
4. TCP 的接收端会丢弃重复的数据。 
5. **流量控制**： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
6. **拥塞控制**： 当网络拥塞时，减少数据的发送。 
7. **停止等待协议** 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 
8. **超时重传**： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段

> 序列号和确认应答提高可靠性、SYN和ACK

当发送端的数据到达接收端的主机之后，接收端主机会返回一个已收到消息的通知，这个消息就叫做确认应答（ACK）。比如发送端发送了1-1000的数据给接收端，接收端就会发出一个ACK 1001，表示下一次我想收到的数据为1001。

如果一段时间之后，发送端都没有收到ACK，那么它就会进行重发。当然发送端没收到ACK并不一定是接收端没收到数据，也有可能是接收端发送的ACK在途中丢失了，没有到达接收端。这种情况同样发送端因为没有收到ACK而认为数据没有到达目的地从而重发数据。

序列号SYN的初始值是在建立连接的时候随机生成的，而后面SYN会累加它所发送过去的数据的字节数。然后接收端查询接受数据TCP首部中的序列号和数据的长度，将自己下一步应该接受的序列号作为ACK返送回去。通过SYN和ACK，TCP可以实现可靠传输。

> TCP以段为单位发送数据

TCP在传输大量数据的时候，是以MSS（Maximum Segment Size）的大小将数据进行分割发送，重发的时候也是以MSS为单位。MSS正好是IP中不会被分片处理的最大数据长度。

MSS是在三次握手的时候由两端主机之间被计算出来的。两端的主机在发出建立连接的请求的时候，会在TCP首部中写入MSS选项，告诉对方自己的接口能够适应的MSS的大小（此时TCP首部不再是20字节了，而是4字节的整数倍）。然后会在两者之间选出一个较小的值投入使用。 

### ARQ协议

ARQ就是自动重传请求，是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ包含停止等待ARQ协议和连续ARQ协议。

**停止等待ARQ协议：**

基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到ACK确认就说明没有发送成功，需要重新发送，直到收到确认之后才会再次发送下一个分组。

在该协议中，若接收方收到重复分组，就丢弃该分组，而且还要发送确认。

优点是简单，缺点是信道利用率低，等待时间长。

**连续ARQ协议：**

该协议可以提高信道利用率。发送方会维持一个发送窗口，凡是位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。

优点：信道利用率高，容易实现，即使确认丢失，也不必重传。

缺点：不能向发送方反映出接收方已经正确收到的所有分组的信息。比如发送方发送了5条消息，但是只有第3条消息丢失了。接收方只能对前两条消息发送确认。而发送方无法知道后续三个分组的情况，只能把后面三个分组都重新传送一次。这也叫Go-Back-N（回退N），表示需要退回来重传已经发送过的N个消息。

### 滑动窗口和流量控制

拥塞控制是防止过多的数据注入网络，使得网络中的路由器或者链路过载。流量控制是点对点的通信量控制，而拥塞控制是全局的网络流量整体性的控制。发送双方都有一个拥塞窗口（cwnd）。  

1. 慢开始：最开始发送方的拥塞窗口为1，由小到大递增。每经过一个传输轮次，拥塞窗口cwnd加倍（乘2）。当cwnd超过慢开始门限，则使用拥塞避免算法，避免cwnd增长过长。  
2. 拥塞避免（算法]）：当cwnd超过慢开始门限，每经过一个往返时间RTT，cwnd就增长1。在慢开始和拥塞避免过程中，一旦发现网络拥塞，就把慢开始门限设置为当前值的一半，并且重新设置cwnd为1，重新慢启动。  
3. 快重传：接收方每收到一个失序的报文段后就立即发出重复确认，发送方只要收到3个重复确认就立即重传。  
4. 快恢复：当发送方连续收到三个重复确认，就将慢开始门限减半，将当前的窗口设置为慢开始门限，并采用拥塞避免算法。（采用快恢复算法时，慢开始只在建立连接和网络超时时才使用）

### TCP头部的RST标志位

RST表示复位，用来异常的关闭连接，在TCP的设计中它是不可或缺的。发送RST包关闭连接时，不必等缓冲区的包都发出去（不像FIN包），直接就丢弃缓冲区的包发送RST包。而接收端收到RST包之后，也不必发送个ACK包来确认。

TCP处理程序会在自己认为的异常时刻发送RST包。

1. A向B发起连接，但B之上并未监听相应的端口，这时B操作系统上的TCP处理程序会发RST包。
2. AB正常建立连接，正在通讯时，A向B发送了FIN包要求关闭连接，B发送ACK之后网断了，A通过若干原因放弃了这个连接（例如进程重启）。网通了之后，B又开始发送数据包，A收到之后表示压力很大，不知道这野连接哪来的，就发了个RST包强制把连接关了，B收到之后会出现connect reset by peer错误。

## 11.3 GET和POST的区别

1. GET重点在于从服务器上获得资源，POST重点在于向服务器发送数据。
2. GET传输的数据量小，因为受URL长度影响，但是效率较高；POST可以传送大量数据，所以上传文件只能POST
3. GET是不安全的，因为GET请求发送的数据是在URL上，是可见的。而POST是放在请求头部的，是安全的。

## 11.4 对称加密和非对称加密

- 对称加密指加密和解密使用的都是同一把钥匙，可能会造成不安全问题
- 非对称加密指使用两把钥匙，一把公钥一把私钥。公钥可以随便发布，私钥只能自己保存。发送密文的一方使用对方的公钥进行加密处理，对方接收到加密信息之后，使用自己的私钥进行解密。可以保障安全性，但是相比对称加密效率较慢。

## 11.5 Cookie和Session

HTTP是一种无状态协议，也就是说HTTP协议本身不对请求和响应之间的通信状态进行保存。因此就可以使用Cookie和Session来解决这个问题。

- Cookie一般用来保存用户信息。它是web服务器保存在用户浏览器上的文件（key-value），可以包含用户相关的信息。客户端向服务器发起请求的时候就会提取浏览器中的用户信息由HTTP发送给服务器。
- Session是浏览器向服务器会话过程中，服务器会分配的一块存储空间给SESSION。服务器默认为客户浏览器的cookie中设置sessionId，这个sessionId就和cookie对应，浏览器在向服务器请求过程中传输的cookie包含sessionId，服务器根据传输的cookie中的sessionId获取出会话中存储的信息，然后确认会话的身份信息。

**区别：**

1. cookie数据放在浏览器端，安全性较差；session放在服务器上，安全性相对较高
2. 单个cookie保存的数据不能超过4K，session无此限制

## 11.6 HTTP和HTTPS

### 1、什么是HTTP和HTTPS

**HTTP：**

- HTTP全称超文本传输协议，用来规范超文本（网络上的包括文本在内的各种各样的消息）的传输的。具体来说，主要是用来规范浏览器和服务器端的行为的。 HTTP是一种无状态的协议，也就是说，服务器不维护任何有关客户端过去所发请求的消息。默认端口是80。
- HTTP优点：扩展性强、速度快、跨平台支持性好。
- HTTP通信过程：首先服务器再80端口等待客户的请求；浏览器发起到服务器的TCP连接；服务器接受来自浏览器的TCP连接；浏览器和服务器交换HTTP消息；关闭TCP连接。 

**HTTPS：**

- HTTPS是HTTP的加强安全版本，具有安全性的SSL加密传输协议。默认端口号是443.
- 保密性好、信任度高（可认证用户和服务器，确保数据发送到正确的客户机和服务器）。
- 建立一个信息安全通道来保证数据传输的安全；另一种就是确认网站的真实性。
- 相对于HTTP来说，HTTPS的技术门槛较高，并且CA证书的申请大部分都需要一定的资金。对接HTTPS也需要额外的技术支持；对于大部分网站来说，并不关系数据的安全性和保密性；HTTPS加重了服务端的负担，相比HTTP需要更多的资源来支撑，同时降低了用户的访问速度；对于用户来说，HTTP和HTTPS的差异感知不大。

### 2、HTTP和HTTPS的区别

| 区别     | HTTP     | HTTPS                                        |
| :------- | -------- | -------------------------------------------- |
| 协议     |          |                                              |
| 端口     | 80       | 443                                          |
| 资源消耗 | 较少     | 由于加密解密处理，会消耗更多的CPU和内存资源  |
| 开销     | 无需证书 | 需要申请到CA申请证书                         |
| 加密机制 | 无       | 共享密钥加密和公开密钥加密并用的混合加密机制 |
| 安全性   | 弱       | 由于加密机制，安全性强                       |

1. 首先HTTP是超文本传输协议，运行在TCP之上，明文传输，**客户端与服务器端无法校验对方的身份**；HTTPS是具有安全性的SSL加密传输协议，运行在SSL之上，而SSL运行在TCP之上，**是添加了加密和认证机制的HTTP**。
2. HTTP默认是80端口，而HTTPS是443
3. HTTP的资源消耗相对于HTTPS来说较少，因为HTTPS的加解密处理，会消耗更多的CPU和内存资源。
4. HTTPS还得需要向CA申请证书，大部分都需要花费一定的金额
5. HTTP连接是无状态的，没有加密解密机制；而HTTPS使用**共享密钥加密和公开密钥加密并用的混合加密机制，安全性较强**

### 3、HTTPS工作原理

![img](IMG/面试话术.asserts/4E0CD01326A8E2DA4531747D0DD3B192)

### 4、一个完整的HTTP请求所经历的步骤

### 5、HTTP版本对比

**HTTP1.1相比HTTP1.0支持的特性：**

- **连接方式**：HTTP1.0为短连接，HTTP1.1为长连接，注意长连接需要客户端和服务端都支持长连接。
- **状态响应码：**HTTP1.1中新加入了大量的状态码，比如100-在请求大量资源前的预热请求，206--范围请求的标识码。
- **缓存处理：**在HTTP1.1中引入了更多的缓存控制策略。
- **带宽优化及网络连接的使用：**HTTP1.0中存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，但是服务器却将整个对象送了过来。而HTTP1.1在请求头中引入了range头域，它允许只请求资源的某个部分，即返回码是206，这样就方便了开发者自由的选择以便于充分利用带宽和连接。
- **HOST头处理：**HTTP1.1在请求头中加入了HOST字段。

**HTTP2相比HTTP1.1支持的特性：**

- **新的二进制格式**：HTTP1.1 基于文本格式传输数据；HTTP2.0采用二进制格式传输数据，解析更高效。 
- **多路复用**：在一个连接里，允许同时发送多个请求或响应，并且这些请求或响应能够并行的传输而不被阻塞，避免 HTTP1.1 出现的”队头堵塞”问题。 
- **头部压缩**，HTTP1.1的header带有大量信息，而且每次都要重复发送；HTTP2.0 把header从数据中分离，并封装成头帧和数据帧，使用特定算法压缩头帧，有效减少头信息大小。并且HTTP2.0在客户端和服务器端记录了之前发送的键值对，对于相同的数据，不会重复发送。比如请求a发送了所有的头信息字段，请求b则只需要发送差异数据，这样可以减少冗余数据，降低开销。 
- **服务端推送**：HTTP2.0允许服务器向客户端推送资源，无需客户端发送请求到服务器获取。

### 6. HTTPS如何实现可靠性

**对称加密 + 非对称加密 + 摘要算法 + 数字签名**

1. 非对称加密主要是通过两个密钥来实现，一个公钥和一个私钥。在通信的时候，私钥仅由解密者保存，公钥由任意一个想要与解密者通信的发送者所知（加密者）。即发送者通过公钥对想要发送的数据进行加密，然后接收者通过私钥对该加密后的消息解密。
2. 但是非对称加密在实际的通信中计算代价较高，效率太低，因此对消息的实际上的加密方式是通过对称加密进行的。 而对称加密的保密性完全依赖于密钥的保密性。但是网络通信是不安全的，**因此就可以使用非对称加密对对称加密的密钥进行加密，保护该密钥不在网络信道中被窃听。**这样通信双方只需要通过一次非对称加密交换对称加密的密钥，在之后的信息通信中，就可以使用对称加密算法对消息进行加密通信了。
3. 数字签名是CA在给服务器颁发证书的时候，使用散列+加密的组合技术，在证书上盖个章，以此来提供验伪的功能。

## 11.8 浏览器中输入url地址->>显示主页的过程

1. **浏览器通过DNS解析查找域名的IP地址（DNS查找过程：浏览器缓存、路由器缓存、DNS缓存）**

    1. 先从浏览器缓存里面查找IP，因为浏览器会缓存DNS记录一段时间
    2. 如果没找到，就会去hosts文件查找是否有该域名和对应IP
    3. 如果没有再从路由器缓存里面找
    4. 如果没找到，再从DNS缓存里面找
    5. 如果都没有，从根域名服务器开始递归搜索，到根、顶级域名服务器，再到自己的输入的域名服务器，直到找到IP

2. **浏览器和服务器建立TCP连接（三次握手）**

    1. 应用层发起HTTP请求
    2. 传输层的TCP协议为传输报文提供可靠的字节流服务，也就是用了TCP三次握手
    3. 网络层把TCP分割好的各种数据包传送给接收方。而要保证确实能传到接收方还需要接收方的MAC地址，也就是物理地址。
    4. 链路层将数据发送到数据链路层传输。至此请求报文已经发出，客户端发送的请求的阶段结束。

3. **浏览器向服务器发送一个HTTP请求**（cookies会随着请求发送给服务器）

    HTTP的请求包含三部分：请求方法URI协议/版本、请求头、请求正文。

    HTTP的响应包含三部分：状态行、响应头、响应正文

4. **服务器处理请求**（通过路径参数映射到对应的请求处理器进行请求）**并发回一个HTML响应**（将处理结果和视图返回给浏览器）。

5. **TCP连接释放。**

6. **浏览器开始显示HTML。**

**这个过程中用到的协议？**

1. DNS：获取域名对应的IP
2. TCP：与服务器建立TCP连接
3. ARP：路由器在与服务器通信时，需要将IP地址转换为MAC地址，需要使用ARP协议。
4. HTTP：在TCP建立连接完成之后使用HTTP协议访问网页。
5. IP：建立TCP协议时，需要发送数据，发送数据在网络层使用IP协议。
6. OSPF：IP数据包在路由器之间，路由选择使用OSPF协议。

## 11.9 Keep-Alive

[(34条消息) http的keep-alive和tcp的keepalive区别_oceanperfect的博客-CSDN博客](https://blog.csdn.net/oceanperfect/article/details/51064574)

> HTTP中的KeepAlive：

在早期的HTTP，每一个HTTP请求都要求打开一个TCP SOCKET连接，并且在使用依次之后就会断开这个连接。这样的消耗无疑是非常大的。因此就可以使用KeepAlive来改善这种状态，**即在一次TCP连接中可以持续发送多份数据而不会断开连接**，只要任意一方没有明确提出断开连接，则保持TCP连接状态。通过该机制，可以减少TCP建立连接次数，提高性能和提高HTTP服务器的吞吐率。但是长时间的TCP连接容易导致系统资源无效占用，配置不当的KeepAlive带来的损失也是很大的。

同时为了避免资源浪费，web服务软件一般会提供`keepalive_timeout`参数，用来指定HTTP长连接的超时时间。比如HTTP的长连接的超时时间是60秒，web服务软件就会启动一个定时器，如果客户端在完成一个HTTP请求之后，60秒内都没有再发起新的请求，定时器的时间一到，就会触发回调函数来释放连接。

> TCP中的KeepAlive

也叫**保活机制**，该功能由内核实现，当客户端和服务端长达一定时间没有进行数据交互的时候，内核为了确保该连接是否还有效，就会发送探测报文，来检查对方是否还在线，然后来决定是否关闭该连接。

TCP连接建立之后，如果应用程序或者上层协议一直不发送消息或者隔很久才发送一次数据，这是掉线了还是确实没有数据传输，连接还需不需要保持？当超过一段时间之后，TCP自动发送一个数据为空的报文给对方，如果对方回应了这个报文，说明连接还可以继续保持，如果没有报文返回，并且重复了多次之后达到了保活探测次数后还是没有，就会认为连接丢失，没有继续保持下去。

注意，应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 `SO_KEEPALIVE` 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。

## 11.10 计算机五层结构

1. **应用层：**提供两个终端设备上的应用程序之间信息交换的服务，它定义了信息交换的格式，消息会传给传输层。HTTP、DNS、SMTP、FTP
2. **传输层：**为两个终端设备进程之间的通信提供通用的数据传输服务。TCP、UDP
3. **网络层：**选择合适的网间路由和交换结点，确保数据及时传送，IP、ARP、ICMP
4. **数据链路层：**将网络层交下来的IP数据报组成成帧，在两个相邻节点之间的链路上传送帧。每一帧包括数据和必要的控制信息（同步信息，地址信息，差错控制）
5. **物理层：**实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。

## （TODO）11.11 ARP协议

## （TODO）11.12 IP协议

IP协议是作用在TCP/IP中的网络层。

# **12. 操作系统**

## 12.1 同步和异步？

1. 如果系统中存在临界资源（资源数量少于竞争资源的线程数量的资源），例如正在写的数据以后可能被另外一个线程读到，或者正在读的数据可能已经被另外一个线程写过了，那么这些数据就必须进行同步存取。
2. 当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用异步编程。
3. 事实上所谓的同步就是指阻塞式操作，而异步就是非阻塞式操作。

## 12.2 有了进程为什么还要有线程

**进程和线程：**

- 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，进程是系统进行资源分配和调度的一个独立单位。
- 线程是进程的一个实体，是CPU调度和分派的基本单位，他是比进程更小的能独立运行的基本单位，线程自己基本上不拥有系统资源，只拥有一点在运行过程中必不可少的资源（程序计数器、寄存器和栈），但是它可以与同属于一个进程的其他线程共享进程所拥有的全部资源。
- 一个进程崩溃之后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径，一个线程死掉就等于整个进程死掉。

**原因：**

- 进程只能在一个时间干一个事，如果想同时干两件事或多件事进程就无能为力了。
- 进程在执行过程中如果阻塞，例如等待输入，整个进程就会被挂起，即使进程中有些工作不依赖于输入的数据也将无法执行。

## 12.3 线程和进程的区别

进程是系统进行资源分配和调度的一个独立单位，是一个在内存中运行的应用程序；线程是进程划分的更小的运行单位，一个进程可以有多个线程。

**进程和线程的区别：**

1. **根本区别：**进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位。
2. **资源开销：**每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看作是轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和PC，线程之间切换的开销比较小。
3. **包含关系：**线程是进程的一部分，所以线程也被称为轻量级进程。
4. **内存分配：**同一个进程的线程共享本进程的地址空间和资源，而进程和进程之间的地址空间和资源是独立的。 
5. **影响关系：**一个进程崩溃之后，在保护模式下不会对其它进程产生影响，但是一个线程崩溃后有可能导致整个进程都死掉。进程比线程更有健壮性。
6. **执行过程：**每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行。

## 12.4 什么是上下文切换？

1. 在多线程编程中，线程的个数一般都大于CPU核心的个数，而一个CPU在任意时刻只能被一个线程使用，为了让这些线程都有效执行，**CPU采取的策略就是为每个线程分配时间片并轮转的形式。**当一个线程的时间片用完的时候就会重新处于就绪状态让给其它线程使用，这个过程就叫做上下文切换。
2. 概括来就是说，当前任务在执行完CPU的时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。**任务从保存到再加载的过程就是一次上下文切换。**
3. 频繁的上下文切换会消耗大量的CPU事件。

## 12.5 死锁

### 1. 死锁形成的条件

- **互斥条件：**资源只能有一个进程占用。如果此时还有其它的进程来请求该资源，就只能等待直到占有资源的进程用毕释放。
- **占有并等待**：一个进程至少应该占有一个资源，并等待另一个资源，而该资源被别的进程所占有。
- **非抢占：**资源不能被抢占，只能在持有资源的进程完成任务后，该资源才会被释放。 
- **循环等待：**若干进程之间形成一种头尾相接的循环等待关系。

### 2. 如何避免死锁

预防死锁，就要避免上述的四个死锁形成条件。

1. 避免一个线程同时获得多个锁
2. 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
3. 尝试使用定时锁，使用lock.tryLock(timeout)来替换使用内部锁机制。

## 12.6 孤儿进程和僵尸进程

**孤儿进程：**一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程成为孤儿进程。孤儿进程将被init进程（进程号为1）所收养，并由init进程对他们完成状态收集工作。

**僵尸进程：**一个进程使用fork创建子进程之后，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。在Linux中，僵尸进程不占用资源，只是它对应的PCB还存在。

**如何杀死僵尸进程？**

 首先僵尸进程一但出现会很难自己消亡，会一直存在直至系统重启。虽然僵尸进程几乎不占用系统资源，但是数量太多了之后还是会对系统带来其它的影响。因此就需要杀掉僵尸进程。而僵尸进程是无法直接使用kill -9命杀掉的。

1. **重启服务器**
2. **找到该defunct（失效的）僵尸进程的父进程，将该进程的父进程杀掉，则此defunct进程将自动消失**

**它们是如何产生的？**

当你运行一个程序时，它会产生一个父进程以及很多子进程。 所有这些子进程都会消耗内核分配给它们的内存和CPU 资源。这些子进程完成执行后会发送一个 Exit 信号然后死掉。这个 Exit 信号需要被父进程所读取。父进程需要随后调用 wait 命令来读取子进程的退出状态，并将子进程从进程表中移除。  

若父进程正确第读取了子进程的 Exit 信号，则子进程会从进程表中删掉。但若父进程未能读取到子进程的 Exit 信号，则这个子进程虽然完成执行处于死亡的状态，但也不会从进程表中删掉。

## 12.7 用户态和系统态

运行在应用态的进程可以直接读取用户程序的数据。运行在系统态的进程几乎可以访问计算机上的任何资源。

**用户态切换到内核态的三种方式：**

1. **系统调用**：用户态主动通过系统调用的方式切换到内核态。如果处于用户态的进程想要调用操作系统提供的系统态级别的子功能的时候，就可以通过系统调用的方式向操作系统提出服务请求，并由操作系统代为完成。
2. **异常：**当CPU在执行运行在用户态下的程序时， 发生了某些事先不可知的异常，这时就会触发当前由运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页中断。
3. **外围设备的中断：**当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU就会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到系统态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

## 12.8 线程的生命周期

对于通用的生命状态来说，一共有五种状态：

1. **初始状态：**线程已经被创建，但是还不允许分配CPU运行。这个状态是属于编程语言特有的，不过这里的创建仅仅是在编程语言层面被创建，而在操作系统层面，真正的线程还未被创建，比如new Thread，这时候在编程语言层面线程是新建状态
2. **可运行状态：**线程可以分配CPU执行，在这个时候，真正的操作系统层面的线程已经被成功创建了，但是还暂未分配CPU。
3. **运行状态：**可运行状态的线程被分配到了处理机资源，进入运行状态
4. 运行状态的线程如果调用一个阻塞的API（例如以阻塞的方式读取文件）或者等待某个事件（例如条件变量），那么线程就会切换至**休眠状态**，同时释放CPU使用权，休眠状态的线程永远无法获得CPU使用权。当等待的事件出现了，线程就会从休眠状态转换到可运行状态。
5. 线程执行完毕或者出现异常就会进入**终止状态**，此时意味着线程的生命周期结束了。

不同的编程语言会有不同的实现，比如Java中的线程生命周期可以分为六个状态。

1. **NEW（初始化状态）**
2. **RUNNABLE（可运行/运行状态）**：Java里面可以把可运行状态和运行状态进行合并，因为这两个状态在操作系统调度层面有用，而JVM层面不关心这两种状态，因为JVM将线程调度交给操作系统处理了。
3. **BLOCK（阻塞状态）**
4. **WAITING（无时限等待）**
5. **TIMED_WAITING（有时限等待）**
6. **TERMINATED（终止状态）**

**Java中各大状态的转换】**

- **RUNNABLE与BLOCKED的状态转换**

当线程等待synchronzied的隐式锁的时候，等待的线程会从RUNNABLE转换位BLOCKED状态，而当等待的线程获取到隐式锁的时候，就会从BLOCKED状态转换回RUNNABLE状态。

如果线程调用阻塞式API，在操作系统层面，的确会转换到休眠状态，释放CPU资源。但是在Java层面线程的状态依然保持RUNNABLE状态，**JVM根本不关心操作系统调度相关的状态**，因为在JVM看来，等待CPU使用权（操作系统层面此时处于可执行状态）和等待IO（操作系统层面处于休眠状态）没有区别，都是在等待某个资源，所以都归入了RUNNABLE状态。

平时说的Java在调用阻塞式API时线程阻塞，说的其实是操作系统层面的阻塞状态。

- **RUNNABLE和WAITTING状态切换**

第一种：在隐式锁中调用wait方法

第二种：调用无参数的Thread.join方法，这是一种线程同步方法，比如有一个线程对象ThreadA，当调用A.join方法的时候，执行这条语句的线程会等待A线程执行完毕，而等待中的这个线程就会从RUNNABLE转换为WAITTING。当线程A执行完之后，线程B就会从WAITTING转换回RUNNABLE

第三种：调用LockSupport.park方法，使用unpark又回去了。

- **RUNNABLE和TIMED_WAITTING**

带有超时参数的各种方法，比如sleep、wait、jon、parkNanos、parkUntil

- **NEW到RUNNABLE**

Java刚创建出来的对象就是NEW状态，只需要调用线程对象的start方法就可以转换为RUNNABLE状态。

- **RUNNABLE到TERMINATED**

执行完run之后自动转换。同时如果执行期间抛出异常也会转换。

如果需要强制中断run方法执行，首先Thread中的stop方法可以，但是不建议使用，可以使用interrupt方法。
