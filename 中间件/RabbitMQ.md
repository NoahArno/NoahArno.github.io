# 一、基础知识

# 1.1 springboot整合

1、添加依赖

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
```

2、配置文件中进行相关配置

```yaml
spring: 
  rabbitmq:
    host: 192.168.118.128
    virtual-host: /
    publisher-returns: true #开启发送端消息抵达队列的确认
    template:
      mandatory: true #只要抵达队列，以异步发送优先回调我们这个returnconfirm
    listener:
      simple:
        acknowledge-mode: manual #手动ack消息
    publisher-confirm-type: correlated #开启发送端确认
```

3、添加注解@EnableRabbit

# 二、面试题

## 2.1 为什么你的项目要使用RabbitMQ？

商品支付之后，要创建订单，要物流信息，要发送通知等，需要异步

## 2.2 MQ的优点

1. **异步处理：**相比于传统的串行、并行方式，提高了系统的吞吐量。（**异步就是你可以不用等到你要执行的任务执行完，而是直接执行下一个任务，最后再执行它的回调函数**）

   从业务上来说，A发送一个请求，需要将数据写入BCD三个系统进行保存，如果不是异步的话，就得等待它们都执行完才返回结果，这无疑是非常耗时的，因此就可以使用MQ的异步，在A处理了请求之后，可以发送三个消息分别发给BCD，去异步的处理它们接下来的业务，这样无疑快得多。

2. **应用解耦**：A系统发送数据给BCD三个系统，如果是通过接口调用的方式也不是不可以，但是如果另一个系统E也想要A的这些数据，或者BCD其中有系统不想要这个数据了，那么负责A系统的团队就得忙活死了，以后如果还要有变更，就得继续修改代码。这就是所谓的**耦合严重**。如果采用MQ的话，就可以让A系统将数据发送到MQ中，其余的系统只需要去消费这些消息就行。

3. **流量削峰：**如果A系统会有一段时间突然产生大量的流量，那么可能会造成MySQL服务器扛不住这么大的请求。就可以接入MQ的方式，将请求发到MQ中，然后A系统会根据自己的承受能力去MQ中处理请求，一般而言，这种大流量持续的时间不会很久，等到系统稳定之后，就可以让积压在MQ中的请求逐步被处理。

## 2.3 MQ的缺点

虽然系统中引入了MQ能带来一定的好处，但是同样也会带来坏处：

1. 首先引入了新的中间件，会造成**系统的可用性降低**，因为本来系统运行的好好的，突然加了个中间件过来，还得去考虑MQ，如果MQ挂了怎么办？如果消息丢失了怎么办？
2. **系统复杂性降低**：比如加入了MQ，你应该如何去处理**消息是否重复消费？**，**怎么处理消息丢失的情况？消息的顺序性该如何保证？**
3. **一致性问题：**比如系统A请求成功了，将消息发送到MQ之后就返回成功。但是此时BCD系统去消费这个消息，如果其中有一个系统消费失败了，那么该怎么办？**这就造成了数据的一致性问题**

## 2.4 各种MQ的区别（为什么选择RabbitMQ？）

相对于其余的几种MQ来说，RabbitMQ拥有开源的活跃社区，它的时效性很高，延迟最低，拥有良好的消息可靠性。并且基于erlang语言开发，并发能力强，性能极好。

| 特性                    | ActiveMQ                   | RabbitMQ                                       | RocketMQ                                                     | Kafka                                                        |
| ----------------------- | -------------------------- | ---------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 单机吞吐量              | 万级                       | 万级                                           | 十万级，支持高吞吐                                           | 十万级，高吞吐                                               |
| topic数量对吞吐量的影响 |                            |                                                | topic可以达到几百/几千的级别，吞吐量会有较小幅度的下降，在同等机器下，可以支撑大量的topic | topic从几十到几百个时候，吞吐量会有较大的下降。Kafka尽量保证topic数量不要太多 |
| 时效性                  | ms                         | 微秒级，延迟最低                               | ms                                                           | ms以内                                                       |
| 可用性                  | 高，基于主从架构实现高可用 | 同Active                                       | 非常高，分布式架构                                           | 非常高，分布式，一个数据多个副本，少数机器宕机不会丢失数据，不会导致不可用 |
| 消息可靠性              | 较低的概率丢失             | 基本不丢                                       | 经过参数优化配置，可以做到0丢失                              | 同rocketmq                                                   |
| 功能支持                | MQ领域的功能及其完备       | 基于erlang开发，并发能力强，性能极好，延时很低 | MQ功能较为完善，分布式，扩展性好                             | 功能简单，在大数据领域的实时计算以及日志采集被大规模使用     |

## 2.5 如何防止消息的重复提交

如果MQ由于某种因素导致消费端收到了两条一模一样的消息，该如何处理？其实就是保证**幂等性**

就以固定的业务来说，比如我们有一种商品它只能每个用户购买一次。

1. 在每次插入订单的时候，就可以查看MySQL中是否有该用户关于该商品Id的订单，如果有了， 就不让它插入。但是这样无疑效率会很低，这时候也可以选择使用Redis来进行这种判重，当我们创建订单时，可以同时将该用户购买了哪个商品记录在redis中，每次插入的时候可以先判断redis是否存在该记录。
2. 也可以使用唯一性约束，如果插入了相同的数据，就会报错。

## 2.6 如何保证消息的消费顺序（不懂）

比如系统A发送了两个消息，M1和M2，并且必须要M1先于M2执行。如果这两个数据被不同的消费者消费掉了，就可能会M2先执行，M1后执行。

对于有顺序要求的消息，可以将其都发送到同一个Queue中，然后依次消费。

- 拆分多个 queue(消息队列)，每个 queue(消息队列) 一个 consumer(消费者)，就是多一些 queue(消息队列)而已，确实是麻烦点；
- 或者就一个 queue (消息队列)但是对应一个 consumer(消费者)，然后这个 consumer(消费者)内部用内存队列做排队，然后分发给底层不同的 worker 来处理。

## 2.7 如何保证消息的可靠传输

**什么情况会导致消费的传输不可靠呢？**

1. 生产者在向MQ传送消息的过程中，消息丢失。
2. MQ收到消息，暂时存在内存中，还没消费，但是此时MQ宕机了，内存中的消息就丢失了。
3. 消费者还没来得及去消费这个消息，就宕机了，而MQ会以为该消息被消费了。

**怎么去解决这些不可靠的传输呢？**

1. 对于生产者，开启RabbitMQ事务（同步，不推荐）或者开启confirm模式（异步，推荐）
2. 对MQ，开启RabbitMQ持久化
3. 对于消费者：关闭RabbitMQ自动ACK

**针对于生产者来说：**

- 将信道设置成confirm模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的ID。
- 一旦消息被投递到目的队列之后，或者消息被写入磁盘之后，信道会发送一个确认给生产者。 （包含唯一的ID），就可以知道消息正确到达目的队列了。
- 如果MQ发生内部错误而导致消息丢失，会发送一条nack（notacknowledged，未确认）消息。这时你可以进行重试等操作。
- 发送方确认模式是**异步的**，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。

**针对MQ来说：**

- 一般而言都是开启持久化磁盘的配置。
- 这个可以配合生产者的confirm模式使用，可以在消息持久化到磁盘之后再给生产者发送一个ACK信号。这样，如果MQ宕机了，而消息此时未被持久化， 那么生产者就收不到ACK信号，生产者就会自动重发。
- 将Queue的持久化标识设置为true，表示持久化该队列。然后设置消息的`deliveryMode`为2，就表示将消息设置为可持久化的，此时MQ就会自动的将消息持久化到磁盘上。

**针对于消费者来说：**

- 将自动确认消息改为手动确认消息即可。不过这样有可能消费者ACK的时机慢了导致消息重复发送，不过这时候只要保证幂等性就可以了。

## 2.8 消息基于什么传输？

由于TCP连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ采用**信道**的方式来传输数据。**信道是建立在真实的TCP连接内的虚拟连接，且每条TCP连接上的信道数量没有限制**。

## 2.9 如何解决MQ消息积压问题

**先定位消费者消息慢的原因**：看看是不是有bug，或者优化一下消费逻辑，批量处理等等。

如果消费者宕机了，就会导致消息大量的积压。这时候只能进行**紧急扩容**了。

- 首先得看消费者为什么宕机，并且修复好它。
- 新建一个topic，然后临时建立好原先十倍的Queue数量。
- 写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，**但是消费之后不做耗时的处理**，直接均匀轮询写入临时建立好的十倍数量的Queue中。
- 临时征用十倍的机器来部署consumer，每一批consumer去消费一个临时Queue中的数据。
- 等快速消费完积压的消息之后，**恢复到原先的架构**，重新用修复好的原先的consumer机器来消费消息。

## 2.10 如何解决数据一致性问题

比如系统A发送了两个消息分别给订单服务和库存服务。然后订单服务成功了，库存服务失败了这时候该怎么办？

如果库存服务失败了，就给MQ返回处理失败的ACK，然后MQ会进行重试，当重试达到一定次数的时候就可以投入到死信队列中，进行人工处理或者定时任务进行相应的补偿。

当然也可以放弃MQ架构，采用分布式事务。

## 2.11 说一说死信队列

所谓的死信就是无法被消费的消息。

1. 消息设置的TTL过期了。
2. 队列达到了最大长度，无法再添加消息到MQ中（声明队列的时候可以设置队列长度）
3. 消费者拒绝消费该消息并且设置了requeue = false（表示拒绝重新入队）

上述三种就是消息成为死信的情况。

**应用场景：**为了保证订单业务的数据不丢失，就可以使用到死信队列机制，当消费发生异常，或者指定时间未支付等，就会将消息发送到对应的死信队列中，然后由消费者去监听这个死信队列去处理这些死信。

